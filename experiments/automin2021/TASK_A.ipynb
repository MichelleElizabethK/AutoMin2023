{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-8T_Vr4G76dv"
   },
   "source": [
    "# THE OFFICIAL COLAB NOTEBOOK OF TEAM ABC FOR AUTOMIN @ INTERSPEECH 2021 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 67664,
     "status": "ok",
     "timestamp": 1682547523478,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "7e8XSCDO1M7w",
    "outputId": "fb0ce023-d523-42f4-f287-aedf39259945"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "/content/drive/MyDrive/AutoMin\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: notebook in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 1)) (6.4.8)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 3)) (2.0.0+cu118)\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.11.0-py3-none-any.whl (468 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 kB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 5)) (3.8.1)\n",
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting py7zr\n",
      "  Downloading py7zr-0.20.5-py3-none-any.whl (66 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting evaluate\n",
      "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 9)) (1.2.2)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.98-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from notebook->-r requirements.txt (line 1)) (3.1.2)\n",
      "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.9/dist-packages (from notebook->-r requirements.txt (line 1)) (5.7.1)\n",
      "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.9/dist-packages (from notebook->-r requirements.txt (line 1)) (5.3.0)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.9/dist-packages (from notebook->-r requirements.txt (line 1)) (1.5.6)\n",
      "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.9/dist-packages (from notebook->-r requirements.txt (line 1)) (6.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.9/dist-packages (from notebook->-r requirements.txt (line 1)) (0.17.1)\n",
      "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.9/dist-packages (from notebook->-r requirements.txt (line 1)) (21.3.0)\n",
      "Requirement already satisfied: ipykernel in /usr/local/lib/python3.9/dist-packages (from notebook->-r requirements.txt (line 1)) (5.5.6)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.9/dist-packages (from notebook->-r requirements.txt (line 1)) (6.5.4)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.9/dist-packages (from notebook->-r requirements.txt (line 1)) (1.8.0)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.9/dist-packages (from notebook->-r requirements.txt (line 1)) (0.2.0)\n",
      "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.9/dist-packages (from notebook->-r requirements.txt (line 1)) (0.16.0)\n",
      "Requirement already satisfied: jupyter-client>=5.3.4 in /usr/local/lib/python3.9/dist-packages (from notebook->-r requirements.txt (line 1)) (6.1.12)\n",
      "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.9/dist-packages (from notebook->-r requirements.txt (line 1)) (23.2.1)\n",
      "Requirement already satisfied: nbformat in /usr/local/lib/python3.9/dist-packages (from notebook->-r requirements.txt (line 1)) (5.8.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers->-r requirements.txt (line 2)) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers->-r requirements.txt (line 2)) (1.22.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers->-r requirements.txt (line 2)) (2022.10.31)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers->-r requirements.txt (line 2)) (4.65.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m113.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers->-r requirements.txt (line 2)) (2.27.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers->-r requirements.txt (line 2)) (3.12.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers->-r requirements.txt (line 2)) (23.1)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch->-r requirements.txt (line 3)) (1.11.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->-r requirements.txt (line 3)) (4.5.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch->-r requirements.txt (line 3)) (3.1)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch->-r requirements.txt (line 3)) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->-r requirements.txt (line 3)) (3.25.2)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->-r requirements.txt (line 3)) (16.0.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets->-r requirements.txt (line 4)) (1.5.3)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets->-r requirements.txt (line 4)) (2023.4.0)\n",
      "Collecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets->-r requirements.txt (line 4)) (9.0.0)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multiprocess\n",
      "  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dill<0.3.7,>=0.3.0\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiohttp\n",
      "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->-r requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk->-r requirements.txt (line 5)) (8.1.3)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from rouge_score->-r requirements.txt (line 6)) (1.4.0)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from rouge_score->-r requirements.txt (line 6)) (1.16.0)\n",
      "Collecting texttable\n",
      "  Downloading texttable-1.6.7-py2.py3-none-any.whl (10 kB)\n",
      "Collecting pybcj>=0.6.0\n",
      "  Downloading pybcj-1.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multivolumefile>=0.2.3\n",
      "  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
      "Collecting brotli>=1.0.9\n",
      "  Downloading Brotli-1.0.9-cp39-cp39-manylinux1_x86_64.whl (357 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.2/357.2 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyppmd<1.1.0,>=0.18.1\n",
      "  Downloading pyppmd-1.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from py7zr->-r requirements.txt (line 7)) (5.9.5)\n",
      "Collecting pycryptodomex>=3.6.6\n",
      "  Downloading pycryptodomex-3.17-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyzstd>=0.14.4\n",
      "  Downloading pyzstd-0.15.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (399 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.3/399.3 kB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting inflate64>=0.3.1\n",
      "  Downloading inflate64-0.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (92 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.0/93.0 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->-r requirements.txt (line 9)) (1.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->-r requirements.txt (line 9)) (3.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (2.0.12)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.4/269.4 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (23.1.0)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.9/dist-packages (from jupyter-client>=5.3.4->notebook->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.9/dist-packages (from jupyter-core>=4.6.1->notebook->-r requirements.txt (line 1)) (3.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers->-r requirements.txt (line 2)) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers->-r requirements.txt (line 2)) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers->-r requirements.txt (line 2)) (3.4)\n",
      "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.9/dist-packages (from terminado>=0.8.3->notebook->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.9/dist-packages (from argon2-cffi->notebook->-r requirements.txt (line 1)) (21.2.0)\n",
      "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from ipykernel->notebook->-r requirements.txt (line 1)) (7.34.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->notebook->-r requirements.txt (line 1)) (2.1.2)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook->-r requirements.txt (line 1)) (0.7.1)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook->-r requirements.txt (line 1)) (0.7.3)\n",
      "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook->-r requirements.txt (line 1)) (1.2.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook->-r requirements.txt (line 1)) (4.11.2)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook->-r requirements.txt (line 1)) (4.9.2)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook->-r requirements.txt (line 1)) (0.4)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook->-r requirements.txt (line 1)) (0.8.4)\n",
      "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook->-r requirements.txt (line 1)) (0.2.2)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook->-r requirements.txt (line 1)) (6.0.0)\n",
      "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook->-r requirements.txt (line 1)) (2.14.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook->-r requirements.txt (line 1)) (1.5.0)\n",
      "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.9/dist-packages (from nbformat->notebook->-r requirements.txt (line 1)) (2.16.3)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.9/dist-packages (from nbformat->notebook->-r requirements.txt (line 1)) (4.3.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets->-r requirements.txt (line 4)) (2022.7.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.9/dist-packages (from ipython>=5.0.0->ipykernel->notebook->-r requirements.txt (line 1)) (4.8.0)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.9/dist-packages (from ipython>=5.0.0->ipykernel->notebook->-r requirements.txt (line 1)) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.9/dist-packages (from ipython>=5.0.0->ipykernel->notebook->-r requirements.txt (line 1)) (0.1.6)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from ipython>=5.0.0->ipykernel->notebook->-r requirements.txt (line 1)) (4.4.2)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/dist-packages (from ipython>=5.0.0->ipykernel->notebook->-r requirements.txt (line 1)) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from ipython>=5.0.0->ipykernel->notebook->-r requirements.txt (line 1)) (3.0.38)\n",
      "Collecting jedi>=0.16\n",
      "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.9/dist-packages (from ipython>=5.0.0->ipykernel->notebook->-r requirements.txt (line 1)) (67.7.2)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>=2.6->nbformat->notebook->-r requirements.txt (line 1)) (0.19.3)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->-r requirements.txt (line 1)) (1.15.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->nbconvert->notebook->-r requirements.txt (line 1)) (2.4.1)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.9/dist-packages (from bleach->nbconvert->notebook->-r requirements.txt (line 1)) (0.5.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->-r requirements.txt (line 1)) (2.21)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->notebook->-r requirements.txt (line 1)) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->notebook->-r requirements.txt (line 1)) (0.2.6)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24954 sha256=3c9311d590df44bb1d7a6ac8fa464ec4591c388a5b2e553c66c56f3032a80beb\n",
      "  Stored in directory: /root/.cache/pip/wheels/9b/3d/39/09558097d3119ca0a4d462df68f22c6f3c1b345ac63a09b86e\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: tokenizers, texttable, sentencepiece, brotli, xxhash, pyzstd, pyppmd, pycryptodomex, pybcj, multivolumefile, multidict, jedi, inflate64, frozenlist, dill, async-timeout, yarl, rouge_score, responses, py7zr, multiprocess, huggingface-hub, aiosignal, transformers, aiohttp, datasets, evaluate\n",
      "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 brotli-1.0.9 datasets-2.11.0 dill-0.3.6 evaluate-0.4.0 frozenlist-1.3.3 huggingface-hub-0.14.1 inflate64-0.3.1 jedi-0.18.2 multidict-6.0.4 multiprocess-0.70.14 multivolumefile-0.2.3 py7zr-0.20.5 pybcj-1.0.1 pycryptodomex-3.17 pyppmd-1.0.0 pyzstd-0.15.7 responses-0.18.0 rouge_score-0.1.2 sentencepiece-0.1.98 texttable-1.6.7 tokenizers-0.13.3 transformers-4.28.1 xxhash-3.2.0 yarl-1.9.2\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# %cd drive/MyDrive/AutoMin\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 820,
     "status": "ok",
     "timestamp": 1682547583922,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "RSwS9Q7s1J9c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "PREPROCESSED_DIR = \"preprocessed_data\"\n",
    "OUTPUT_DIR = \"minutes\"\n",
    "\n",
    "TRAIN_DIR = \"train\"\n",
    "DEV_DIR = \"dev\"\n",
    "TEST_DIR = \"test\"\n",
    "TEST2_DIR = \"test2\"\n",
    "\n",
    "MODEL_PATH = \"models/bart_large_xsum_samsum\"\n",
    "MODEL_NAME = \"facebook/bart-large-xsum\"\n",
    "CHECKPOINT = \"checkpoint-5500\"\n",
    "PRETRAIN_DATASET = \"samsum\"\n",
    "METRIC = \"rouge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2270,
     "status": "ok",
     "timestamp": 1682547589373,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "qB92jNAF5zg_",
    "outputId": "0a7ffb31-fe8f-41aa-c1ec-9e177546e677"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name())\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276,
     "referenced_widgets": [
      "0be7b5910e8e41be9424295998f46569",
      "e62e3ff63b984e8a8c38e4d9b534251f",
      "69eb5b2b3b7c4db29d05750e0de3e13c",
      "8a4a8c70653c46e7b7e55161ab78b786",
      "21ff593fad284a0893618fc0fa598371",
      "70418d1b76a445c78fd45dd7d05a2f37",
      "e952d821f2c84c088d7d31e9c9e2c2f2",
      "39480c2e10bd4e0d9a5691f8693efb0f",
      "37c01a8e24034fdbb11f36d4357dd69f",
      "744551fb48b743f1ba8c388c7c9e3d78",
      "39e71963f0734ff4b0a1976ec6e0fabb",
      "ba6afd4fe48d4af4b57aa63710422e48",
      "41369f0df37449cca5db9a3ea4343e8c",
      "1bf5bdc3ed4f4843b8a5be7cec4e4a61",
      "1cf51c58aa8f4b58bbde38e9f7982089",
      "659b56c2c3da4d0f976b0e935a695f12",
      "70ce3baac1614a03b2a5fbd3ec372d76",
      "99d5ec18ceb24be68ff71cee533d987a",
      "e1343128a8e148909c67c432ecbe71c7",
      "c3aa5b42ec804a22b0ed0a161ea89494",
      "86743b788fb64ad7a2fcc0d3698cb8e1",
      "c899881f4a99464bb893c406557ec37d",
      "0424a5f9d0554d8fa7e140b53e97e058",
      "e9a126f8b0c540008fecfc1fc3ec1643",
      "82fe36019b8c4abe98e3f64df392de8f",
      "a7da8b45e1ac4695841b3765c98e2ea7",
      "d6ee480089974b68822fe03461f48ba2",
      "b2df8d4ce807492fbe7d5da71d5c0fbf",
      "ee7a46a7ab7a47ee9f58803f884c82b7",
      "9fb84994405f4f879579bc14a3e37008",
      "cd0784ff3ff043029d0a53276c7215f4",
      "6389af7f7df64b2f8bade5af96165ac5",
      "3a062a81783d4fe182801e659f579aef",
      "d1a8ea2af6974dd2b879c6c7899a2acc",
      "2576e2e5d26d4bc1a9af456d8c1c6610",
      "9f010fc8ea4747719096404365713af5",
      "639be07d74de48a89ac8541f6a329ee3",
      "c0cc811310b045208054582bdf31507e",
      "d156b75b4cfe4614871b66ffa142fc67",
      "560d0c10616f4648a8cc5be7f7fcfaa4",
      "6bcb494658184a4190c5e02d921b6545",
      "6bf1c3bc52f14ccd97254b2cc4647149",
      "aadd876e8107480899cde6d29112688b",
      "0f69d93ad981442e8609b16c93711f1f",
      "899cecd503c443328e4d9e38c510c00e",
      "738d7cb305124cb6a537b638f69569ba",
      "dc7662194cc1452fb365dd14898f4cb2",
      "d3e4d4986d9a486297c0177252436be7",
      "37db54af76c74bfe96777a5f5c5a6d4c",
      "deeea229c94141b28b0f8dd26188874e",
      "0070bcb06ddf4ab3a6fe6cc2e4b90ace",
      "7f5f1dc8f34d4a61a3c71b012844dc16",
      "cfbdf5f1b2454611b9797b25b668c85f",
      "260e547d94804de49e5a27b8693236be",
      "bee97cf0e6b54da68dc71b5ab8a91067",
      "5c7b5ce44f1f4740be55481c2543404d",
      "6c2dd4cb0dcf48ef96f8e8bef5e03721",
      "e703d274799642fa80ec0a3c138d7dec",
      "786a649a2b134d47951cd389dca85113",
      "1b127286b3f94d43ba939aad47c6d2c9",
      "1229d438945742458eeba0010a9827bf",
      "7a825ca8753c434aa03c2844dd4cd7a0",
      "cdb13e3cda8b48618898acebdd55dc3e",
      "dd26efb9b4024fb9a054b919c4fc2d7a",
      "bd1372f973c34bf38fe39fbd91828965",
      "803fd2a45af5453ab95c03852739e347",
      "664b19797efe463fa03489f87efca28d",
      "a08b337cb0eb440fb02c6ba15410e140",
      "d38a3a83264e42ed93990d45db08587d",
      "9420510e242f42a3b85a1e772f04bfc6",
      "2163958cbd72439db7ec6ba17d1d251b",
      "a49450be232741e6abca0345f9eaf2ec",
      "7378db67124e403db42173bb0dd0996f",
      "8c196a76ebd047189a79b0601e95fe39",
      "30f805de7fbb470e86bd22759bd1d607",
      "f29e0471e1134035b52455f575c50c39",
      "d6b7a53f1a4f4fa68f0921c2207f16e7"
     ]
    },
    "executionInfo": {
     "elapsed": 91308,
     "status": "ok",
     "timestamp": 1682547701169,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "0ukVZnIADqw8",
    "outputId": "94603eba-9186-453e-d8df-32fb52dd40e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/michelle/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Can't load the configuration of 'models/bart_large_xsum_samsum/checkpoint-5500'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'models/bart_large_xsum_samsum/checkpoint-5500' is the correct path to a directory containing a config.json file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/LCT/Year1-CharlesUniversity/Summer Term/Statistical Machine Translation/AutoMin2023/venv/lib/python3.10/site-packages/transformers/configuration_utils.py:628\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    627\u001b[0m     \u001b[39m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m     resolved_config_file \u001b[39m=\u001b[39m cached_file(\n\u001b[1;32m    629\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m    630\u001b[0m         configuration_file,\n\u001b[1;32m    631\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    632\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    633\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    634\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    635\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    636\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    637\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    638\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    639\u001b[0m         subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[1;32m    640\u001b[0m         _commit_hash\u001b[39m=\u001b[39;49mcommit_hash,\n\u001b[1;32m    641\u001b[0m     )\n\u001b[1;32m    642\u001b[0m     commit_hash \u001b[39m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n",
      "File \u001b[0;32m~/Desktop/LCT/Year1-CharlesUniversity/Summer Term/Statistical Machine Translation/AutoMin2023/venv/lib/python3.10/site-packages/transformers/utils/hub.py:409\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 409\u001b[0m     resolved_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[1;32m    410\u001b[0m         path_or_repo_id,\n\u001b[1;32m    411\u001b[0m         filename,\n\u001b[1;32m    412\u001b[0m         subfolder\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mlen\u001b[39;49m(subfolder) \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;49;00m subfolder,\n\u001b[1;32m    413\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    414\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    415\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    416\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    417\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    418\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    419\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    420\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    421\u001b[0m     )\n\u001b[1;32m    423\u001b[0m \u001b[39mexcept\u001b[39;00m RepositoryNotFoundError:\n",
      "File \u001b[0;32m~/Desktop/LCT/Year1-CharlesUniversity/Summer Term/Statistical Machine Translation/AutoMin2023/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:112\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m arg_name \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mrepo_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfrom_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mto_id\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m--> 112\u001b[0m     validate_repo_id(arg_value)\n\u001b[1;32m    114\u001b[0m \u001b[39melif\u001b[39;00m arg_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtoken\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m arg_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/LCT/Year1-CharlesUniversity/Summer Term/Statistical Machine Translation/AutoMin2023/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:160\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[39mif\u001b[39;00m repo_id\u001b[39m.\u001b[39mcount(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 160\u001b[0m     \u001b[39mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    161\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRepo id must be in the form \u001b[39m\u001b[39m'\u001b[39m\u001b[39mrepo_name\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mnamespace/repo_name\u001b[39m\u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mrepo_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. Use `repo_type` argument if needed.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m REPO_ID_REGEX\u001b[39m.\u001b[39mmatch(repo_id):\n",
      "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': 'models/bart_large_xsum_samsum/checkpoint-5500'. Use `repo_type` argument if needed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(MODEL_NAME)\n\u001b[1;32m     11\u001b[0m model \u001b[39m=\u001b[39m AutoModelForSeq2SeqLM\u001b[39m.\u001b[39mfrom_pretrained(MODEL_NAME)\n\u001b[0;32m---> 12\u001b[0m summarizer \u001b[39m=\u001b[39m pipeline(\u001b[39m\"\u001b[39;49m\u001b[39msummarization\u001b[39;49m\u001b[39m\"\u001b[39;49m, model\u001b[39m=\u001b[39;49mos\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(MODEL_PATH, CHECKPOINT), device\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/LCT/Year1-CharlesUniversity/Summer Term/Statistical Machine Translation/AutoMin2023/venv/lib/python3.10/site-packages/transformers/pipelines/__init__.py:692\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, use_auth_token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m     hub_kwargs[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39m_commit_hash\n\u001b[1;32m    691\u001b[0m \u001b[39melif\u001b[39;00m config \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(model, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 692\u001b[0m     config \u001b[39m=\u001b[39m AutoConfig\u001b[39m.\u001b[39;49mfrom_pretrained(model, _from_pipeline\u001b[39m=\u001b[39;49mtask, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhub_kwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs)\n\u001b[1;32m    693\u001b[0m     hub_kwargs[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39m_commit_hash\n\u001b[1;32m    695\u001b[0m custom_tasks \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/Desktop/LCT/Year1-CharlesUniversity/Summer Term/Statistical Machine Translation/AutoMin2023/venv/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:896\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    894\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mname_or_path\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pretrained_model_name_or_path\n\u001b[1;32m    895\u001b[0m trust_remote_code \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mtrust_remote_code\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 896\u001b[0m config_dict, unused_kwargs \u001b[39m=\u001b[39m PretrainedConfig\u001b[39m.\u001b[39;49mget_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    897\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mAutoConfig\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict[\u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    898\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m trust_remote_code:\n",
      "File \u001b[0;32m~/Desktop/LCT/Year1-CharlesUniversity/Summer Term/Statistical Machine Translation/AutoMin2023/venv/lib/python3.10/site-packages/transformers/configuration_utils.py:573\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    571\u001b[0m original_kwargs \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    572\u001b[0m \u001b[39m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 573\u001b[0m config_dict, kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_get_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    574\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict:\n\u001b[1;32m    575\u001b[0m     original_kwargs[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m config_dict[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/LCT/Year1-CharlesUniversity/Summer Term/Statistical Machine Translation/AutoMin2023/venv/lib/python3.10/site-packages/transformers/configuration_utils.py:649\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[1;32m    647\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    648\u001b[0m         \u001b[39m# For any other exception, we throw a generic error.\u001b[39;00m\n\u001b[0;32m--> 649\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    650\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt load the configuration of \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. If you were trying to load it\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    651\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m from \u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/models\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, make sure you don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt have a local directory with the same\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    652\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m name. Otherwise, make sure \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m is the correct path to a directory\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    653\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m containing a \u001b[39m\u001b[39m{\u001b[39;00mconfiguration_file\u001b[39m}\u001b[39;00m\u001b[39m file\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    654\u001b[0m         )\n\u001b[1;32m    656\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    657\u001b[0m     \u001b[39m# Load config dict\u001b[39;00m\n\u001b[1;32m    658\u001b[0m     config_dict \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_dict_from_json_file(resolved_config_file)\n",
      "\u001b[0;31mOSError\u001b[0m: Can't load the configuration of 'models/bart_large_xsum_samsum/checkpoint-5500'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'models/bart_large_xsum_samsum/checkpoint-5500' is the correct path to a directory containing a config.json file"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, pipeline, AutoModelForSeq2SeqLM\n",
    "import nltk\n",
    "import re\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
    "summarizer = pipeline(\"summarization\", model=os.path.join(MODEL_PATH, CHECKPOINT), device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 620,
     "status": "ok",
     "timestamp": 1682547736306,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "Wupr-PBc1J9g",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_preprocessed_transcripts(file_name):\n",
    "  with open(f\"{file_name}.json\", \"r\") as f:\n",
    "    preprocessed_transcripts = json.load(f)\n",
    "\n",
    "  return preprocessed_transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 8194,
     "status": "ok",
     "timestamp": 1682547754415,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "st2y7Snb1J9h",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cs_train_preprocessed = load_preprocessed_transcripts(os.path.join(PREPROCESSED_DIR, \"cs\", TRAIN_DIR))\n",
    "cs_dev_preprocessed = load_preprocessed_transcripts(os.path.join(PREPROCESSED_DIR, \"cs\", DEV_DIR))\n",
    "cs_test_preprocessed = load_preprocessed_transcripts(os.path.join(PREPROCESSED_DIR, \"cs\", TEST_DIR))\n",
    "cs_test2_preprocessed = load_preprocessed_transcripts(os.path.join(PREPROCESSED_DIR, \"cs\", TEST2_DIR))\n",
    "\n",
    "en_train_preprocessed = load_preprocessed_transcripts(os.path.join(PREPROCESSED_DIR, \"en\", TRAIN_DIR))\n",
    "en_dev_preprocessed = load_preprocessed_transcripts(os.path.join(PREPROCESSED_DIR, \"en\", DEV_DIR))\n",
    "en_test_preprocessed = load_preprocessed_transcripts(os.path.join(PREPROCESSED_DIR, \"en\", TEST_DIR))\n",
    "en_test2_preprocessed = load_preprocessed_transcripts(os.path.join(PREPROCESSED_DIR, \"en\", TEST2_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1682547766097,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "2zMtAUGgyq9I",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### CUSTOMIZED STRIP, REPLACE AND PREPROCESS FUNCTIONS ###\n",
    "\n",
    "def stripp(string):\n",
    "    list1=[]\n",
    "    string = string.strip()\n",
    "    list1[:0]=string\n",
    "    idx = 0\n",
    "    cnd = False\n",
    "    for i in list1:\n",
    "        if i.isalpha():\n",
    "            cnd = True\n",
    "            break\n",
    "    if cnd:\n",
    "        while list1[0].isalpha() == False:\n",
    "            if idx+1 == len(string):\n",
    "                break\n",
    "            list1.remove(list1[0])\n",
    "            idx+=1\n",
    "        list1 = ''.join(list1)\n",
    "    else:\n",
    "        list1 = None\n",
    "\n",
    "    return list1\n",
    "\n",
    "def preprocess(ctx):\n",
    "  ctx = ctx.replace(\" '\", \"'\")\n",
    "  ctx = ctx.replace(\" ,\", \",\")\n",
    "  ctx = ctx.replace(\" .\", \".\")\n",
    "  ctx = ctx.replace(\" ?\", \"?\")\n",
    "  ctx = ctx.replace(\"Ehmm\", \"\")\n",
    "  ctx = ctx.replace(\" Ehm\", \"\")\n",
    "  ctx = ctx.replace(\" mmm\", \"\")\n",
    "  ctx = ctx.replace(\" hmm\", \"\")\n",
    "  ctx = ctx.replace(\" uh\", \"\")\n",
    "  ctx = ctx.replace(\" uh ,\", \"\")\n",
    "  ctx = ctx.replace(\" uh .\", \"\")\n",
    "  ctx = ctx.replace(\" um\", \"\")\n",
    "  ctx = ctx.replace(\" um ,\", \"\")\n",
    "  ctx = ctx.replace(\" um .\", \"\")\n",
    "  ctx = ctx.replace(\" Uh\", \"\")\n",
    "  ctx = ctx.replace(\" Uh ,\", \"\")\n",
    "  ctx = ctx.replace(\" Uh .\", \"\")\n",
    "  ctx = ctx.replace(\" Um\", \"\")\n",
    "  ctx = ctx.replace(\" Um ,\", \"\")\n",
    "  ctx = ctx.replace(\" Um .\", \"\")\n",
    "  ctx = ctx.replace(\"Uh\", \"\")\n",
    "  ctx = ctx.replace(\"Um\", \"\")\n",
    "  ctx = ctx.replace(\"Yeah\", \"\")\n",
    "  ctx = ctx.replace(\" yeah\", \"\")\n",
    "  ctx = ctx.replace(\"Ehm, \", \"\")\n",
    "  ctx = ctx.replace(\"Hmm, \", \"\")\n",
    "  ctx = ctx.replace(\"Ehm. \", \"\")\n",
    "  ctx = ctx.replace(\"Hmm. \", \"\")\n",
    "  ctx = ctx.replace(\"Yeah\", \"\")\n",
    "  ctx = ctx.replace(\" yeah\", \"\")\n",
    "  ctx = ctx.replace(\"Ehm\", \"\")\n",
    "  ctx = ctx.replace(\"Hmm\", \"\")\n",
    "  ctx = ctx.replace(\"Ehm\", \"\")\n",
    "  ctx = ctx.replace(\"Hmm\", \"\")\n",
    "  ctx = ctx.replace(\"Mhm\", \"\")\n",
    "  ctx = ctx.replace(\" {disfmarker}\", \"\")\n",
    "  ctx = ctx.replace(\" {vocalsound}\", \"\")\n",
    "  ctx = ctx.replace(\" {gap}\", \"\")\n",
    "  ctx = ctx.replace(\"...\", \".\")\n",
    "  ctx = ctx.replace(\"..\", \".\")\n",
    "  ctx = ctx.replace(\",,\", \",\")\n",
    "  ctx = ctx.replace(\",,\", \",\")\n",
    "  ctx = ctx.replace(\",.\", \"\")\n",
    "  ctx = ctx.replace(\".,\", \".\")\n",
    "  ctx = ctx.replace(\"  \", \" \")\n",
    "  ctx = ctx.replace(\"(\", \"\")\n",
    "  ctx = ctx.replace(\")\", \"\")\n",
    "  ctx = ctx.replace(\"Person\", \"PERSON\")\n",
    "  ctx = ctx.replace(\"is going to\", \"will\")\n",
    "  ctx = ctx.replace(\"are going to\", \"will\")\n",
    "  ctx = ctx.replace(\"are discussing\", \"discussed\")\n",
    "  ctx = ctx.replace(\"discuss\", \"discussed\")\n",
    "  ctx = ctx.replace(\"are working\", \"worked\")\n",
    "  ctx = ctx.replace(\"is working\", \"worked\")\n",
    "\n",
    "  return ctx\n",
    "\n",
    "def replacee(i):\n",
    "  i = i.replace(\"do n't\", \"do not\")\n",
    "  i = i.replace(\"n't\", \"not\")\n",
    "  i = i.replace(\"it 's\", \"it is\")\n",
    "  i = i.replace(\" 's\", \"\")\n",
    "  if i[0]+i[1] == \"'s\":\n",
    "    i = i.replace(\"'s \", \"\")\n",
    "  i = i.replace(\"wo n't\", \"won't\")\n",
    "  i = i.replace(\" and\", \",\")\n",
    "  i = i.replace(\",,\", \",\")\n",
    "  return i\n",
    "\n",
    "def gen_tscs(length, transcripts, meeting_id=None):\n",
    "  def split_line(line):\n",
    "    splits = []\n",
    "\n",
    "    line_ = line.split('.')\n",
    "    split_ = len(line_)//2\n",
    "    line1 = '. '.join(line_[0:split_]) + '.\\n'\n",
    "    line2 = role + ': ' + '. '.join(line_[split_:])\n",
    "\n",
    "    for line in [line1, line2]:\n",
    "      if len(tokenizer.encode(line)) >= length:\n",
    "        splits += split_line(line)\n",
    "      else:\n",
    "        splits.append(line)\n",
    "\n",
    "    return splits\n",
    "\n",
    "\n",
    "  tscs_preprocessed = {}\n",
    "  attendees = []\n",
    "\n",
    "  for m_id, transcript in transcripts.items():\n",
    "    if meeting_id is not None and m_id != meeting_id:\n",
    "      continue\n",
    "\n",
    "    roles = transcript['roles']\n",
    "    attendees.append(sorted(list(set(roles))))\n",
    "    utterances = transcript['utterances']\n",
    "    tsc = ['']\n",
    "    i=0\n",
    "    for role, utterance in zip(roles, utterances):\n",
    "      utterance = preprocess(utterance)\n",
    "      v = re.sub(r\"[^a-zA-Z0-9]+\", ' ', utterance)\n",
    "      v = v.split(' ')\n",
    "      if len(v)<=4:\n",
    "        continue\n",
    "      if len(v)>4 and len(v)<7 and 's' in v:\n",
    "        continue\n",
    "      utterance = stripp(utterance)\n",
    "      if utterance == None:\n",
    "        continue\n",
    "      if len(utterance) == 1:\n",
    "        continue\n",
    "      line = role + ': ' + utterance + '\\n'\n",
    "\n",
    "      # IF DIALOGUE IS LONGER THAN \"length\"\n",
    "      tokenized_line = tokenizer.encode(line)\n",
    "      if len(tokenized_line)>=length:\n",
    "          line_splits = split_line(line)\n",
    "      else:\n",
    "          line_splits = [line]\n",
    "\n",
    "      for l in line_splits:\n",
    "          tokenized = tokenizer.encode(tsc[i]+l)\n",
    "          if len(tokenized)>=length:\n",
    "              i+=1\n",
    "              tsc.append('')\n",
    "              tsc[i]+=l\n",
    "          else:\n",
    "              tsc[i]+=l\n",
    "\n",
    "    tscs = {m_id: tsc}\n",
    "    tscs_preprocessed.update(tscs)\n",
    "\n",
    "  return tscs_preprocessed, attendees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1972,
     "status": "ok",
     "timestamp": 1682547771027,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "-6_e2PWcU30k",
    "outputId": "7ebe654e-4bf3-46c6-a922-d6895519cdec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSON11: Hi, how are you? Good morning.\n",
      "PERSON4: Good morning. I'm, well, fine. Still at home.\n",
      "PERSON4: You know. And you?\n",
      "PERSON11: I'm also at home. But, ehm, the Czech republic government, they already lifted the Kind of lifted the rules. So, ehm, from this Monday we can actually go out even if it's not like the necessity. It the meetings of. Up to 10 people are allowed.\n",
      "PERSON4: Ha. So here in LOCATION1, we have to wait until the 4th of May, some commercial activity can already be open. But we think that we have to wait until June for the free circulation of people. And fortunately, starting from the 4th of June we are allowed to reach our family. If it's in the same region.\n",
      "PERSON4: And so finally, I will reach my parents. Cause we live in two different cities. Because I'm in Trento and my family is in Bolzano. Which is pretty near around 50 kilometres. But, but\n",
      "PERSON11: So you're looking forward.\n",
      "PERSON4: exactly. Hi guys, good morning.\n",
      "PERSON11: So I went to the park yestreday and I was really happy. I mean I kept my distance from everyone but like it was green there. So it was.\n",
      "PERSON15: But you can't go to the forest or something?\n",
      "PERSON15: You can't just go to the forest or something?\n",
      "PERSON11: Well, the rules changed here and since this Monday we can't go out even if it is not like the most necessary groceries or stuff like this, and.\n",
      "PERSON15: And thanks we are able to go out to the forest, whenever we wanted.\n",
      "PERSON11: Yes, but if you are in the city then you have to somehow get to the forest, so.\n",
      "PERSON8: Hello. Can you hear me?\n",
      "PERSON8: Sorry for the delay. So, Am I the last one?\n",
      "PERSON11: Probably yes, because ORGANIZATION3,PERSON3 and PERSON14 said that they have the call so they can't join ours.\n",
      "PERSON11: And ORGANIZATION3 is not coming.\n",
      "PERSON8: So we have every partner. A partner from everywhere, that thats great. Thanks for joining. So this is again one of our regular calls. There will be, before the summer, there will be at least one more, in May. Oh no, two more actually. One in May and one in June, and. Let maybe PERSON11 should start with the administrative part. . So, PERSON11, can you? You know the review day, then all this.\n",
      "PERSON11: Okay, so, we. PERSON7 told us that we will have to postpone one of our regular meeting. And she asked us about dates. So I already set it up. Well. Not many people voted in that Doodle. So, please vote for the postpone review. It should be in September. I know that nobody knows so litheraly if will be able to travel somewhere, and it looks like that it will be just online meeting. But, anyway just vote in a Doodle so I can get PERSON7 some dates. So, just do your best estimates for September. And that's it for that. We have we will have eh couple of deliverables due in June. I've link there in the in that Google sheet we have for tricking our like deliverables or stuff. We have the links for overview. So for these six up coming once you can basically start working on them.\n",
      "PERSON11: We haven't decided who will be our internal review person for any of them.\n",
      "PERSON8: Which is a good opportunity to choose them now.\n",
      "PERSON11: Yes. So just have a look. And if it's not your deliverable and you would like to read it just tell me.\n",
      "PERSON8: So we will be contribute. So I think that the the two point one, the initial ASR systems ORGANIZATION1 is not providing in ASR system. And that's a technical We are providing some. So it will be good if if ORGANIZATION1 review that. So actually PERSON10 the. The volunteer should be entered in the continues reporting. She not not in this table just copy copypasted.\n",
      "PERSON11: You can you can enter it here and I will just put it into the right place. You can just.\n",
      "PERSON1: Okay, I'm gonna last review the summarization. But generally, there ASR also interesting for me. So probably put down PERSON10.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### IF INFERENCING ON A SPECIFIC TRANSCRIPT, INPUT THE MEETING ID... ###\n",
    "m_id = 'meeting_en_test_006'\n",
    "\n",
    "### IMPLEMENTING THE BELOW LINES WILL GIVE 3 SUMMARIES WITH VARYING LENGTHS, AS MENTIONED ###\n",
    "tscs_preprocessed_long, attendees = gen_tscs(512, en_test_preprocessed, meeting_id=m_id) #for longer summary\n",
    "tscs_preprocessed_avg, attendees = gen_tscs(768, en_test_preprocessed, meeting_id=m_id)\n",
    "tscs_preprocessed_short, attendees = gen_tscs(1024, en_test_preprocessed, meeting_id=m_id) #for shorter summary\n",
    "\n",
    "print(tscs_preprocessed_short[m_id][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1682547773264,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "mKc5wZQp1J9h",
    "outputId": "caa6073c-32a4-429d-c3e1-8ff97f5ffdfd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "14\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "print(len(tscs_preprocessed_short[m_id]))\n",
    "print(len(tscs_preprocessed_avg[m_id]))\n",
    "print(len(tscs_preprocessed_long[m_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1682547776763,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "xeoD-XjdDk8-",
    "outputId": "698d10a8-95ba-4fb6-d8a2-c97a8d6dc4b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - PERSON11: Hi, how are you? Good morning.\n",
      "PERSON4: Good morning. I'm, well, fine. Still at home.\n",
      "PERSON4: You know. And you?\n",
      "PERSON11: I'm also at home. But, ehm, the Czech republic government, they already lifted the Kind of lifted the rules. So, ehm, from this Monday we can actually go out even if it's not like the necessity. It the meetings of. Up to 10 people are allowed.\n",
      "PERSON4: Ha. So here in LOCATION1, we have to wait until the 4th of May, some commercial activity can already be open. But we think that we have to wait until June for the free circulation of people. And fortunately, starting from the 4th of June we are allowed to reach our family. If it's in the same region.\n",
      "PERSON4: And so finally, I will reach my parents. Cause we live in two different cities. Because I'm in Trento and my family is in Bolzano. Which is pretty near around 50 kilometres. But, but\n",
      "PERSON11: So you're looking forward.\n",
      "PERSON4: exactly. Hi guys, good morning.\n",
      "PERSON11: So I went to the park yestreday and I was really happy. I mean I kept my distance from everyone but like it was green there. So it was.\n",
      "PERSON15: But you can't go to the forest or something?\n",
      "PERSON15: You can't just go to the forest or something?\n",
      "PERSON11: Well, the rules changed here and since this Monday we can't go out even if it is not like the most necessary groceries or stuff like this, and.\n",
      "PERSON15: And thanks we are able to go out to the forest, whenever we wanted.\n",
      "PERSON11: Yes, but if you are in the city then you have to somehow get to the forest, so.\n",
      "PERSON8: Hello. Can you hear me?\n",
      "PERSON8: Sorry for the delay. So, Am I the last one?\n",
      "PERSON11: Probably yes, because ORGANIZATION3,PERSON3 and PERSON14 said that they have the call so they can't join ours.\n",
      "PERSON11: And ORGANIZATION3 is not coming.\n",
      "PERSON8: So we have every partner. A partner from everywhere, that thats great. Thanks for joining. So this is again one of our regular calls. There will be, before the summer, there will be at least one more, in May. Oh no, two more actually. One in May and one in June, and. Let maybe PERSON11 should start with the administrative part. . So, PERSON11, can you? You know the review day, then all this.\n",
      "PERSON11: Okay, so, we. PERSON7 told us that we will have to postpone one of our regular meeting. And she asked us about dates. So I already set it up. Well. Not many people voted in that Doodle. So, please vote for the postpone review. It should be in September. I know that nobody knows so litheraly if will be able to travel somewhere, and it looks like that it will be just online meeting. But, anyway just vote in a Doodle so I can get PERSON7 some dates. So, just do your best estimates for September. And that's it for that. We have we will have eh couple of deliverables due in June. I've link there in the in that Google sheet we have for tricking our like deliverables or stuff. We have the links for overview. So for these six up coming once you can basically start working on them.\n",
      "PERSON11: We haven't decided who will be our internal review person for any of them.\n",
      "PERSON8: Which is a good opportunity to choose them now.\n",
      "PERSON11: Yes. So just have a look. And if it's not your deliverable and you would like to read it just tell me.\n",
      "PERSON8: So we will be contribute. So I think that the the two point one, the initial ASR systems ORGANIZATION1 is not providing in ASR system. And that's a technical We are providing some. So it will be good if if ORGANIZATION1 review that. So actually PERSON10 the. The volunteer should be entered in the continues reporting. She not not in this table just copy copypasted.\n",
      "PERSON11: You can you can enter it here and I will just put it into the right place. You can just.\n",
      "PERSON1: Okay, I'm gonna last review the summarization. But generally, there ASR also interesting for me. So probably put down PERSON10.\n",
      "\n",
      "1 - PERSON8: So I don't know, who should we the summarization eh review. Then that's another.\n",
      "PERSON1: I think we're not contributing that don't know facts.\n",
      "PERSON1: There we should wouldn't not this stage.\n",
      "PERSON16: Okay, I would be happy to do the review.\n",
      "PERSON8: Okay, rage. What can we review? Is there anything that we can review?\n",
      "PERSON1: That's a problem we contribute everything.\n",
      "PERSON8: And for this D7 2 do I understand correctly, PERSON11, please correct me. I think that we should ask for an extension for this deliver because Congress has not taken place.\n",
      "PERSON8: So actually, I hope that this one will not be needed. So.\n",
      "PERSON11: Yes, we will have to chec check it with PERSON7.\n",
      "PERSON1: So, who is gonna review three point one, cause I'm hoping that everyone only the universe is contributing three point one.\n",
      "PERSON1: So maybe maybe ORGANIZATION5 would be just a placed.\n",
      "PERSON8: Exactly Because ORGANIZATION5 is also developing their own systems in this area.\n",
      "PERSON8: There. So it would be great if ORGANIZATION5 did it.\n",
      "PERSON13: Let me down the check, okay?\n",
      "PERSON8: So PERSON13 should we list your name or not? Or you will let us know?\n",
      "PERSON13: Eh, I will let you know.\n",
      "PERSON8: okay. So lets put PERSON13 with two question marks. Okay. And then, then the management guy.\n",
      "PERSON11: Well, I think I could I could. Well, the dissemination activities I could do that but if we are not. But I'm also doing the dissemination on the web and stuff like that.\n",
      "PERSON8: I don't think there will be too too much of a problem. So I think that that that little should be like cross reviewed between ORGANIZATION3 and us. So we should review what they wrote and they should review what we wrote.\n",
      "PERSON8: So, PERSON11, write yourself as the reviewer and\n",
      "PERSON11: So I will put here PERSON11 plus PERSON3.\n",
      "PERSON8: and I have no idea of this project management guide is again.\n",
      "PERSON8: I think that will be checked an update.\n",
      "PERSON11: No no, there is no, there wasn't any, anything like that before.\n",
      "PERSON8: Oh, this is the.\n",
      "PERSON11: Sum it. And this is the first one. So I'm apparently writing it.\n",
      "PERSON11: And it will be a lot of lot of words about nothing but yes. Yes.\n",
      "PERSON8: I'm afraid so.\n",
      "PERSON11: So who wants who wants to read a fairy tale.\n",
      "PERSON8: So the the best position would be I think ORGANIZATION1, because they have coordinated a number of projects.\n",
      "PERSON1: I'm much rather read about ASR systems.\n",
      "PERSON1: not that keen on reading it to be honest.\n",
      "PERSON1: I could, you know, I could say we have to if it's not many words. PERSON11 said it'll be lots of words.\n",
      "PERSON8: Yes, PERSON11, please cut down the number of words.\n",
      "PERSON11: Like I think will run out of idea what to write there. So it won't be really long.\n",
      "PERSON8: But there must be, there must be some project management guide from previous project.\n",
      "PERSON11: I don't have it. So if you do you send to me.\n",
      "PERSON1: I, I do not know, I think we managed to avoid such a thing before.\n",
      "PERSON11: Why do we have it even?\n",
      "PERSON1: Even I do remember writing it on.\n",
      "PERSON8: well. Wasn't there anything like that from QT21 for example? I'll search.\n",
      "PERSON11: I mean. Yesterday I search in PROJECT2 like what is the description of this of this deliverable, and it says just czech management guide. There is no description.\n",
      "PERSON1: And this is the first iteration of that, is it?\n",
      "PERSON1: And how it could be managing without project management guide so far if we don't. 15 months.\n",
      "PERSON11: I mean, with PERSON8 we are awesome obviously. We can manage the project even without a guide.\n",
      "PERSON8: it's just a party, they do do what they're expected to do even without the managing them. So that.\n",
      "\n",
      "2 - PERSON15: An exercise is so organized.\n",
      "PERSON8: exactly, that's that's what PERSON9 can has always said I also believe in selforganization. Hm so QT21 doesn't seem to have this. They have this period reports and data management plans but not the project management guides.\n",
      "PERSON1: I don't remember such a thing, no.\n",
      "PERSON8: So it probably it was copypasted from something from somewhere. And no whatever.\n",
      "PERSON1: I don't remember.\n",
      "PERSON11: Okay, anyway, I'll write something and someone then will review it.\n",
      "PERSON8: So another thing is like who would like to coordinate future projects. Those people should also have some a little incentive to to read it. So is any partner planning to do like start. Anyone who was not coordinated the projects yet. We could even ask ORGANIZATION3 to to review that because there. So that they would finally know what like what these EU projects are about. .\n",
      "PERSON11: Okay, we can decided slowlier.\n",
      "PERSON8: So it is important that they do start writing and the the due date has not been shifting. So that would be the end of June. So the internal reviews should be ready by mid June at the latest. So that we have two weeks to finish that.\n",
      "PERSON1: Can you give us a date? Mid June seems kind of late.\n",
      "PERSON8: Okay, yes, exactly. , let's do it earlier.\n",
      "PERSON1: Especially things usually slept.\n",
      "PERSON8: Yep So the 8th, the 8th of June.\n",
      "PERSON1: that sounds fine.\n",
      "PERSON8: So that should be the end of the review, kind of, right? Or no. It shou No, sorry, sorry. The beginning, the beginning. This should be delay.\n",
      "PERSON1: It is the first draft.\n",
      "PERSON8: First draft, yes, but complete draft. , So then you basically have a week reviewer two week to fix it.\n",
      "PERSON1: And a week for no further every week spare\n",
      "PERSON1: For for final tracks from the coordinator.\n",
      "PERSON8: okay, that looks good. So, then the milestone. So the previous milestones of talk to PERSON5 in the email that you seen that of the milestones claiming that we have all the complete set up for ORGANIZATION4 Congress, which technically we have. So And there is one more milestone, the Congress. And PERSON5 said that there is no need to like think that of specifically, because, well, it won't happen yet. So we will take it off in that year from from now. So.\n",
      "PERSON11: Yes and another. . Another another the most earlier milestone is in December. So. Do we find have anyone milestone in December. And there will be. I forgot to put the the one more deliverable. That will be due in the end of August. And that's the year 2 test set. So, that will be.\n",
      "PERSON8: So the test sets, this is something that we are building. We call it the PROJECT1 test sets. So it is, I think the the main responsible for this deliverable is ORGANIZATION1, right?\n",
      "PERSON8: So PERSON9 please, I have started this PROJECT1 test sets some time ago. You know, where the repository lives. So please pick up on that, and hopefully will not be like too confused from the layout of the of that test set and also that you would not disagree too much with the ambition that I have there. So it's, so this is this is technical thing no that me and PERSON9 should discussed. But, like my my idea is that we should have this populated and described by the August date. So that the we can then easily like submit as a deliver. So if the if you want test sets are not part of this yet and I think they should be. so wish put them in, and we should put all the other languages, and and everything. And we should also tested with our pipelines regularly.\n",
      "\n",
      "3 - PERSON8: And the layout for for those who are not following these details these the layout of the test sets is that. It's many documents, and depending on the availablity of the document. Some of the languages are available. Sometimes it's also ASR test set. So, sometimes there is also the speech. Sometimes that just runs quick. Sometimes there is, there is the. Eeeh, that that was PERSON2, sorry. There is another meeting happening and I can't answer him now. So, it is and kind of assorted collection of documents in terms of languages, and like modality the speech, or or the text. And whenever someone wants to test against it. They will select a subset of files which have the require set of languages. So the test sets consists of these raw documents, obviously, curated to to serve well, linebay, segmented, everything. But the actual set of documents that you will test against will depend on the set of languages that you want to test.\n",
      "PERSON8: So the part of this repository is directory of file lists. And these file lists are then the subset of of that.\n",
      "PERSON1: So this is the WMT 20 PROJECT1 test you are talking about, or?\n",
      "PERSON8: This is, this is PROJECT1 test set. Do you see that?\n",
      "PERSON8: So please, this is like the the starting point. And I have PERSON12 PERSON12 just should be really of like of coordinating annotators. The annotators are searching for poll documents and in many of the languages. We've asked that we have to have included more people we have any more people to the language map. And we have short term agreements with them. Unfortunately, PERSON12 is not feeding them with the prepared automatically paralyzed files. so that they would review them, because he is very slow, and he is also not soliciting new links from them. So that is it is. It is a growing much slower than I wanted to. We have enough time for August. But if we were really wanting this for the ORGANIZATION4 Congress we will be in in a bit of trouble.\n",
      "PERSON1: So wa was the August the August just the low deliverable of the year 2 test set, is that right?\n",
      "PERSON1: okay. And these are, okay So these are documents or sentences or speech. It is everything really?\n",
      "PERSON8: It is everything, but if everything is curated. So it is like constraint, when when when finished, they all should be curated for the part particle purpose. So if it's the speech type of test set. It will be the sound, and the transcript with timestamps of individual words. That's what we are trying. We called it forced alignment. Sometimes we have to do it manually because the the the forced alignment automatic one fails. And if it's the machine translation test set then it's the standard poll think, ideally documents. We are trying to have documents, but sometimes it is the line oriented. So it needs to some still some clarification, like how do we like name the files. And then there is the file lists. And ideally, there would be automatic checks so that the everybody could check out this repository and run these checks. And then, with.\n",
      "PERSON8: It would check the number of lines, the the length of the non emptiness, and everything all the format things. And also it would automatically be able to create the file lists. So the file list should be essentially like fine graph. you you for those who like a clever fine graph so that you list all the files, and check that you have all the languages that you want. And with this fine graph the result of the set of files that that you can test on. And that should be stored there as a fixed file list, so then in order to evaluate with the test set you would say I'm for the evaluation I use this particular version of my model, whatever, and I use this commit ID of PROJECT1 test set with this file list. And that uniquely defines what is what is the test set.\n",
      "PERSON8: And obviously, some of these subsets would be like stable ones. So that we we would really have like there could be a file list cord called year 2 SLT test set. And year 2 empty test set and year 2 ASR test set. But that it would gradually grow as we will be covering more and more languages.\n",
      "PERSON8: So it's. It can be seen as an overkill but.\n",
      "PERSON1: And could be so suffered text to text can I do someone like sacrebleu or use well.\n",
      "PERSON8: So this is this defines just the data and not the evaluation metric and that's a separatelly.\n",
      "\n",
      "4 - PERSON1: That, that and some some as a true, but sacrebleu has a way to just yet be a text.\n",
      "PERSON8: So that would be a nice extension of sacrebleu, so that we could like add like FLAC to sacrebleu PROJECT1 test set and then the the file list name, and it would do automatical downloaded and it would put the commit ID the current commit ID into the fingerprint.\n",
      "PERSON1: and I, I have observed that Max apps test sets really quickly to sacrebleu. Okay, whether he was not all test set from PERSON7. I'm not sure.\n",
      "PERSON15: I mean, it's a little.\n",
      "PERSON8: And so so the I think it would be better to kind of avoid forks, because then the versioning is is confused. But I'm totally agree that the public use of these test sets, the should be limited to few of those. And I think that the file list are the concept to use for this. So the the file list, and, that there should be only 3 at most 3 file lists that are interesting for the general public.\n",
      "PERSON8: But we need, whatever we need the particle, computational linguistics domain. We need the auditing domain. We need the text audits versus speech audits domain.\n",
      "PERSON8: So I think that for the for the general public there should be just at most 3 file lists. They could grow in time, the fingerprint would then it clearly indicate which which version was used. And it would be downloadable by sacrebleu automatically. I can't hear you. There u something happen. .\n",
      "PERSON1: That all seems good. Emm, I mean, I mean, the sacrebleu, I mean, I was insane added sacrebleu. I just mean this kind of approach is very useful cause it makes it very easy.\n",
      "PERSON8: So for the evaluation it's for the tool, we're still working on the SLTF, which is a private repository and you can see it, but it will be public wants finally finalize it. And it's it is now under like have it testing for the audible SLT share task evaluation.\n",
      "PERSON8: So, we will know how the various scores behave. And it's this is geared towards the evaluation of spoken language translation, and it has kind of a mode, where it doesn't need a translation. So it's only ASR evaluation. The SLTF, ideally would be the sacrebleu for spoken English translation.\n",
      "PERSON1: okay. I mean that. This is more interesting to me, because mean, essentially, I know I know how to text evaluation marks. And I know that's you just have some test sets you run you run whatever. Spoken language translation is a bit more but nearer to me. And then we have these these problems are and simultaneous translation. , of an effect on the button translation.\n",
      "PERSON13: people I try to reconnecting if you needs.\n",
      "PERSON8: Okay. . PERSON15. , PERSON15 please go on.\n",
      "PERSON15: spoken translation evaluation effect to reward the same unless you need symetrics.\n",
      "PERSON8: We do include latency. So SLTF does include delay and latency and and also the well the wasted effort. So there is two measures of wasted effort.\n",
      "PERSON15: I haven't done that task on IWSLT to you.\n",
      "PERSON15: It was boring thing integrate the model itself to the wrong model and and watch the output or.\n",
      "PERSON8: No it trust it trust the it trust the time stamps given by the participants. And in our case, we actually all we said that the primary evaluation will be the translation quality, and the ASR and translation quality regardless the delaying. So we also have submissions who do not include any time stamps, the the the others. So it is like a secondary thing. It was not not a requirement for the audible SLT task this year. But I can imagine then in the next year, we would maybe even try running the model, so that this is a this is hard to run the models. But maybe we would really force everyone to submit time stamp information.\n",
      "PERSON8: So this is, for us, we need it in any case. So the SLTF should serve us like what is ideal set up. Evaluating latency.\n",
      "PERSON15: I have strong preference not to submit my model to eh\n",
      "PERSON15: To organizers to run it for one, because the unpublished code\n",
      "\n",
      "5 - PERSON15: Because it's python code I have no choice, but to send the actual source code. And yahoo it's not a problem and, I would prefer just send the sour eh the lock file we have to do, because with the something in translation task and probably the SLT and I was not able do that.\n",
      "PERSON1: Okay, but I mean, I mean how else do you. I mean if you want to save varieties these places is cautios so now, do you? How do you set this up?\n",
      "PERSON15: I mean, so used that's for lock former time stamps.\n",
      "PERSON8: Yes, this is exactly what we did for these for desirability to tasks it. It is quite clear, this cries what the lock file shouldn't lying.\n",
      "PERSON8: And then you trust the the participants.\n",
      "PERSON8: And there could be many lay. So this is all is risky with the lock files, because people still can misinterpret what time stamps should they use. So we try to be very clear about like this is the time when the the award was starting to be authored. This is the time when the word stopped to be authored. And this is the time when its ASR was available like printed on the screen for the user. And this is the time when the translation appeared on screen for the user. But people can misinterpret and also the the forced alignment that we're running. Eh, so so the so the the one people misinterpret it then someone's results can be like shifted in bad ways. So these measures will be always on the reliable, the only way to to do the comparison really fairly is to run the models or a serve the model.\n",
      "PERSON8: So that people with really live, receive the the sound, and they would like in in in actual networks sockets provide the the outputs. So this would be the only reliable way to to measure that. The the extra thing that I wanted to mention is that the forced alignment, which finds the words in the in the sound is not reliable for us either. So sometimes it is really shifted. Sometimes it is towards the ends of the word. Sometimes it is toward the beginning of the words. It's in your own network model that like attention somewhat flows. It's not attention but it still somewhat floats, floats around. And the the the only thing that the one can say to this is the this at least affects everybody the same way. When people misinterpret what the locks should be. Then everybody's like each party is affected in a different way, and that's bad for the for the evaluation.\n",
      "PERSON8: But I think that's like that just life. So I think it is, it is quite easy to proceed with a with these limitations and what the set up. So so the so ORGANIZATION1 people please review the PROJECT1 test set, as I set it up and please contribute to it in any possible way. You remember that some at the several months ago of of I suggested that you can ask your students and and PERSON10 said that well we cannot expect volunteers eeh possibly paid volunteers or nonpaid volunteers that that makes some different, but not to it to to just do slavery task on the data. Maybe you can find someone who can do it if you can paid them. That's okay, I'm not curious.\n",
      "PERSON1: Sorry just reminded the task is what? One is cur is checking the translations are making translations or?\n",
      "PERSON8: We do both. So.\n",
      "PERSON8: So well, we we plan to do both we. We try to, find, and the and the revised translations.\n",
      "PERSON8: And and this, if I was correct PERSON11 I do not know whether you have double checked my numbers. But it turns, it seems that finding and curating is half the price when we pay what we pay to our annotators normally compared to like the professional translation. So there is some reduction of costs but is. It's not like it doesn't come for free anyway.\n",
      "PERSON8: One could, one could. , it is war. And one one could just trust the automatic processing and maybe use some quality automatic quality measures. So one could could cut it down further. But for now, I prefer, especially because is this kind of obscure languages. I prefer to find people who actually speak them, and I preferred them to to find the related data sets. But if we are unable to to find speech domain and auditing domain. Then indeed, we will ask the people to find these text monolingually and translated maybe back to Czech. So do manual back translation to Czech. This is the the wrong direction of translation. But it's the it's more reliable with respect the domain of interest.\n",
      "\n",
      "6 - PERSON1: In in terms of finding the translation I mean we and PERSON9 maybe can comment. We made some progress in getting translations out of the auditing websites, ehmm.\n",
      "PERSON1: And that if that is what we are looking for pro tests about is nonspeech segments, that some text insistent. This is that.\n",
      "PERSON8: So this is relevant. And this is this is what we really should do. the current people, those that we have have just like signed up work agreements, the short term contracts with, our four languages, which are not well represented there, so far. But we also want to do it for the well represented languages, because we should we should cover them as well. So so PERSON12 sh PERSON12 has, for example, link to one great site of of speeches and he should run by textor and they and he.\n",
      "PERSON1: We can also work on this and for a lot of Irish state. If you are under represent to languages.\n",
      "PERSON1: The Irish supreme auditor, apparently translates lot everything into Irish.\n",
      "PERSON1: And doesn't very. It wasn't very structured way wasn't it though?\n",
      "PERSON16: we got, ehm, what was it? And ten tens of thousands of sentences I think. .\n",
      "PERSON1: We assume that Irish was not huge priority for the project But.\n",
      "PERSON8: Well, Irish is equally equal priority with as other languages.\n",
      "PERSON8: well, the project was started when the EU still existed. So we will see what happened.\n",
      "PERSON11: Okay, there is one more point and we promised half hour call so.\n",
      "PERSON8: Yes, with this is that the finishes, the set of feel free to step in, and whatever you can do for PERSON12 that will help us then the next person when PERSON12 is still not like woken up is PERSON6 who is now finishing the overview of the audible SLT test set. And he will be moving to to to these like supervision and managing the the annotators for the PROJECT1 test set if if PERSON12 doesn't start really. And, but feel free to step in and provide feedback on the layout, upload data sets everything. So let's let's get this grow. And if we if we do this over the following couple of weeks. Then and if we test with these test sets then it will be very easy to do the deliverable for August. . And the last point now, that's the demo. So here I would I was I was hoping that PERSON13 would would reconnect by this time.\n",
      "PERSON8: And yes maybe he is here. I'm not sure.\n",
      "PERSON13: Yes I'm here.\n",
      "PERSON8: So would it be possible that that ORGANIZATION5 would would like manage and make sure that this demo is delivered? As as the integration part. Obviously, like it's we will be PERSON2 will be running the systems. But I I need someone to to make sure that these things happen. Because I'm like overloaded and you're the integration partner. So that's that's the the general question at the beginning. And maybe let's wait with the answer until I tell you whatever we know about this. there is no particular requests for the scenario. As far as I know PERSON5 has just answered and they have also provided some feedback and that's interesting for everybody. So they've they've reminded us off BBC guidelines and standards for subtitling, which we are aware off, but they are not reflected in our systems in in any way. And then the better captioning or as spoken text translation ehm on screen will make better translation and readability, recomposing sentence on the fly my ethic liability.\n",
      "PERSON8: So so in a sense this is not the first time I hear that the users are always afraid of what ORGANIZATION7 worked on for for the past years. So ORGANIZATION7 has been working on this retranslation approach. And the users seem to, to prefer a delay. , okay, so so maybe maybe ORGANIZATION7 has already experience with defending their approach to the users. I keep.\n",
      "PERSON1: This is the segmentation as opposed to the, you mean, the segmentation and\n",
      "PERSON15: ASR have focused on resending.\n",
      "PERSON1: Ahh, okay, the retranslation, right.\n",
      "PERSON8: The retranslation, yes. I think the users are afraid of retranslation because we were not able to hide it sufficiently. If we are able to make the retranslation stable. Then the users will not complain.\n",
      "\n",
      "7 - PERSON1: I mean, we've been playing with this and we can certainly improve the stability. I mean we only tested this simulator ASR which talking this morning about trying to get more testing the ASR. , if you're doing retranslation you're never going to be up to completely make it stable without actually messing up the end performs. It's sort of a trade off.\n",
      "PERSON8: it is a it is a trade off. So. I think that in the long term I would like this to be evaluated on humans towards the end of the project we we we would really have like user study that would be great to to see which, and I think there will be people of different groups. Some will prefer this some will prefer that\n",
      "PERSON1: Should be do this at the end or should be do this a bit sooner?\n",
      "PERSON8: Any time we have the time for that.\n",
      "PERSON1: Okay. Well, I mean it it's a question that's it's a question of making the time. I mean, it's whether we see it as a priority or not.\n",
      "PERSON8: So it's that's a good idea. So we're now in the, in which of the project, it's where in the middle of the project, right.\n",
      "PERSON1: I mean immediately end and say ou, we should retranslations a terrible idea. We should do less of it or we get the end and say retranslations is briliant. We should, you know, when you care about this. We we probably are not learn up before the end.\n",
      "PERSON1: But I agree that way we for this. And I do not know.\n",
      "PERSON15: Well, okay. So little bit respect on this, I'm not an ASR person so probably PERSON9 could more about this. But it's entirely possible that retranslation go go back a lot with the transition to endtoend ASR.\n",
      "PERSON15: Because of course the the unstable have are based on which our research. Multiplies already to the high get models. So it's entirely possible that pressure answer. So because we decided to go to the end the data.\n",
      "PERSON1: That you still have. We would still have instability. The MT is all also gonna inject instability, isn't it.\n",
      "PERSON15: No. The MT only translate will be get from ASR. Like every hand is also changes, we have changes otherwise that we have.\n",
      "PERSON1: so that injects instability. So the MT.\n",
      "PERSON15: If there are no updated ASR hypothesis then they MT hypothesis.\n",
      "PERSON1: Okay, so if the ASR wait to the end of the sentence before sending his hypothesis. Then obviously this know instability.\n",
      "PERSON15: That's probably just going to get better as we train models in fact. We have lot.\n",
      "PERSON15: We will have our new generation of eh models previously based transformers finally in direct translator. And so far the experience from actual lectures is that there is a big improvement.\n",
      "PERSON8: Still I underst.\n",
      "PERSON15: And this is how much improvements is for flickering and every translation support generally, the quality is.\n",
      "PERSON8: Sorry, sorry. Go on. So I was I was double checking. PERSON15, you were saying that with the in the endtoend SLT which includes transform models now in the new generation. There is, no, no.\n",
      "PERSON8: Okay, no internal SLT. , okay.\n",
      "PERSON1: And endtoend ASR. I think he means.\n",
      "PERSON8: Okay, endtoend ASR. So, endtoend ASR there is no partial sentences admitted. It would be only complete sentences admitted. Is that what you say?\n",
      "PERSON15: because that's not my field. I think there is a lot of research right now.\n",
      "PERSON15: Oh, I'm sorry. There is research going on right now. How to low latency, and when they ASR and right now. We do get a partial sentences, but I don't think the hypothesis updated as much.\n",
      "PERSON1: So they don't change, but they still extend. You know it doesn't rewrite extends.\n",
      "PERSON1: But even even extending could still could still lead flickering the MT it's like you listen to German. If you listen to German, you don't know what the verb it so you make prediction and reproduction wrong. German to English say, you don't know the verb is in the sentence predictor wrongly, or you could just wait, but maybe that's bad to.\n",
      "\n",
      "8 - PERSON8: Exactly. So this is, I think the the problem with the integration of the ASR and MT will remain even once the, the new generation of the ASR models is is there. And there will be the question for the users whether they preferred to wait for the German verb, or guess and put there some English verb. So there there would be a trade off like what and what confidence should I insert the verb and then maybe recovery. I'm sure that there is also ways in English in which you can still.\n",
      "PERSON1: you can find examples and languages and say.\n",
      "PERSON8: No, no, no. I mean, that you could recover from that\n",
      "PERSON8: To preserve the stability and reintroduce some kind of correction.\n",
      "PERSON1: So why I wonder this when you could to look what interpreters do. Cause they just have strategies for doing this, the massive strategies where they serve formulate the the speech and serve wheter the is open, but I don't know the computation like. And then there is the other aspect, which I think will be trouble for us. Like the system, even guess is what people are gonna to say, and translates sooner. And sometimes you can because you know the. So where is he asked for other word words. Sometimes You can guess to 90 percent. Yet should you do that? Because you may have maybe wrong.\n",
      "PERSON8: So this is. We are trying to run GPT tool to predict the tail of the sentence.\n",
      "PERSON8: But it so far. It's like, the ASR so bad that that the prediction is like totally off, and so far it doesn't work at all, but but we are trying this guessing. So maybe I think it totally makes sense to do this guesses. That's what the interpreters do. And that's a question whether we will be able to do it well enough and half a good enough confidence eh explicitely in the models to make the decision, whether we should follow this guess or not.\n",
      "PERSON8: Okay. So back back to the demo.\n",
      "PERSON8: So the demo. The date should be. Where was that idealy May? 14th May 17th the sooner the better. And there eh is there is all this, all these recommendations for all the partners and their systems. But I think we should. There is no way to touch up on these topics before the demo. So my question back to PERSON13. Would could you, could ORGANIZATION5 supervise the the organization of the of the demo? Obviously, asking all the partners to have their systems ready. And and all that, but like doing the communication, so that that eh successfully. That that we delivered demo.\n",
      "PERSON13: So we can. It's important is 17 than 4.\n",
      "PERSON8: Say it again, it's a.\n",
      "PERSON13: I mean it's important it's not a. Because it's too\n",
      "PERSON8: so they said, they said sooner is better. So maybe maybe the best option send, so did closer to sending. So could it be like the 8th the so 11th seems like the average.\n",
      "PERSON13: We learn about quit couple of proposal in the.\n",
      "PERSON8: Maybe, maybe, so actually it won't be better if you could even create the Doodle Poll with time slots already for PERSON5. And directly con PERSON5. So like these are the time slots, which we are like offering. And then, well for all the partners it should be. .\n",
      "PERSON13: I think it's better if we post the final this proposal informaly as a Doodle and then ask PERSON5.\n",
      "PERSON13: So we will, we will learn set up the Doodle, send it to in both partners. Then then once agree share with.\n",
      "PERSON8: And also propose what you prefer to demo because there is. You send, you have seen the email. I've sent a couple of a like a recorded demo most to PERSON5 and propose, and something specific. It's up to us. So well, decide.\n",
      "PERSON4: I saw the demo you send project officer and she mostly seen the Monday seminary, em.\n",
      "PERSON8: You mean the Czech talk, right?\n",
      "\n",
      "9 - PERSON4: I, think that probably we if you would like to present to the same thing we should then everything right now put the same set up without the. It's also well tested by you. So it will be probably the safe solution. Might just, my only worry is about how to presents the results to the project officier. Because actually during the demo you project both the ORGANIZATION2 representation and the sub ORGANIZATION5 subtitles. In the future of the page on the projector in the class. And we will not vote to presente the same thing online to the project officer. Because actually are two different web pages, it's completly different.\n",
      "PERSON8: So what we can do is like screen sharing and screen a broadcasting.\n",
      "PERSON4: Ah, okay. It works.\n",
      "PERSON8: That is that is an option. And and a question is, what should be the material that we are that we are subtitling.\n",
      "PERSON8: I think it could be some low like French watching session.\n",
      "PERSON4: Yes to the ASR domains.\n",
      "PERSON1: That was quite challenging.\n",
      "PERSON1: I'm not worrying about this, they have the same process on subtitling. And not really doing subtitling at the moment, we are doing transcription and translation, which is not subtitling by some kind of summarization. Sometimes. Which we won't do. It just about managing expectations.\n",
      "PERSON8: That's true. So the translation, transcription and translation. And in that case, that's the paragraph you, which we can include in the demo as well. So I think the demo should demo both.\n",
      "PERSON1: Hm. I think the idea screenshare is a good one. Just takes away one indicate.\n",
      "PERSON8: But the the live aspect there. So what the, what was the challenge on the French watching session that we didn't understand the source language.\n",
      "PERSON1: we didn't, to be honest, someone PERSON4 understood. What what the topic was. And you didn't really understand, and I didn't. You talk about the item, didn't. Understand so well, I have trouble with with it as well. So it was quite hard to follow have to met.\n",
      "PERSON8: So that's that's a safer way of selling what we are doing. I've already\n",
      "PERSON1: Some like a TED talk suppose might be. Little bit to save, is it?\n",
      "PERSON8: No, no, It's not necessary to save. So it could be authentic stock, or something like that, so that it's not delivered in English, the prime language. So maybe if the primer language would be German, because ORGANIZATION7 has good models for this. And from German into English and from English into all the languages, TEDx talk.\n",
      "PERSON1: Is the audio gonna be easier and gonna be clearer than news broadcast is gonna be easier for ASR.\n",
      "PERSON8: I think that the segmentation would be a little bit easier. But, Well, I don't know. Sentence segmentation. So what so far in our experiments what kills the performance for the final user of the machine translation is the sentence segmentation.\n",
      "PERSON15: we have new models now as well.\n",
      "PERSON1: Is it just cause sent me I mean because fundamentally sentiments segmentation is really hard, because people just you're trying compose compose something that is not really there cause I'm not speaking in sentences.\n",
      "PERSON8: I think that many of the. There are many errors. So yes, there is this hard concept. But still, there there are many cases where I would simply nowhere to put the full stop. And the system does not put it there.\n",
      "PERSON1: Okay. So it is about partly by having better models.\n",
      "PERSON8: So maybe maybe PERSON15 he could propose some German talks that are, on this and we we should test the whole set up via English into all the languages.\n",
      "PERSON15: Yes,m. I can do that in next week, I can't that this week.\n",
      "PERSON8: Say it again. It will be when?\n",
      "PERSON15: It will be next week.\n",
      "PERSON8: Yes So. So the communication about the the day should be already like that to start internally immediately. Then early next week, we should sent an email to the PERSON5 to truce, his date. And that would be towards the end of the the next week, we should be ready for that. And in the week from the 11th, the sooner the better. We should run it life for them. And before that we should run it for ourselves, right?\n",
      "\n",
      "10 - PERSON8: Okay so. Sorry for not managing the the half an hour. Thanks for joining, and will be in very close touch for for the demo in the coming days.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# OVERVIEW THE SECTIONED BLOCKS OF CONVERSATIONS FROM THE TRANSCRIPT ...\n",
    "for idx, i in enumerate(tscs_preprocessed_short[m_id]):\n",
    "  print(f\"{idx} - {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1682547780955,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "nmVyodp41J9j",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### USEFUL UTIL FUNCTIONS FOR GENERATION AND FORMATTING ###\n",
    "def summarize(tsc):\n",
    "  a1 = summarizer(tsc)[0]['summary_text']\n",
    "  return a1\n",
    "\n",
    "def format_summary_with_pronouns(s2):\n",
    "  s3 = ''.join(s2) #s2[0]\n",
    "\n",
    "  s3 = s3.split('.')\n",
    "  summ = ['']\n",
    "  id=0\n",
    "  summ1 = []\n",
    "  for i in s3:\n",
    "    #stripping the spaces\n",
    "    i = i.replace('  ', ' ')\n",
    "    if len(i) == 1:\n",
    "      continue\n",
    "    if i[0]==' ' and i[1].isalpha():\n",
    "      i = stripp(i)\n",
    "    if type(i) == type(None):\n",
    "      continue\n",
    "    if i[0] == ' ':\n",
    "      continue\n",
    "    i = preprocess(i)\n",
    "    check = re.sub(r\"[^a-zA-Z0-9]+\", ' ', i)\n",
    "    check = ''.join(i for i in check if not i.isdigit())\n",
    "    check = check.replace('  ', ' ')\n",
    "    check = check.split(' ')\n",
    "    if len(check)<=6:\n",
    "      continue\n",
    "\n",
    "    #formatting\n",
    "    if i[0] == 'P' and i[1] == 'E':\n",
    "      summ1.append('-' + i + '.')\n",
    "    # elif i[0] in ['M','T','O','A'] and (i[1].isalpha()==False):\n",
    "    #   id+=1\n",
    "    #   summ.append('')\n",
    "    #   summ[id] = summ[id] + ' -' + i + '.'\n",
    "    # elif i[0]=='M' and i[1]=='U':\n",
    "    #   id+=1\n",
    "    #   summ.append('')\n",
    "    #   summ[id] = summ[id] + ' -' + i + '.'\n",
    "    else:\n",
    "      summ1.append(i + '.')\n",
    "\n",
    "  summ1 = insert_pronouns(summ1)\n",
    "  for i in summ1:\n",
    "    if i[1] == 'P' and i[2] == 'E':\n",
    "      id+=1\n",
    "      summ.append('')\n",
    "      summ[id] = summ[id] + ' ' + i\n",
    "    else:\n",
    "      summ[id] = summ[id] + '\\n  ' + i\n",
    "\n",
    "  if '' in summ:\n",
    "    summ.remove('')\n",
    "  summ = '\\n'.join(summ)\n",
    "  return summ\n",
    "\n",
    "### A FORMAT SUMMARY FUNCTION, WITHOUT PRONOUN INSERTION ###\n",
    "def format_summary_without_pronouns(s2):\n",
    "  s3 = ''.join(s2) #s2[0]\n",
    "\n",
    "  s3 = s3.split('.')\n",
    "  summ = ['']\n",
    "  id=0\n",
    "\n",
    "  for i in s3:\n",
    "    #stripping the spaces\n",
    "    i = i.replace('  ', ' ')\n",
    "    if len(i) == 1:\n",
    "      continue\n",
    "    if i[0]==' ' and i[1].isalpha():\n",
    "      i = stripp(i)\n",
    "    if type(i) == type(None):\n",
    "      continue\n",
    "    if i[0] == ' ':\n",
    "      continue\n",
    "    i = preprocess(i)\n",
    "    check = re.sub(r\"[^a-zA-Z0-9]+\", ' ', i)\n",
    "    check = ''.join(i for i in check if not i.isdigit())\n",
    "    check = check.replace('  ', ' ')\n",
    "    check = check.split(' ')\n",
    "    if len(check)<=6:\n",
    "      continue\n",
    "\n",
    "    #formatting\n",
    "    if i[0] == 'P' and i[1] == 'E':\n",
    "      id+=1\n",
    "      summ.append('')\n",
    "      summ[id] = summ[id] + ' -' + i + '.'\n",
    "    # elif i[0] in ['M','T','O','A'] and (i[1].isalpha()==False):\n",
    "    #   id+=1\n",
    "    #   summ.append('')\n",
    "    #   summ[id] = summ[id] + ' -' + i + '.'\n",
    "    # elif i[0]=='M' and i[1]=='U':\n",
    "    #   id+=1\n",
    "    #   summ.append('')\n",
    "    #   summ[id] = summ[id] + ' -' + i + '.'\n",
    "    else:\n",
    "      summ[id] = summ[id] + '\\n  ' + i + '.'\n",
    "\n",
    "  if '' in summ:\n",
    "    summ.remove('')\n",
    "  summ = '\\n'.join(summ)\n",
    "  return summ\n",
    "\n",
    "def insert_pronouns(summ1):\n",
    "  len_sum = len(summ1)\n",
    "  for line_no, i in enumerate(summ1):\n",
    "    if '-' in i:\n",
    "      if len_sum-line_no <= 3:\n",
    "        rng = len_sum-line_no-1\n",
    "      else:\n",
    "        rng = 3\n",
    "      for k1 in range(rng):\n",
    "        st1, st2 = check_req(i, summ1[line_no+k1+1])\n",
    "        if st1:\n",
    "          summ1[line_no+k1+1] = summ1[line_no+k1+1].replace(st1, 'They')\n",
    "          summ1[line_no+k1+1] = summ1[line_no+k1+1].replace(\"They's\", 'Their')\n",
    "          summ1[line_no+k1+1] = summ1[line_no+k1+1].replace(\"They is\", 'They are')\n",
    "          summ1[line_no+k1+1] = summ1[line_no+k1+1].replace(\"They is\", 'They are')\n",
    "          summ1[line_no+k1+1] = summ1[line_no+k1+1].replace(\"They has\", 'They have')\n",
    "          summ1[line_no+k1+1] = summ1[line_no+k1+1].replace(\"They wants\", 'They want')\n",
    "  return summ1\n",
    "\n",
    "def check_req(line1, line2):\n",
    "  if ('-' in line1) and ('-' in line2):\n",
    "    st1 = ''\n",
    "    st2 = ''\n",
    "    for _ in range(8):\n",
    "      st1+=line1[_]\n",
    "      st2+=line2[_]\n",
    "    if st1 == st2:\n",
    "      if line1[_+1] == line2[_+1]:\n",
    "        if line1[_+1]==' ':\n",
    "          st3 = st1\n",
    "          st4 = st2\n",
    "        elif line1[_+1]==',':\n",
    "          st3 = False\n",
    "          st4 = False\n",
    "        else:\n",
    "          st3 = st1+line1[_+1]\n",
    "          st4 = st2+line2[_+1]\n",
    "      else:\n",
    "        if line1[_+1]==\"'\" or line2[_+1]==\"'\":\n",
    "          st3 = st1\n",
    "          st4 = st2\n",
    "        else:\n",
    "          st3 = False\n",
    "          st4 = False\n",
    "    else:\n",
    "      st3 = False\n",
    "      st4 = False\n",
    "  else:\n",
    "    st3 = False\n",
    "    st4 = False\n",
    "\n",
    "  return st3, st4\n",
    "\n",
    "def gen_summaries(tscs_preprocessed):\n",
    "  summaries = {}\n",
    "\n",
    "  for k, v in tscs_preprocessed.items():\n",
    "    if len(v) < 11:\n",
    "      section = 2\n",
    "    elif len(v) < 18:\n",
    "      section = 4\n",
    "    elif len(v) < 24:\n",
    "      section = 6\n",
    "    else:\n",
    "      section = 8\n",
    "    s1 = ['']\n",
    "    tsc = v\n",
    "    id=0\n",
    "    for i, t1 in enumerate(tsc):\n",
    "      a1 = summarize(t1)\n",
    "      s1[id] = s1[id] + a1 + ' '\n",
    "      if i%section==0:\n",
    "        s1.append('')\n",
    "        id+=1\n",
    "\n",
    "    summaries[k] = s1\n",
    "\n",
    "  return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21653,
     "status": "ok",
     "timestamp": 1682547807610,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "FQcS-1NADjYw",
    "outputId": "1216b93b-06dc-466b-82be-93a4bef77c3a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 62, but you input_length is only 39. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=19)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  The Czech Republic government has lifted the rules.\n",
      "  People can go out even if they don't need to, but they have to wait until June for the free circulation of people.\n",
      " -PERSON4 lives in Trento and his family lives in Bolz PERSON1, PERSON8, PERSON11, PERSON13 and PERSON13 will write a project management guide for Organization 5.\n",
      "  Organization 5 is developing their own systems in this area.\n",
      "  Organization 3 is doing the dissemination on the web.\n",
      "  Organization 1 is not keen on reading the guide PERSON11 will write something and someone will review it.\n",
      "  The project management guides should be ready by the end of June at the latest and the internal reviews should be tested by mid June, so that they have two weeks to finish that.\n",
      " -PERSON8 has started the PROJECT1 test sets PERSON8 explains to PERSON1 and PERSON2 the layout of the test sets.\n",
      " -PERSON1, PERSON8, PERSON15 and PERSON13 worked on a project to develop a test set for spoken English translation.\n",
      "  The test set should be limited to 3 file lists for the general public.\n",
      " -PERSON15 has to send the source code of the task to the Organization 1.\n",
      " -PERSON8 asks Organization 1 to review the PROJECT1 test set and contribute to it.\n",
      " -PERSON1, PERSON8, PERSON12, PERSON13, PERSON5 and PERSON11 worked on a project.\n",
      "  The project was started when the EU still existed, so they will see what happened.\n",
      " -PERSON1, PERSON8 and PERSON15 want to improve the stability of the ASR.\n",
      " -PERSON1 is not an ASR person, so he doesn't know if it's a good idea to do it at the end of the project.\n",
      " -PERSON8 and PERSON13 worked on the integration of the ASR and MT models.\n",
      "  They are trying to run GPT tool to predict the tail of the sentence, but it doesn't work very well.\n",
      "  The date for the demo is 14th May 17th.\n",
      "  Organization 5 PERSON4, PERSON8, PERSON1, PERSON15 and PERSON8 discussed how to present the results of the demo to the project officer.\n",
      " -PERSON8 is sorry for not managing the half an hour.\n",
      "  He will be in touch for the demo in the coming days.\n"
     ]
    }
   ],
   "source": [
    "### THE BELOW 4 CELLS WOULD GIVE YOU 4 SUMMARIES VARYING IN LENGTH; ###\n",
    "### THIS WOULD NORMALLY AFFECT THE COVERAGE AND ADEQUACY OF THE SUMMARIES; ###\n",
    "### YOU CAN CHOOSE A SUITABLE SUMMARY FOR EVERY SINGLE TRANSCRIPT !!! ###\n",
    "\n",
    "s2_short = gen_summaries(tscs_preprocessed_short)\n",
    "print(format_summary_without_pronouns(s2_short[m_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25506,
     "status": "ok",
     "timestamp": 1682547833112,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "UncQ_DOw5LGO",
    "outputId": "81380890-f833-4571-a757-26cc777f1346"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  The Czech Republic government has lifted the rules.\n",
      "  They can go out even if they don't need to, but they have to wait until June for the free circulation of people.\n",
      " -PERSON4 lives in Trento and his family lives in PERSON11, PERSON7, PERSON1, PERSON8, PERSON13 and PERSON16 will postpone one of their regular meetings to September.\n",
      "  They have a couple of deliverables due in June.\n",
      "  They haven't decided who will be their internal review person for any of them.\n",
      " -PERSON11 is writing a project management guide for Organization 3 and Organization 1.\n",
      "  There is no description of the deliverable and there are no project management guides.\n",
      "  Organization 1 has coordinated a number of projects.\n",
      "  Organization 3 has period reports and data management plans.\n",
      "  Organization 2 has project reports and PERSON11 will write something and someone will review it.\n",
      "  The internal reviews should be ready by mid June at the latest.\n",
      "  The deliverables will be due in the end of August.\n",
      "  The Congress will take place in December.\n",
      " -PERSON8 has started the PROJECT1 test set.\n",
      "  He wants to have it populated and described by the August date so that the project can be ready to submit as a deliver.\n",
      "  It's a collection of documents in various languages.\n",
      "  The annotators are searching for poll documents and in PERSON8, PERSON15 and PERSON1 agree that the public use of the test sets should be limited to few of those.\n",
      " -PERSON8 worked on a tool for the evaluation of spoken language translation.\n",
      " -PERSON15 has to send the source code for the translation task.\n",
      "  People can misinterpret the time stamps used for the lock files and the forced alignment of the translations is not reliable for the participants.\n",
      "  People's results can be shifted in bad ways.\n",
      "  People need to PERSON8, PERSON11, PERSON1 and PERSON9 discusseded the costs of finding and curating.\n",
      "  The project was started when the EU still existed.\n",
      "  The current people that work for the project have just signed up work agreements and short-term contracts with, their four languages.\n",
      " -PERSON6 is finishing the overview of the audible SLT test set.\n",
      " -PERSON13 is waiting for PERSON12 to start working on the project.\n",
      "  Organization 7 has been working on a retranslation approach for the past years.\n",
      "  Organization 5 has just answered PERSON8 would like the project to be evaluated on humans towards the end of the project.\n",
      " -PERSON1 and PERSON15 think it's a good idea to go to the end the data.\n",
      "  The endtoend ASR translation is unstable, because it injects instability into the data There is research going on how to low-latency ASR and MT.\n",
      "  There is a problem with the ASR when the new generation of ASR models is there.\n",
      "  People are trying to run a GPT tool to predict the tail of the sentence, but it doesn't work PERSON13, PERSON8 and PERSON1 will present their proposal to the project officer.\n",
      "  They will create a Doodle and send it to both partners.\n",
      "  The demo should demo both the ORGANIZATION2 representation and the sub Organization's subtitles.\n",
      " -PERSON1, PERSON4 and PERSON8 didn't understand the topic they were talking about.\n",
      " -PERSON15 will propose some German talks as a primer language and they will test the whole set up via English into all the languages next week.\n"
     ]
    }
   ],
   "source": [
    "s2_avg = gen_summaries(tscs_preprocessed_avg)\n",
    "print(format_summary_without_pronouns(s2_avg[m_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34692,
     "status": "ok",
     "timestamp": 1682547867797,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "9fxfDgkJ0PKN",
    "outputId": "8ce4b05f-46e2-414a-b93d-e1533d9fdb65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  The Czech Republic government has lifted the rules.\n",
      "  People can go out even if they don't need to.\n",
      "  People in LOCATION1 are allowed to meet up to 10 people.\n",
      "  People living in Trento and Bolzano are able to meet their families starting PERSON11 will postpone one of their regular meetings in September.\n",
      "  There will be two more meetings in May and one in June.\n",
      "  There are six deliverables due in June, one of them technical.\n",
      "  Organized 1 is not providing ASR system, so it will be good PERSON16 will do the summarization of the review.\n",
      " -PERSON8, PERSON1, PERSON11, PERSON13 and PERSON3 will be the reviewers.\n",
      " -PERSON11 is writing a project management guide for a new project.\n",
      "  There is no description of the deliverable and there is no czech management guide.\n",
      "  Organization 1 is in the best position to write it as they have coordinated a number of projects.\n",
      "  Organization 2 is not keen on reading PERSON1 will write something and someone will review it.\n",
      "  The internal reviews should be ready by mid June at the latest, so that they have two weeks to finish that.\n",
      "  QT21 doesn't have the project management guides.\n",
      "  They have this period reports and data management plans, but PERSON8 and PERSON9 will discussed the delivery of the PROJECT1 test sets.\n",
      "  They need to be populated and described by August.\n",
      " -PERSON8 explains to PERSON1 and PERSON2 the layout of the WMT 20 PROJECT1 test set.\n",
      "  It's a collection of documents and depending on the availablity of the document, some of the languages are available, others are not.\n",
      "  The set of documents PERSON8 explains to PERSON1 what a proper test set should be and how it should be organized.\n",
      " -PERSON8 and PERSON1 want to limit the public use of the test sets to 3 at most 3 file lists for the general public.\n",
      " -PERSON8 explains the evaluation of spoken language translation to PERSON1, PERSON15 and PERSON13.\n",
      " -PERSON15 has to send the lock file with the source code.\n",
      "  People can misinterpret the time stamps and the forced alignment that they are running.\n",
      " -PERSON8 asks Organization 1 to review the PROJECT1 test set and contribute to it in any way.\n",
      "  Organization 1 agrees to do both the translation and curating of the data.\n",
      " -PERSON1 and PERSON9 made some progress in getting translations out of the auditing websites.\n",
      "  The project was started when the EU still existed.\n",
      " -PERSON6 is finishing the overview of the audible SLT test set.\n",
      "  If PERSON12 doesn't start really, then PERSON6 will take over.\n",
      " -PERSON5 has just answered and they have provided some feedback.\n",
      "  The users are afraid of the retranslation approach of Organization 7.\n",
      "  Organization 7 has been working on it for the past years, but the users prefer a delay.\n",
      "  Organisation 7 wants to do a user study at the end of the project.\n",
      " -PERSON1, PERSON9 and PERSON15 are arguing about the pros and cons of retranslating data.\n",
      " -PERSON1 thinks it's a bad idea to retranslate.\n",
      " -PERSON15 thinks it will be better as they train models in direct translators.\n",
      " -PERSON15 is not interested in endtoend ASR.\n",
      " -PERSON1 is interested in low-latency ASR and PERSON8 in the new generation of ASR models.\n",
      " -PERSON8 is trying to run GPT tool to predict the tail of the sentence, but it doesn't work at all.\n",
      "  The date for the demo should be 14th May 17th the sooner the better, but there is no way to touch up the topics before the demo.\n",
      " -PERSON13, PERSON8 and PERSON4 will set up the Doodle, send it to in both partners.\n",
      " -PERSON1 is not worried about how to present the results to the project officer.\n",
      " -PERSON1, PERSON8 and PERSON4 didn't understand the source language during the French watching session.\n",
      "  The sentence segmentation is a problem with the machine translation.\n",
      "  They will test the set up via English into all the languages.\n",
      " -PERSON8 and PERSON15 will send an e-mail to the PERSON5 about the date of the demo towards the end of the week from the 11th.\n"
     ]
    }
   ],
   "source": [
    "s2_long = gen_summaries(tscs_preprocessed_long)\n",
    "print(format_summary_without_pronouns(s2_long[m_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"PERSON11 is going to postpone one of their regular meetings in September. There will be two more meetings in May and one in June. There are six deliverables due in June, one of them technical. Organized 1 is not providing ASR system, so it will be good PERSON16 will do the summarization of the review. PERSON8, PERSON1, PERSON11, PERSON13 and PERSON3 will be the reviewers.  PERSON11 is writing a project management guide for a new project. There is no description of the deliverable and there is no czech management guide. Organization 1 is in the best position to write it as they have coordinated a number of projects. Organization 2 is not keen on reading PERSON1 will write something and someone will review it. The internal reviews should be ready by mid June at the latest, so that they have two weeks to finish that. QT21 doesn't have the project management guides. They have this period reports and data management plans, but PERSON8 and PERSON9 are going to discuss the delivery of the PROJECT1 test sets. They need to be populated and described by August. PERSON8 explains to PERSON1 and PERSON2 the layout of the WMT 20 PROJECT1 test set. It's a collection of documents and depending on the availablity of the document, some of the languages are available, others are not. The set of documents \""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2_long[m_id][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oWS4uhFM5mFl",
    "outputId": "37f69110-46a6-44e5-a285-d6366c2bd776",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# If we want to further shorten the obtained summary...\n",
    "This method sacrifices gramaticality and readbility, in order to achieve compactness, by using NLTK stopword reduction over a general BART Summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1682547880165,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "iTle3n8Bo-Za",
    "outputId": "43864e1e-951f-45fa-869a-ad8ea55e4ad1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/kristyna/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/kristyna/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 1345,
     "status": "ok",
     "timestamp": 1682547881508,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "BhlbYAFro-Zb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# RUN THE CELLS BELOW AND USE THIS FUNCTION INSTEAD OF THE 'format_summary()' version ...\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def shorten(example_sent):\n",
    "  stop_words = set(stopwords.words('english'))\n",
    "  stop_words.remove('to')\n",
    "  stop_words.remove('of')\n",
    "  stop_words.remove('from')\n",
    "  stop_words.remove('as')\n",
    "  stop_words.remove('has')\n",
    "  stop_words.remove('do')\n",
    "  stop_words.remove('not')\n",
    "  #stop_words.remove('be')\n",
    "  stop_words.remove('on')\n",
    "  stop_words.remove('in')\n",
    "  stop_words.remove('if')\n",
    "  stop_words.remove('is')\n",
    "  stop_words.remove('it')\n",
    "  stop_words.remove('for')\n",
    "  stop_words.remove('with')\n",
    "  stop_words.remove('he')\n",
    "  stop_words.remove('can')\n",
    "  stop_words.remove('does')\n",
    "  stop_words.remove('between')\n",
    "  stop_words.add('They')\n",
    "  stop_words.add('which')\n",
    "  stop_words.add('On')\n",
    "  stop_words.add('It')\n",
    "  stop_words.add('The')\n",
    "  stop_words.remove('over')\n",
    "  stop_words.remove('until')\n",
    "  stop_words.remove('after')\n",
    "  stop_words.add('He')\n",
    "  stop_words.remove('when')\n",
    "  stop_words.remove('have')\n",
    "  stop_words.remove('them')\n",
    "  stop_words.remove('into')\n",
    "  stop_words.remove('by')\n",
    "  stop_words.remove('and')\n",
    "  stop_words.remove('will')\n",
    "  stop_words.remove('what')\n",
    "  stop_words.add('manually')\n",
    "  stop_words.remove('him')\n",
    "\n",
    "  word_tokens = word_tokenize(example_sent)\n",
    "\n",
    "  filtered_sentence = [w for w in word_tokens if w not in stop_words]\n",
    "\n",
    "  return ' '.join(filtered_sentence)\n",
    "\n",
    "def format_summary_short(s2):\n",
    "  s3 = ''.join(s2) #s2[0]\n",
    "  s3 = s3.split('.')\n",
    "  summ = ['']\n",
    "  id=0\n",
    "  for i in s3:\n",
    "\n",
    "    #stripping the spaces\n",
    "    i = i.replace('  ', ' ')\n",
    "    if len(i) == 1:\n",
    "      continue\n",
    "    if i[0]==' ' and i[1].isalpha():\n",
    "      i = stripp(i)\n",
    "    if i[0] == ' ':\n",
    "      continue\n",
    "    check = re.sub(r\"[^a-zA-Z0-9]+\", ' ', i)\n",
    "    check = ''.join(i for i in check if not i.isdigit())\n",
    "    check = check.replace('  ', ' ')\n",
    "    check = check.split(' ')\n",
    "    if len(check)<=6:\n",
    "      continue\n",
    "\n",
    "    #formatting\n",
    "    if i[0] == 'P':\n",
    "      id+=1\n",
    "      summ.append('')\n",
    "      i = shorten(i)\n",
    "      i = replacee(i)\n",
    "      summ[id] = summ[id] + ' -' + i + '.'\n",
    "    else:\n",
    "      i = shorten(i)\n",
    "      i = replacee(i)\n",
    "      summ[id] = summ[id] + '\\n  ' + i + '.'\n",
    "\n",
    "  if '' in summ:\n",
    "    summ.remove('')\n",
    "  summ = '\\n'.join(summ)\n",
    "  return summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177,
     "referenced_widgets": [
      "6ca726f2f6ae4188a6d4286d76cb3d77",
      "52d7d759f8f448dfa2239803f4807aba",
      "97daf800f5c944afaf4fcb9e363e494c",
      "75dafaaec01844ff98ec197bd208c608",
      "f2a22e297e5146e78ebae1e2350fc8b2",
      "5373d141061848f39512d08cae3ab7cf",
      "695c288dc5f74883ba661d0cc1290ab1",
      "5bb65d004ca44883872882278293c247",
      "0bd999803a6349c3b1137df3241ff4a2",
      "1dac18c7ae5640c182d7d5f3f970a7ba",
      "a9e369bee21e47319d5908f8ba0911cc",
      "68f253f4415c4b01a8d44e1c6eed53e0",
      "e0ce10dfde56486d9a73424bea365fd7",
      "304685b4441a4c2aa2c20a188d55fac1",
      "165ef8932a4d4270bd9025e2d2669c48",
      "52f15c73c5a949b88b5b1b9bbce4f872",
      "94e0b2c96de64e08bccaea41766da157",
      "78e56005d7f34bc3a3301598af3cdfdb",
      "3f1d6bc509124f1c9336887da9624583",
      "277abda9e01a43cb81beaee37d7badf2",
      "062bde705a14462eb769f7129f18cb52",
      "14be9d019a5a4771a694eb95dcdf0167",
      "fdd8bbf1874a49d295c7b1e109284319",
      "0478d4ac6986447584c1b46583fd4082",
      "78f22a0f83684ab3b3bd1eb651fcd63f",
      "267ee48e1078453db0798242ccd8d79a",
      "2ecaf77a7166441ebf897213f356601f",
      "d1d8fa1ec8334c569d313c33830a9687",
      "efa87580be4c4635b06c3fc9529adf1f",
      "71fece62a5ea452c93c32815cd396521",
      "0994d7cfb0474899ad0fb2c9c4a1e020",
      "ea4d4a69c4f94b93a23f48cbaf942c83",
      "e253b0beb4c24a1bafea3f3ad5c2ba80",
      "a83aac335f404e7daffdcc8b45d281d8",
      "9196db2ca87a4845bdb456850839cea0",
      "805fb0155482486991c58fd79d0c2e45",
      "7eca2506697a4f59859736a46998896c",
      "95ca2ced96aa42d89e5b50a72be8767b",
      "7106e4ca0ac54492bbf06da4c7f9836c",
      "b94da93817f340a08986e549204081e0",
      "cb86cf5f9c21424ba00b859beed1aa7f",
      "bed5bd398305496e893e7117d555ac99",
      "ff040a3d422c47f19ef548378da1be65",
      "fec6273f5fd64dfdb8f026fad2e95da9",
      "96a6d1aacb4241eebb061a6ad2e12b55",
      "0d05802e92cd4cfa90006c8f99456823",
      "12029d572df540cf85506f85493563a4",
      "efb884374339447080f713143384686d",
      "85bae560481d4b829e55d3ab28da90e5",
      "be2bbe922d2f4af9bed6fcb53ba1dfff",
      "1034c2742bb445de9f7d00cfa6216781",
      "e2f180c501424c57acbffbe1707edaef",
      "801d3371cc7649298ba3050f6c24a8f8",
      "e9dcda09bc684ef2b2d20d13b5020c9c",
      "6b766194c56b4779ab12d3d5e9dc6916"
     ]
    },
    "executionInfo": {
     "elapsed": 19620,
     "status": "ok",
     "timestamp": 1682547901885,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "UFE8hI97DR4x",
    "outputId": "83c4d034-7098-4800-a688-31c15f445da5"
   },
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1682547901887,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "CHJCDTU1o-Zd",
    "outputId": "2452d928-39a4-4762-c3c4-77a6948ad56e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Czech Republic government has lifted rules.\n",
      " -People can go even if do not need to , have to wait until June for free circulation of people.\n",
      " -PERSON4 lives in Trento, family lives in Bolz PERSON1 , PERSON8 , PERSON11 , PERSON13, PERSON13 going to write project management guide for Organization 5.\n",
      "  Organization 5 is developing systems in area.\n",
      "  Organization 3 is dissemination on web.\n",
      "  Organization 1 is not keen on reading guide PERSON11 will write something, someone will review it.\n",
      "  project management guides ready by end of June latest, internal reviews tested by mid June , have two weeks to finish.\n",
      " -PERSON8 has started PROJECT1 test sets PERSON8 explains to PERSON1, PERSON2 layout of test sets.\n",
      " -PERSON1 , PERSON8 , PERSON15, PERSON13 working on project to develop test set for spoken English translation.\n",
      "  test set limited to 3 file lists for general public.\n",
      " -PERSON15 has to send source code of task to Organization 1.\n",
      " -Person8 asks Organization 1 to review PROJECT1 test set, contribute to it.\n",
      " -PERSON1 , PERSON8 , PERSON12 , PERSON13 , PERSON5, PERSON11 working on project.\n",
      "  project started when EU still existed , will see what happened.\n",
      " -PERSON1 , PERSON8, PERSON15 want to improve stability of ASR.\n",
      " -PERSON1 is not ASR person , he does not know if it is good idea to do it end of project.\n",
      " -PERSON8, PERSON13 working on integration of ASR, MT models.\n",
      "  trying to run GPT tool to predict tail of sentence , it does not work well.\n",
      "  date for demo is 14th May 17th.\n",
      "  Organization 5 PERSON4 , PERSON8 , PERSON1 , PERSON15, PERSON8 discuss to present results of demo to project officer.\n",
      " -PERSON8 is sorry for not managing half hour.\n",
      "  will in touch for demo in coming days.\n"
     ]
    }
   ],
   "source": [
    "print(format_summary_short(s2_short[m_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "summary = ''\n",
    "for s in s2_short[m_id]:\n",
    "  preprocess_text = s.strip().replace(\"\\n\",\"\")\n",
    "  inputs = tokenizer(preprocess_text, return_tensors='pt')\n",
    "  summary_ids = model.generate(inputs['input_ids'], num_beams=4, max_length=512)\n",
    "  output = tokenizer.decode(summary_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "  summary = summary + output + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Czech Republic government has lifted the rules. People can go out even if they don't need to, but they have to wait until June for the free circulation of people. PERSON4 lives in Trento and his family lives in Bolz. PERSON11 went to the park yesterday. PERSON1, PERSON8, PERSON11, PERSON13 and PERSON13 are going to write a project management guide for Organization 5. Organization 5 is developing their own systems in this area. The project management guides should be ready by the end of June at the latest and the internal reviews should be tested by mid June. PERSON15 has to send the source code of the task to the Organization 1. Person8 asks Organization 1 to review the PROJECT1 test set and contribute to it. The date for the demo is 14th May 17th. The project was started when the EU still existed, so they will see what happened. PERSON4, PERSON8, PERSON1, PERSON15 and PERSON8 discuss how to present the results of the demo to the project officer. The demo should be in German. PERSON8 is sorry for not managing the half an hour. He will be in touch for the demo in the coming days. \""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1682547911003,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "qc8bBll9o-Ze",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Generate minutes\n",
    "def format_minutes(attendees, minutes):\n",
    "  tday = datetime.date.today()\n",
    "  att = \", \".join(attendees[0])\n",
    "  return f\"DATE : {tday}\\nATTENDEES : {att}\\n\\n\\nSUMMARY-\\n{minutes}\\n\\n\\nMinuted by: Team ABC\"\n",
    "\n",
    "def generate_minutes(preprocessed_transcripts, output_dir):\n",
    "  for length in [512, 768, 1024]:\n",
    "    split_transcripts, attendees = gen_tscs(length, preprocessed_transcripts)\n",
    "    summaries = gen_summaries(split_transcripts)\n",
    "\n",
    "    for meeting_id, summary in summaries.items():\n",
    "      minutes_with_pronouns = format_summary_with_pronouns(summary)\n",
    "      minutes_without_pronouns = format_summary_without_pronouns(summary)\n",
    "      minutes_shorten = format_summary_short(summary)\n",
    "\n",
    "      os.makedirs(os.path.join(output_dir, meeting_id), exist_ok=True)\n",
    "\n",
    "      with open(os.path.join(output_dir, meeting_id, f\"length_{length}_with_pronouns\"), \"w\") as f:\n",
    "        f.write(format_minutes(attendees, minutes_with_pronouns))\n",
    "\n",
    "      with open(os.path.join(output_dir, meeting_id, f\"length_{length}_without_pronouns\"), \"w\") as f:\n",
    "        f.write(format_minutes(attendees, minutes_without_pronouns))\n",
    "\n",
    "      with open(os.path.join(output_dir, meeting_id, f\"length_{length}_shorten\"), \"w\") as f:\n",
    "        f.write(format_minutes(attendees, minutes_shorten))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3954126,
     "status": "ok",
     "timestamp": 1682551891943,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "WmQHCqjgo-Zf",
    "outputId": "a163eaaa-34a7-4a8d-b61c-a2e2a872553e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2759 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 36. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=18)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 13. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=6)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 12. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=6)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 58. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=29)\n",
      "Your max_length is set to 62, but you input_length is only 27. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 37. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=18)\n",
      "Your max_length is set to 62, but you input_length is only 50. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=25)\n",
      "Your max_length is set to 62, but you input_length is only 25. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n",
      "Your max_length is set to 62, but you input_length is only 37. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=18)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 37. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=18)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 21. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 17. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=8)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 17. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=8)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 39. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=19)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "Your max_length is set to 62, but you input_length is only 3. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n"
     ]
    }
   ],
   "source": [
    "# generate_minutes(cs_train_preprocessed, os.path.join(OUTPUT_DIR, \"cs\", TRAIN_DIR))\n",
    "# generate_minutes(cs_dev_preprocessed, os.path.join(OUTPUT_DIR, \"cs\", DEV_DIR))\n",
    "# generate_minutes(cs_test_preprocessed, os.path.join(OUTPUT_DIR, \"cs\", TEST_DIR))\n",
    "# generate_minutes(cs_test2_preprocessed, os.path.join(OUTPUT_DIR, \"cs\", TEST2_DIR))\n",
    "\n",
    "generate_minutes(en_train_preprocessed, os.path.join(OUTPUT_DIR, \"en\", TRAIN_DIR))\n",
    "generate_minutes(en_dev_preprocessed, os.path.join(OUTPUT_DIR, \"en\", DEV_DIR))\n",
    "generate_minutes(en_test_preprocessed, os.path.join(OUTPUT_DIR, \"en\", TEST_DIR))\n",
    "generate_minutes(en_test2_preprocessed, os.path.join(OUTPUT_DIR, \"en\", TEST2_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xJh02iTH2tGS"
   },
   "source": [
    "# TextRank Scipt for ranking sentences\n",
    "This method uses GloVe Embeddings to calculate similarity score with the help of cosine similairty, and ranks individual sentences with the help of the PageRank Algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1155,
     "status": "ok",
     "timestamp": 1682551898666,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "tBJaRqQAEHKV",
    "outputId": "f9b518e0-de5b-40a5-e88b-c735b179c040"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/kristyna/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt') # one time execution\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1682551900813,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "fwK8kem-33KA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove.6B.zip        100%[===================>] 822.24M   633KB/s    in 13m 1s  \r\n",
      "\r\n",
      "2023-04-27 10:29:52 (1.05 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\r\n",
      "\r\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Archive:  glove.6B.zip\r\n",
      "  inflating: models/glove.6B.50d.txt  \r\n",
      "  inflating: models/glove.6B.100d.txt  \r\n",
      "  inflating: models/glove.6B.200d.txt  \r\n",
      "  inflating: models/glove.6B.300d.txt  \r\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "--2023-04-27 10:30:05--  http://nlp.stanford.edu/data/glove.6B.zip\r\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\r\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\r\n",
      "--2023-04-27 10:30:06--  https://nlp.stanford.edu/data/glove.6B.zip\r\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\r\n",
      "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\r\n",
      "--2023-04-27 10:30:07--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\r\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\r\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 862182613 (822M) [application/zip]\r\n",
      "Saving to: ‘glove.6B.zip.1’\r\n",
      "\r\n",
      "glove.6B.zip.1       13%[=>                  ] 112.82M   730KB/s    eta 15m 36s^C\r\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Archive:  glove.6B.zip\r\n",
      "replace models/glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\r\n"
     ]
    }
   ],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip glove*.zip -d models/glove\n",
    "!rm -rf glove*.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "error",
     "timestamp": 1682551900814,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "nO2wMYWo33yP",
    "outputId": "b21dbc2d-d7ba-4ced-bc03-5149dad7b72f"
   },
   "outputs": [],
   "source": [
    "# ENTER THE MINUTE_ID\n",
    "min_id = 'meeting_en_train_001'\n",
    "\n",
    "import os\n",
    "# path = 'outputs'\n",
    "path = OUTPUT_DIR + '/en/train'\n",
    "# os.chdir(path)\n",
    "summaries = []\n",
    "# for file1 in sorted(os.listdir()):\n",
    "sumfile = open(path + '/' + min_id + '/' + 'length_1024_with_pronouns', 'r')\n",
    "summ = sumfile.readlines()\n",
    "summ = summ[5:-3]\n",
    "text = ''\n",
    "for line in summ:\n",
    "    line = line.replace(' -', '')\n",
    "    line = line.replace('  ', '')\n",
    "    line = line.replace('\\n', '')\n",
    "    text = text + line + ' '\n",
    "summaries.append(text)\n",
    "#break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "aborted",
     "timestamp": 1682551900815,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "VtmWVTeH36yZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of sentences:  22\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "sentences = []\n",
    "for s in summaries:\n",
    "  sentences.append(sent_tokenize(s))\n",
    "\n",
    "sentences = [(idx, y) for x in sentences for idx, y in enumerate(x)] # flatten list\n",
    "print('Total no. of sentences: ', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "aborted",
     "timestamp": 1682551900816,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "5zKjmVRt4Gw_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/kristyna/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# EXTRACT WORD VECTORS\n",
    "\n",
    "word_embeddings = {}\n",
    "f = open('models/glove/glove.6B.100d.txt', encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    word_embeddings[word] = coefs\n",
    "f.close()\n",
    "\n",
    "\n",
    "# REMOVE PUNCTUATIONS, NUMBERS AND SPECIAL CHARACTERS\n",
    "# clean_sentences = pd.Series(sentences).str.replace(\"[^a-zA-Z]\", \" \")\n",
    "clean_sentences = pd.DataFrame(sentences, columns = ['order', 'sentence'])\n",
    "\n",
    "\n",
    "# MAKE ALPHABETS TO LOWERCASE\n",
    "# clean_sentences = [s.lower() for s in clean_sentences]\n",
    "clean_sentences['sentence'] = clean_sentences['sentence'].str.replace(\"[^a-zA-Z]\", \" \").str.lower()\n",
    "\n",
    "# REMOVE STOPWORDS\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(sen):\n",
    "    sen_new = \" \".join([i for i in sen if i not in stop_words])\n",
    "    return sen_new\n",
    "\n",
    "# clean_sentences = [remove_stopwords(r.split()) for r in clean_sentences]\n",
    "clean_sentences['sentence'] = clean_sentences['sentence'].apply(lambda x: remove_stopwords(x.split()))\n",
    "\n",
    "# EXTRACT SENTENCE VECTORS\n",
    "\n",
    "sentence_vectors = []\n",
    "# for i in clean_sentences:\n",
    "def get_sentence_vectors(row):\n",
    "  sentence_vector = None\n",
    "  sentence = row['sentence']\n",
    "  if len(sentence) != 0:\n",
    "    sentence_vector = sum([word_embeddings.get(w, np.zeros((100,))) for w in sentence.split()])/(len(sentence.split())+0.001)\n",
    "  else:\n",
    "    sentence_vector = np.zeros((100,))\n",
    "  return sentence_vector\n",
    "\n",
    "clean_sentences['sentence_vector'] = clean_sentences.apply(lambda x: get_sentence_vectors(x), axis=1)\n",
    "\n",
    "\n",
    "# INITIALIZE A SIMILARITY MATRIX\n",
    "sim_mat = np.zeros([len(sentences), len(sentences)])\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "  for j in range(len(sentences)):\n",
    "    if i != j:\n",
    "      # sim_mat[i][j] = cosine_similarity(sentence_vectors[i].reshape(1,100), sentence_vectors[j].reshape(1,100))[0,0]\n",
    "      sim_mat[i][j] = cosine_similarity(clean_sentences['sentence_vector'][i].reshape(1,100), clean_sentences['sentence_vector'][j].reshape(1,100))[0,0]\n",
    "\n",
    "\n",
    "# PAGERANK SCORING\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "nx_graph = nx.from_numpy_array(sim_mat)\n",
    "scores = nx.pagerank(nx_graph)\n",
    "ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "aborted",
     "timestamp": 1682551900817,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "-Er-FCrg4NFZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.051023536570241404, 'The project management guides should be ready by the end of June at the latest and the internal reviews should be tested by mid June, so that they have two weeks to finish that.')\n",
      "(0.05097876245559428, 'PERSON8 asks Organization 1 to review the PROJECT1 test set and contribute to it.')\n",
      "(0.0506864561085652, 'The project was started when the EU still existed, so they will see what happened.')\n",
      "(0.0502904519060587, 'Organization 1 is not keen on reading the guide PERSON11 will write something and someone will review it.')\n",
      "(0.049871040776940094, 'Organization 5 PERSON4, PERSON8, PERSON1, PERSON15 and PERSON8 discussed how to present the results of the demo to the project officer.')\n",
      "(0.04980569948654663, \"People can go out even if they don't need to, but they have to wait until June for the free circulation of people.\")\n",
      "(0.04941230787880488, 'PERSON1, PERSON8, PERSON15 and PERSON13 worked on a project to develop a test set for spoken English translation.')\n",
      "(0.048815409165515154, 'The test set should be limited to 3 file lists for the general public.')\n",
      "(0.047457347150899776, 'Organization 5 is developing their own systems in this area.')\n",
      "(0.04738628640110713, \"PERSON1 is not an ASR person, so he doesn't know if it's a good idea to do it at the end of the project.\")\n",
      "(0.0463883066872457, \"They are trying to run GPT tool to predict the tail of the sentence, but it doesn't work very well.\")\n",
      "(0.045733799611167525, 'PERSON15 has to send the source code of the task to the Organization 1.')\n",
      "(0.04561242513829104, 'PERSON4 lives in Trento and his family lives in Bolz PERSON1, PERSON8, PERSON11, PERSON13 and PERSON13 will write a project management guide for Organization 5.')\n",
      "(0.045099824359749026, 'PERSON8 has started the PROJECT1 test sets PERSON8 explains to PERSON1 and PERSON2 the layout of the test sets.')\n",
      "(0.04304539323142301, 'PERSON1, PERSON8 and PERSON15 want to improve the stability of the ASR.')\n",
      "(0.04271933065194986, 'The date for the demo is 14th May 17th.')\n",
      "(0.04261275001661858, 'He will be in touch for the demo in the coming days.')\n",
      "(0.04211328235686471, 'Organization 3 is doing the dissemination on the web.')\n",
      "(0.041444196812446, 'PERSON8 is sorry for not managing the half an hour.')\n",
      "(0.03875217000198939, 'PERSON1, PERSON8, PERSON12, PERSON13, PERSON5 and PERSON11 worked on a project.')\n",
      "(0.03726930159447005, ' The Czech Republic government has lifted the rules.')\n",
      "(0.033481921637511895, 'PERSON8 and PERSON13 worked on the integration of the ASR and MT models.')\n"
     ]
    }
   ],
   "source": [
    "# REVIEW THE RANKINGS BEFORE ELIMINATING IRRELEVANT INFO FROM THE SUMMARY\n",
    "\n",
    "for ranked_sentence in ranked_sentences:\n",
    "  print(ranked_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "aborted",
     "timestamp": 1682551900818,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "vmP_iRje4jef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of sentences removed:  4\n",
      "\n",
      "\n",
      "Reduced Summary(jumbled): \n",
      "\n",
      "The project management guides should be ready by the end of June at the latest and the internal reviews should be tested by mid June, so that they have two weeks to finish that.\n",
      "PERSON8 asks Organization 1 to review the PROJECT1 test set and contribute to it.\n",
      "The project was started when the EU still existed, so they will see what happened.\n",
      "Organization 1 is not keen on reading the guide PERSON11 will write something and someone will review it.\n",
      "Organization 5 PERSON4, PERSON8, PERSON1, PERSON15 and PERSON8 discussed how to present the results of the demo to the project officer.\n",
      "People can go out even if they don't need to, but they have to wait until June for the free circulation of people.\n",
      "PERSON1, PERSON8, PERSON15 and PERSON13 worked on a project to develop a test set for spoken English translation.\n",
      "The test set should be limited to 3 file lists for the general public.\n",
      "Organization 5 is developing their own systems in this area.\n",
      "PERSON1 is not an ASR person, so he doesn't know if it's a good idea to do it at the end of the project.\n",
      "They are trying to run GPT tool to predict the tail of the sentence, but it doesn't work very well.\n",
      "PERSON15 has to send the source code of the task to the Organization 1.\n",
      "PERSON4 lives in Trento and his family lives in Bolz PERSON1, PERSON8, PERSON11, PERSON13 and PERSON13 will write a project management guide for Organization 5.\n",
      "PERSON8 has started the PROJECT1 test sets PERSON8 explains to PERSON1 and PERSON2 the layout of the test sets.\n",
      "PERSON1, PERSON8 and PERSON15 want to improve the stability of the ASR.\n",
      "The date for the demo is 14th May 17th.\n",
      "He will be in touch for the demo in the coming days.\n",
      "Organization 3 is doing the dissemination on the web.\n"
     ]
    }
   ],
   "source": [
    "# ENTER THE PERCENTAGE OF SENTENCES THAT SEEM UNIFORMATIONAL,  THIS NUMBER IS USUALLY AROUND ~15% FOR THE MINUTES BELONGING TO A LENGTHY TRANSCRIPT\n",
    "\n",
    "rem_perc = 0.15\n",
    "\n",
    "import math\n",
    "remove_count = math.ceil(len(sentences)*rem_perc)\n",
    "print('No. of sentences removed: ', remove_count)\n",
    "\n",
    "print('\\n\\nReduced Summary(jumbled): \\n')\n",
    "for i in range(len(ranked_sentences)-remove_count):\n",
    "  print(ranked_sentences[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "aborted",
     "timestamp": 1682551900819,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "2gKJSP_t1J9r",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ranked_sentences.sort(key=lambda sentence: sentence[1][0])\n",
    "\n",
    "for sentence in ranked_sentences:\n",
    "  print(sentence[1][1])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0070bcb06ddf4ab3a6fe6cc2e4b90ace": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0424a5f9d0554d8fa7e140b53e97e058": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e9a126f8b0c540008fecfc1fc3ec1643",
       "IPY_MODEL_82fe36019b8c4abe98e3f64df392de8f",
       "IPY_MODEL_a7da8b45e1ac4695841b3765c98e2ea7"
      ],
      "layout": "IPY_MODEL_d6ee480089974b68822fe03461f48ba2"
     }
    },
    "0478d4ac6986447584c1b46583fd4082": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d1d8fa1ec8334c569d313c33830a9687",
      "placeholder": "​",
      "style": "IPY_MODEL_efa87580be4c4635b06c3fc9529adf1f",
      "value": "Downloading (…)neration_config.json: 100%"
     }
    },
    "062bde705a14462eb769f7129f18cb52": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0994d7cfb0474899ad0fb2c9c4a1e020": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0bd999803a6349c3b1137df3241ff4a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0be7b5910e8e41be9424295998f46569": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e62e3ff63b984e8a8c38e4d9b534251f",
       "IPY_MODEL_69eb5b2b3b7c4db29d05750e0de3e13c",
       "IPY_MODEL_8a4a8c70653c46e7b7e55161ab78b786"
      ],
      "layout": "IPY_MODEL_21ff593fad284a0893618fc0fa598371"
     }
    },
    "0d05802e92cd4cfa90006c8f99456823": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be2bbe922d2f4af9bed6fcb53ba1dfff",
      "placeholder": "​",
      "style": "IPY_MODEL_1034c2742bb445de9f7d00cfa6216781",
      "value": "Downloading (…)olve/main/merges.txt: 100%"
     }
    },
    "0f69d93ad981442e8609b16c93711f1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1034c2742bb445de9f7d00cfa6216781": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "12029d572df540cf85506f85493563a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e2f180c501424c57acbffbe1707edaef",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_801d3371cc7649298ba3050f6c24a8f8",
      "value": 456318
     }
    },
    "1229d438945742458eeba0010a9827bf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14be9d019a5a4771a694eb95dcdf0167": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "165ef8932a4d4270bd9025e2d2669c48": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_062bde705a14462eb769f7129f18cb52",
      "placeholder": "​",
      "style": "IPY_MODEL_14be9d019a5a4771a694eb95dcdf0167",
      "value": " 1.63G/1.63G [00:06&lt;00:00, 258MB/s]"
     }
    },
    "1b127286b3f94d43ba939aad47c6d2c9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1bf5bdc3ed4f4843b8a5be7cec4e4a61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e1343128a8e148909c67c432ecbe71c7",
      "max": 1515,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c3aa5b42ec804a22b0ed0a161ea89494",
      "value": 1515
     }
    },
    "1cf51c58aa8f4b58bbde38e9f7982089": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_86743b788fb64ad7a2fcc0d3698cb8e1",
      "placeholder": "​",
      "style": "IPY_MODEL_c899881f4a99464bb893c406557ec37d",
      "value": " 1.51k/1.51k [00:00&lt;00:00, 18.9kB/s]"
     }
    },
    "1dac18c7ae5640c182d7d5f3f970a7ba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2163958cbd72439db7ec6ba17d1d251b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21ff593fad284a0893618fc0fa598371": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2576e2e5d26d4bc1a9af456d8c1c6610": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d156b75b4cfe4614871b66ffa142fc67",
      "placeholder": "​",
      "style": "IPY_MODEL_560d0c10616f4648a8cc5be7f7fcfaa4",
      "value": "Downloading (…)olve/main/merges.txt: 100%"
     }
    },
    "260e547d94804de49e5a27b8693236be": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "267ee48e1078453db0798242ccd8d79a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea4d4a69c4f94b93a23f48cbaf942c83",
      "placeholder": "​",
      "style": "IPY_MODEL_e253b0beb4c24a1bafea3f3ad5c2ba80",
      "value": " 363/363 [00:00&lt;00:00, 5.35kB/s]"
     }
    },
    "277abda9e01a43cb81beaee37d7badf2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2ecaf77a7166441ebf897213f356601f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "304685b4441a4c2aa2c20a188d55fac1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f1d6bc509124f1c9336887da9624583",
      "max": 1625270765,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_277abda9e01a43cb81beaee37d7badf2",
      "value": 1625270765
     }
    },
    "30f805de7fbb470e86bd22759bd1d607": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "37c01a8e24034fdbb11f36d4357dd69f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "37db54af76c74bfe96777a5f5c5a6d4c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39480c2e10bd4e0d9a5691f8693efb0f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39e71963f0734ff4b0a1976ec6e0fabb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3a062a81783d4fe182801e659f579aef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3f1d6bc509124f1c9336887da9624583": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41369f0df37449cca5db9a3ea4343e8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_70ce3baac1614a03b2a5fbd3ec372d76",
      "placeholder": "​",
      "style": "IPY_MODEL_99d5ec18ceb24be68ff71cee533d987a",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "52d7d759f8f448dfa2239803f4807aba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5373d141061848f39512d08cae3ab7cf",
      "placeholder": "​",
      "style": "IPY_MODEL_695c288dc5f74883ba661d0cc1290ab1",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "52f15c73c5a949b88b5b1b9bbce4f872": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5373d141061848f39512d08cae3ab7cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "560d0c10616f4648a8cc5be7f7fcfaa4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5bb65d004ca44883872882278293c247": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c7b5ce44f1f4740be55481c2543404d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6c2dd4cb0dcf48ef96f8e8bef5e03721",
       "IPY_MODEL_e703d274799642fa80ec0a3c138d7dec",
       "IPY_MODEL_786a649a2b134d47951cd389dca85113"
      ],
      "layout": "IPY_MODEL_1b127286b3f94d43ba939aad47c6d2c9"
     }
    },
    "6389af7f7df64b2f8bade5af96165ac5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "639be07d74de48a89ac8541f6a329ee3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aadd876e8107480899cde6d29112688b",
      "placeholder": "​",
      "style": "IPY_MODEL_0f69d93ad981442e8609b16c93711f1f",
      "value": " 456k/456k [00:00&lt;00:00, 2.14MB/s]"
     }
    },
    "659b56c2c3da4d0f976b0e935a695f12": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "664b19797efe463fa03489f87efca28d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a08b337cb0eb440fb02c6ba15410e140",
       "IPY_MODEL_d38a3a83264e42ed93990d45db08587d",
       "IPY_MODEL_9420510e242f42a3b85a1e772f04bfc6"
      ],
      "layout": "IPY_MODEL_2163958cbd72439db7ec6ba17d1d251b"
     }
    },
    "68f253f4415c4b01a8d44e1c6eed53e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e0ce10dfde56486d9a73424bea365fd7",
       "IPY_MODEL_304685b4441a4c2aa2c20a188d55fac1",
       "IPY_MODEL_165ef8932a4d4270bd9025e2d2669c48"
      ],
      "layout": "IPY_MODEL_52f15c73c5a949b88b5b1b9bbce4f872"
     }
    },
    "695c288dc5f74883ba661d0cc1290ab1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "69eb5b2b3b7c4db29d05750e0de3e13c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_39480c2e10bd4e0d9a5691f8693efb0f",
      "max": 26,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_37c01a8e24034fdbb11f36d4357dd69f",
      "value": 26
     }
    },
    "6b766194c56b4779ab12d3d5e9dc6916": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6bcb494658184a4190c5e02d921b6545": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6bf1c3bc52f14ccd97254b2cc4647149": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6c2dd4cb0dcf48ef96f8e8bef5e03721": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1229d438945742458eeba0010a9827bf",
      "placeholder": "​",
      "style": "IPY_MODEL_7a825ca8753c434aa03c2844dd4cd7a0",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "6ca726f2f6ae4188a6d4286d76cb3d77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_52d7d759f8f448dfa2239803f4807aba",
       "IPY_MODEL_97daf800f5c944afaf4fcb9e363e494c",
       "IPY_MODEL_75dafaaec01844ff98ec197bd208c608"
      ],
      "layout": "IPY_MODEL_f2a22e297e5146e78ebae1e2350fc8b2"
     }
    },
    "70418d1b76a445c78fd45dd7d05a2f37": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "70ce3baac1614a03b2a5fbd3ec372d76": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7106e4ca0ac54492bbf06da4c7f9836c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "71fece62a5ea452c93c32815cd396521": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7378db67124e403db42173bb0dd0996f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "738d7cb305124cb6a537b638f69569ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_deeea229c94141b28b0f8dd26188874e",
      "placeholder": "​",
      "style": "IPY_MODEL_0070bcb06ddf4ab3a6fe6cc2e4b90ace",
      "value": "Downloading (…)/main/tokenizer.json: 100%"
     }
    },
    "744551fb48b743f1ba8c388c7c9e3d78": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75dafaaec01844ff98ec197bd208c608": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1dac18c7ae5640c182d7d5f3f970a7ba",
      "placeholder": "​",
      "style": "IPY_MODEL_a9e369bee21e47319d5908f8ba0911cc",
      "value": " 1.58k/1.58k [00:00&lt;00:00, 98.7kB/s]"
     }
    },
    "786a649a2b134d47951cd389dca85113": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bd1372f973c34bf38fe39fbd91828965",
      "placeholder": "​",
      "style": "IPY_MODEL_803fd2a45af5453ab95c03852739e347",
      "value": " 1.63G/1.63G [00:16&lt;00:00, 99.7MB/s]"
     }
    },
    "78e56005d7f34bc3a3301598af3cdfdb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "78f22a0f83684ab3b3bd1eb651fcd63f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_71fece62a5ea452c93c32815cd396521",
      "max": 363,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0994d7cfb0474899ad0fb2c9c4a1e020",
      "value": 363
     }
    },
    "7a825ca8753c434aa03c2844dd4cd7a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7eca2506697a4f59859736a46998896c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ff040a3d422c47f19ef548378da1be65",
      "placeholder": "​",
      "style": "IPY_MODEL_fec6273f5fd64dfdb8f026fad2e95da9",
      "value": " 899k/899k [00:00&lt;00:00, 1.06MB/s]"
     }
    },
    "7f5f1dc8f34d4a61a3c71b012844dc16": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "801d3371cc7649298ba3050f6c24a8f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "803fd2a45af5453ab95c03852739e347": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "805fb0155482486991c58fd79d0c2e45": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cb86cf5f9c21424ba00b859beed1aa7f",
      "max": 898823,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bed5bd398305496e893e7117d555ac99",
      "value": 898823
     }
    },
    "82fe36019b8c4abe98e3f64df392de8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9fb84994405f4f879579bc14a3e37008",
      "max": 898822,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cd0784ff3ff043029d0a53276c7215f4",
      "value": 898822
     }
    },
    "85bae560481d4b829e55d3ab28da90e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86743b788fb64ad7a2fcc0d3698cb8e1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "899cecd503c443328e4d9e38c510c00e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_738d7cb305124cb6a537b638f69569ba",
       "IPY_MODEL_dc7662194cc1452fb365dd14898f4cb2",
       "IPY_MODEL_d3e4d4986d9a486297c0177252436be7"
      ],
      "layout": "IPY_MODEL_37db54af76c74bfe96777a5f5c5a6d4c"
     }
    },
    "8a4a8c70653c46e7b7e55161ab78b786": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_744551fb48b743f1ba8c388c7c9e3d78",
      "placeholder": "​",
      "style": "IPY_MODEL_39e71963f0734ff4b0a1976ec6e0fabb",
      "value": " 26.0/26.0 [00:00&lt;00:00, 754B/s]"
     }
    },
    "8c196a76ebd047189a79b0601e95fe39": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9196db2ca87a4845bdb456850839cea0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7106e4ca0ac54492bbf06da4c7f9836c",
      "placeholder": "​",
      "style": "IPY_MODEL_b94da93817f340a08986e549204081e0",
      "value": "Downloading (…)olve/main/vocab.json: 100%"
     }
    },
    "9420510e242f42a3b85a1e772f04bfc6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f29e0471e1134035b52455f575c50c39",
      "placeholder": "​",
      "style": "IPY_MODEL_d6b7a53f1a4f4fa68f0921c2207f16e7",
      "value": " 309/309 [00:00&lt;00:00, 10.7kB/s]"
     }
    },
    "94e0b2c96de64e08bccaea41766da157": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "95ca2ced96aa42d89e5b50a72be8767b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96a6d1aacb4241eebb061a6ad2e12b55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0d05802e92cd4cfa90006c8f99456823",
       "IPY_MODEL_12029d572df540cf85506f85493563a4",
       "IPY_MODEL_efb884374339447080f713143384686d"
      ],
      "layout": "IPY_MODEL_85bae560481d4b829e55d3ab28da90e5"
     }
    },
    "97daf800f5c944afaf4fcb9e363e494c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5bb65d004ca44883872882278293c247",
      "max": 1585,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0bd999803a6349c3b1137df3241ff4a2",
      "value": 1585
     }
    },
    "99d5ec18ceb24be68ff71cee533d987a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9f010fc8ea4747719096404365713af5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6bcb494658184a4190c5e02d921b6545",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6bf1c3bc52f14ccd97254b2cc4647149",
      "value": 456318
     }
    },
    "9fb84994405f4f879579bc14a3e37008": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a08b337cb0eb440fb02c6ba15410e140": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a49450be232741e6abca0345f9eaf2ec",
      "placeholder": "​",
      "style": "IPY_MODEL_7378db67124e403db42173bb0dd0996f",
      "value": "Downloading (…)neration_config.json: 100%"
     }
    },
    "a49450be232741e6abca0345f9eaf2ec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a7da8b45e1ac4695841b3765c98e2ea7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6389af7f7df64b2f8bade5af96165ac5",
      "placeholder": "​",
      "style": "IPY_MODEL_3a062a81783d4fe182801e659f579aef",
      "value": " 899k/899k [00:00&lt;00:00, 1.05MB/s]"
     }
    },
    "a83aac335f404e7daffdcc8b45d281d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9196db2ca87a4845bdb456850839cea0",
       "IPY_MODEL_805fb0155482486991c58fd79d0c2e45",
       "IPY_MODEL_7eca2506697a4f59859736a46998896c"
      ],
      "layout": "IPY_MODEL_95ca2ced96aa42d89e5b50a72be8767b"
     }
    },
    "a9e369bee21e47319d5908f8ba0911cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aadd876e8107480899cde6d29112688b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b2df8d4ce807492fbe7d5da71d5c0fbf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b94da93817f340a08986e549204081e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ba6afd4fe48d4af4b57aa63710422e48": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_41369f0df37449cca5db9a3ea4343e8c",
       "IPY_MODEL_1bf5bdc3ed4f4843b8a5be7cec4e4a61",
       "IPY_MODEL_1cf51c58aa8f4b58bbde38e9f7982089"
      ],
      "layout": "IPY_MODEL_659b56c2c3da4d0f976b0e935a695f12"
     }
    },
    "bd1372f973c34bf38fe39fbd91828965": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be2bbe922d2f4af9bed6fcb53ba1dfff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bed5bd398305496e893e7117d555ac99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bee97cf0e6b54da68dc71b5ab8a91067": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c0cc811310b045208054582bdf31507e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3aa5b42ec804a22b0ed0a161ea89494": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c899881f4a99464bb893c406557ec37d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cb86cf5f9c21424ba00b859beed1aa7f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd0784ff3ff043029d0a53276c7215f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cdb13e3cda8b48618898acebdd55dc3e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cfbdf5f1b2454611b9797b25b668c85f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d156b75b4cfe4614871b66ffa142fc67": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1a8ea2af6974dd2b879c6c7899a2acc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2576e2e5d26d4bc1a9af456d8c1c6610",
       "IPY_MODEL_9f010fc8ea4747719096404365713af5",
       "IPY_MODEL_639be07d74de48a89ac8541f6a329ee3"
      ],
      "layout": "IPY_MODEL_c0cc811310b045208054582bdf31507e"
     }
    },
    "d1d8fa1ec8334c569d313c33830a9687": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d38a3a83264e42ed93990d45db08587d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8c196a76ebd047189a79b0601e95fe39",
      "max": 309,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_30f805de7fbb470e86bd22759bd1d607",
      "value": 309
     }
    },
    "d3e4d4986d9a486297c0177252436be7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_260e547d94804de49e5a27b8693236be",
      "placeholder": "​",
      "style": "IPY_MODEL_bee97cf0e6b54da68dc71b5ab8a91067",
      "value": " 1.36M/1.36M [00:01&lt;00:00, 1.29MB/s]"
     }
    },
    "d6b7a53f1a4f4fa68f0921c2207f16e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d6ee480089974b68822fe03461f48ba2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc7662194cc1452fb365dd14898f4cb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7f5f1dc8f34d4a61a3c71b012844dc16",
      "max": 1355863,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cfbdf5f1b2454611b9797b25b668c85f",
      "value": 1355863
     }
    },
    "dd26efb9b4024fb9a054b919c4fc2d7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "deeea229c94141b28b0f8dd26188874e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0ce10dfde56486d9a73424bea365fd7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_94e0b2c96de64e08bccaea41766da157",
      "placeholder": "​",
      "style": "IPY_MODEL_78e56005d7f34bc3a3301598af3cdfdb",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "e1343128a8e148909c67c432ecbe71c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e253b0beb4c24a1bafea3f3ad5c2ba80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e2f180c501424c57acbffbe1707edaef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e62e3ff63b984e8a8c38e4d9b534251f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_70418d1b76a445c78fd45dd7d05a2f37",
      "placeholder": "​",
      "style": "IPY_MODEL_e952d821f2c84c088d7d31e9c9e2c2f2",
      "value": "Downloading (…)okenizer_config.json: 100%"
     }
    },
    "e703d274799642fa80ec0a3c138d7dec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cdb13e3cda8b48618898acebdd55dc3e",
      "max": 1625270765,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dd26efb9b4024fb9a054b919c4fc2d7a",
      "value": 1625270765
     }
    },
    "e952d821f2c84c088d7d31e9c9e2c2f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e9a126f8b0c540008fecfc1fc3ec1643": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b2df8d4ce807492fbe7d5da71d5c0fbf",
      "placeholder": "​",
      "style": "IPY_MODEL_ee7a46a7ab7a47ee9f58803f884c82b7",
      "value": "Downloading (…)olve/main/vocab.json: 100%"
     }
    },
    "e9dcda09bc684ef2b2d20d13b5020c9c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea4d4a69c4f94b93a23f48cbaf942c83": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ee7a46a7ab7a47ee9f58803f884c82b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "efa87580be4c4635b06c3fc9529adf1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "efb884374339447080f713143384686d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e9dcda09bc684ef2b2d20d13b5020c9c",
      "placeholder": "​",
      "style": "IPY_MODEL_6b766194c56b4779ab12d3d5e9dc6916",
      "value": " 456k/456k [00:00&lt;00:00, 723kB/s]"
     }
    },
    "f29e0471e1134035b52455f575c50c39": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f2a22e297e5146e78ebae1e2350fc8b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fdd8bbf1874a49d295c7b1e109284319": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0478d4ac6986447584c1b46583fd4082",
       "IPY_MODEL_78f22a0f83684ab3b3bd1eb651fcd63f",
       "IPY_MODEL_267ee48e1078453db0798242ccd8d79a"
      ],
      "layout": "IPY_MODEL_2ecaf77a7166441ebf897213f356601f"
     }
    },
    "fec6273f5fd64dfdb8f026fad2e95da9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ff040a3d422c47f19ef548378da1be65": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
