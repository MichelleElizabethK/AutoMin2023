{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-8T_Vr4G76dv"
   },
   "source": [
    "# TEAM SYNAPSE : SUBMISSION FOR AUTOMIN 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48079,
     "status": "ok",
     "timestamp": 1682953253275,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "7e8XSCDO1M7w",
    "outputId": "b7f80afe-9436-47a2-9d81-b5837159c56d"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "#\n",
    "# %cd drive/MyDrive/AutoMin\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1682953502889,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "RSwS9Q7s1J9c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "PREPROCESSED_DIR = \"preprocessed_data\"\n",
    "OUTPUT_DIR = \"minutes\"\n",
    "\n",
    "EUROPARL_DATA_PATH = \"europarl/test1\"\n",
    "ELITR_DATA_PATH = \"elitr/en/test2023-en\"\n",
    "\n",
    "# MODEL_SHORT_NAME = \"bart-large-xsum\"\n",
    "MODEL_SHORT_NAME = \"MEETING_SUMMARY\"\n",
    "\n",
    "# MODEL = f\"facebook/{MODEL_SHORT_NAME}/\"\n",
    "MODEL = f\"knkarthick/{MODEL_SHORT_NAME}\"\n",
    "\n",
    "# SUMMARIZER_MODEL = f\"models/{MODEL_SHORT_NAME}/checkpoint-5500\"\n",
    "SUMMARIZER_MODEL = f\"knkarthick/{MODEL_SHORT_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/kristyna/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, pipeline, AutoModelForSeq2SeqLM\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import re\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "vnvGXjEt06FF",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1682953291212,
     "user_tz": -120,
     "elapsed": 18359,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 877,
     "status": "ok",
     "timestamp": 1682953307185,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "qB92jNAF5zg_",
    "outputId": "5130825e-1a39-493d-88bd-86f0cee851be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name())\n",
    "    torch.cuda.set_device(0)\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241,
     "referenced_widgets": [
      "dfff6636e432470c9f9b5e9327e06775",
      "f4e959e848074a36b692316a35c0ea44",
      "c1b768bc7bda4f4bb72e1d9455d848f6",
      "54b753d573ba4af5aae6e90eae730525",
      "b91a7e309ec244f6bdbc1ee5cf4a748b",
      "b2884184297c4ae2b72dc1653f473912",
      "a48425092997483c97880427e1b370f8",
      "2dbae29561d44d00ba018fa6050f9651",
      "e359d34b57044c8290f114084129edbc",
      "293cd5f4623e47819f237dfe800917d9",
      "f1405f3c93e7431bad45566b04d28092",
      "b0e05b95d78949c2b5248144b4b53ef8",
      "3419a24159d245e09f24a6de15579537",
      "95d5b07289a5461e90d2863d52651437",
      "0258c0f831864d76b8da412c72e1bcec",
      "15fcefddfe1241e1912308a3e0369feb",
      "37d46921f77e433a8ee85fc5b26f731c",
      "1c565184f62047d4ac2310ea0274954b",
      "210f248fc74a4f2cb2671e5f1850e784",
      "be16aa0d06634e559f5754a382902314",
      "9d5196deb05549d0b7ba47c8e2bd9b70",
      "413d836d8a2049d684557a931b29459d",
      "f7edb77d5a314f67879c075773f9f10d",
      "687c56454d1043f2b79d171810dfeb7f",
      "551bbd9e8cdd445594f93bb87fc94720",
      "356744cd08f64f9c9977b18e90101745",
      "7e6273c05af04dba8538019b5dabe5e4",
      "5a966c0de188464d8e40e0cdd3c8d50a",
      "2e9b7e1831de42b19c7a7c2959bc683d",
      "a6d6153c476f4df28d5ff439a15f4a68",
      "db78284b8e654440af7b8d3a69dd0aa0",
      "9e907706ca3845e891c9fd380d44d92f",
      "af05bfefe9a444b09286c8716d72b8c3",
      "37c98c759b094742b2fdb16d06296b17",
      "d4171be7b8b949fa8300301a06e3cb4c",
      "46bcad2ebe4f42ac8f3c1766d5ccec49",
      "9b24d42bb3f74204b63024820b670156",
      "9ed9bc7814264744acb089f4dd53c453",
      "29b916fbd0844450a84f25c1352068b4",
      "fac3824f4c3a4c24a4e86a523e0dc8fd",
      "d7f3dc64f3cf495b9cbcd7050cdd7502",
      "1ac19fa9c73d42e89ab53b515a439758",
      "f2fb7df4991e472a9f5307c7a4cce042",
      "79cdbad0d1dc4f6ab324ac13dd317b8f",
      "79a8b1dd39ab4e4db3d9b099692e955a",
      "2fa95194cd614752a83fd964a6af9839",
      "f4e14fdbc7124a2c927f8ceae7837577",
      "892b5f7aa84b4ae981379c09f5397a21",
      "be362682da394b65beb1a67c6eec6a1f",
      "436643afb6404e03a3f3fe554dfb8a72",
      "261c2a72381e40cb94c5c60cf0237d50",
      "407d2cb054564c46881e2fff1b48705f",
      "2076cd74bf534668b7a85e8fc4ea2cc0",
      "4367fe694cd54f26b800f9ae19d2a8e2",
      "a8ad1c8f7ebe44de9298c3c68241ee51",
      "b5d4c6556d5f4927a90780c4ea2cd515",
      "98807b0cbaaa42bfbefe464c1c194166",
      "5906ee8507074480b59086e52120b132",
      "c50d2fec73aa4dc2a4d22bf266bbe322",
      "4102431c863e43bd8e35567c14d89c64",
      "5a3de526b5d246df981d7714133a784d",
      "a5f5e7d780c341efb20e1a60dd511261",
      "149ccf52c9b84a6b8791139bf5c1abe5",
      "de54ef26639f47e6b3c148d6ee025b86",
      "4a274883440848e1895d4c37911b1531",
      "883614ba846d460895201d82bb29f597",
      "8ad79bc9e7604cad94978c3d51f5fe64",
      "78f6244dbe4d4f69a77241ca759a0f76",
      "32171595336644219238ca6aa86a3987",
      "789e1174eb834523aa2d996da8d4f624",
      "8e1a4e3068c94492a7c65486cf59b82c",
      "f836df9ac66c4415910f0da952f44461",
      "0f5f1407d88845d388871e827eb377e8",
      "693b5dd44a2e48a1b9634500713ecfa8",
      "2d708f20e51d46fa8da7e624f3f84c78",
      "e83b1ae3ea7246d7b2b7222b78c3df1d",
      "d80cafc5015c456e8cf27031815aa841"
     ]
    },
    "executionInfo": {
     "elapsed": 90439,
     "status": "ok",
     "timestamp": 1682953400077,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "0ukVZnIADqw8",
    "outputId": "3df6d7ec-427d-4b06-ffbe-035aa297d712"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL)\n",
    "device = 0 if torch.cuda.is_available() else None\n",
    "summarizer = pipeline(\"summarization\", model=SUMMARIZER_MODEL, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1682953509170,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "Wupr-PBc1J9g",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_preprocessed_transcripts(file_name):\n",
    "  with open(f\"{file_name}.json\", \"r\") as f:\n",
    "    preprocessed_transcripts = json.load(f)\n",
    "\n",
    "  return preprocessed_transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "executionInfo": {
     "elapsed": 2712,
     "status": "ok",
     "timestamp": 1682953512503,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "st2y7Snb1J9h",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "elitr_preprocessed = load_preprocessed_transcripts(os.path.join(PREPROCESSED_DIR, ELITR_DATA_PATH))\n",
    "europarl_preprocessed = load_preprocessed_transcripts(os.path.join(PREPROCESSED_DIR, EUROPARL_DATA_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "executionInfo": {
     "elapsed": 414,
     "status": "ok",
     "timestamp": 1682953851880,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "2zMtAUGgyq9I",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def segment_transcripts(max_input_length, transcripts, meeting_id=None):\n",
    "  def split_line(line):\n",
    "    splits = []\n",
    "\n",
    "    sentences = sent_tokenize(line)\n",
    "    split_idx = len(sentences)//2\n",
    "    line1 = \" \".join(sentences[:split_idx]) + '.\\n'\n",
    "    line2 = role + \": \" + \" \".join(sentences[split_idx:])\n",
    "\n",
    "    for line in [line1, line2]:\n",
    "      if len(tokenizer.encode(line)) >= max_input_length:\n",
    "        splits += split_line(line)\n",
    "      else:\n",
    "        splits.append(line)\n",
    "\n",
    "    return splits\n",
    "\n",
    "  segmented_transcripts = {}\n",
    "  attendees = []\n",
    "\n",
    "  for m_id, transcript in transcripts.items():\n",
    "    if meeting_id is not None and m_id != meeting_id:\n",
    "      continue\n",
    "\n",
    "    roles = transcript['roles']\n",
    "    attendees.append(sorted(list(set(roles))))\n",
    "    utterances = transcript['utterances']\n",
    "    segmented_transcript = [\"\"]\n",
    "\n",
    "    for role, utterance in zip(roles, utterances):\n",
    "      line = role + ': ' + utterance + '\\n'\n",
    "      # TODO remove short lines?\n",
    "      tokenized_line = tokenizer.encode(line)\n",
    "\n",
    "      if len(tokenized_line)>=max_input_length:\n",
    "          line_splits = split_line(line)\n",
    "      else:\n",
    "          line_splits = [line]\n",
    "\n",
    "      for line_split in line_splits:\n",
    "          tokenized = tokenizer.encode(segmented_transcript[-1]+line_split)\n",
    "          if len(tokenized)>=max_input_length:\n",
    "              segmented_transcript.append(line_split)\n",
    "          else:\n",
    "              segmented_transcript[-1] += line_split\n",
    "\n",
    "    segmented_transcripts[m_id] = segmented_transcript\n",
    "\n",
    "  return segmented_transcripts, attendees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1335,
     "status": "ok",
     "timestamp": 1682953553740,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "-6_e2PWcU30k",
    "outputId": "927c7d2c-bd0b-4a0a-cb67-ab59e2899258"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSON6: Hi, hello. Can you hear me?\n",
      "PERSON2: Yes.\n",
      "PERSON6: I do not hear anyone. I have to reconnect again. Or maybe can someone else, give it a try as well, because –\n",
      "PERSON2: I can hear you.\n",
      "PERSON6: PERSON11, can you say something as well. Because with PERSON2, I remember that PERSON2 also had some microphone issues at times.\n",
      "PERSON2: And you can hear – You cannot hear me or –\n",
      "PERSON6: Yeah. So. I'll try to reconnect. I'll – Yeah – So, PERSON8. Hello, can you say something?\n",
      "PERSON8: Oh yeah. Hi.\n",
      "PERSON6: Oh, yeah. I. I have to reconnect. Making PERSON8 the host, for now. Yeah. So, I'll make PERSON8 the host for now, and I reconnect. Leave meeting.\n",
      "PERSON8: Oh, okay. I hear you, by the way. Hello.\n",
      "PERSON6: Yeah, yeah. Now I can hear it. So, for some reason I have always to connect a few times until zoom starts sending also the sound to me. So, It's annoying. Yeah. So. I was in a call until the very last minute. So, sorry that I didn't remind everybody to – to connect. And – I'm happy to see that you are here. So, let's start. And also my machine crashed in the meantime, so I had to, like, restart it. And now it's all, like, starting up. So, so, I would like to start, maybe in the other order. In the opposite order than last week. So, PERSON7, if you could start. You were one of those –\n",
      "PERSON1: So, you want to hear, what did I do?\n",
      "PERSON6: Yeah. Yeah, yeah, yeah.\n",
      "PERSON1: So. The transcripts for check are almost done. And one – one transcriber of Germany's working. And she wants to do it alone, until December the 10th. And my mother is writing the question for the German subti – subtitle user study. And she – and she has some progress, and then – then she will move it to the spreadsheet, so we can get, her feedback and – and continue with that. And I started to write deliverables.\n",
      "PERSON6: Okay, that's great. Starting to write de – That's – That's excellent. I'm hopeful about PERSON12, but I haven't heard from him back. And he is not on the call either. So let's – Feel free to ping PERSON12 – Yourself as well. So the more –\n",
      "PERSON8: Okay.\n",
      "PERSON6: The more – the more, we do, the better. Great. Yeah, then.\n",
      "PERSON1: Can I ask PERSON11 to do, the transcripts of – By German ASR for the German transcriber.\n",
      "PERSON6: Yeah, yeah, that –\n",
      "PERSON11: So – So, I have just added the transcripts for the first 30 parts, and for the next ten parts, it's still running.\n",
      "PERSON1: Okay.\n",
      "PERSON11: But for some folders, for some reason, the audio format is wrong, so, something is wrongly – Basically, the big trade, or something is wrong. So, some files are still – Have still weird output. But – but for most folders, it should be already fine.\n",
      "PERSON1: Okay, thanks.\n",
      "PERSON6: Yeah, that's great. So, I support this, it's, it's, it's great that, Dá. PERSON7, you have thought of PERSON11. And PERSON11 now has the time. There are other things where I was, thinking of PERSON11 and that would be training of, empty systems, so that they do the shortening. So if you, PERSON11, had the time. Obviously, there is no way we could do it for the next week. But we should really have the system – ready for –\n",
      "PERSON11: I looked at the tutorial from, from, from the NLP was it?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m_id = 'meeting_en_test2023_001'\n",
    "\n",
    "segmented_transcript_long, _ = segment_transcripts(512, elitr_preprocessed, meeting_id=m_id)\n",
    "segmented_transcript_avg, _ = segment_transcripts(768, elitr_preprocessed, meeting_id=m_id)\n",
    "segmented_transcript_short, _ = segment_transcripts(1024, elitr_preprocessed, meeting_id=m_id)\n",
    "\n",
    "print(segmented_transcript_short[m_id][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1682953563674,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "mKc5wZQp1J9h",
    "outputId": "22a6e62d-2edd-49bf-f128-3c461e3f374c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "17\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "print(len(segmented_transcript_short[m_id]))\n",
    "print(len(segmented_transcript_avg[m_id]))\n",
    "print(len(segmented_transcript_long[m_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1682953565854,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "xeoD-XjdDk8-",
    "outputId": "6e428502-53dc-4899-99e3-998db26db529"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - PERSON6: Hi, hello. Can you hear me?\n",
      "PERSON2: Yes.\n",
      "PERSON6: I do not hear anyone. I have to reconnect again. Or maybe can someone else, give it a try as well, because –\n",
      "PERSON2: I can hear you.\n",
      "PERSON6: PERSON11, can you say something as well. Because with PERSON2, I remember that PERSON2 also had some microphone issues at times.\n",
      "PERSON2: And you can hear – You cannot hear me or –\n",
      "PERSON6: Yeah. So. I'll try to reconnect. I'll – Yeah – So, PERSON8. Hello, can you say something?\n",
      "PERSON8: Oh yeah. Hi.\n",
      "PERSON6: Oh, yeah. I. I have to reconnect. Making PERSON8 the host, for now. Yeah. So, I'll make PERSON8 the host for now, and I reconnect. Leave meeting.\n",
      "PERSON8: Oh, okay. I hear you, by the way. Hello.\n",
      "PERSON6: Yeah, yeah. Now I can hear it. So, for some reason I have always to connect a few times until zoom starts sending also the sound to me. So, It's annoying. Yeah. So. I was in a call until the very last minute. So, sorry that I didn't remind everybody to – to connect. And – I'm happy to see that you are here. So, let's start. And also my machine crashed in the meantime, so I had to, like, restart it. And now it's all, like, starting up. So, so, I would like to start, maybe in the other order. In the opposite order than last week. So, PERSON7, if you could start. You were one of those –\n",
      "PERSON1: So, you want to hear, what did I do?\n",
      "PERSON6: Yeah. Yeah, yeah, yeah.\n",
      "PERSON1: So. The transcripts for check are almost done. And one – one transcriber of Germany's working. And she wants to do it alone, until December the 10th. And my mother is writing the question for the German subti – subtitle user study. And she – and she has some progress, and then – then she will move it to the spreadsheet, so we can get, her feedback and – and continue with that. And I started to write deliverables.\n",
      "PERSON6: Okay, that's great. Starting to write de – That's – That's excellent. I'm hopeful about PERSON12, but I haven't heard from him back. And he is not on the call either. So let's – Feel free to ping PERSON12 – Yourself as well. So the more –\n",
      "PERSON8: Okay.\n",
      "PERSON6: The more – the more, we do, the better. Great. Yeah, then.\n",
      "PERSON1: Can I ask PERSON11 to do, the transcripts of – By German ASR for the German transcriber.\n",
      "PERSON6: Yeah, yeah, that –\n",
      "PERSON11: So – So, I have just added the transcripts for the first 30 parts, and for the next ten parts, it's still running.\n",
      "PERSON1: Okay.\n",
      "PERSON11: But for some folders, for some reason, the audio format is wrong, so, something is wrongly – Basically, the big trade, or something is wrong. So, some files are still – Have still weird output. But – but for most folders, it should be already fine.\n",
      "PERSON1: Okay, thanks.\n",
      "PERSON6: Yeah, that's great. So, I support this, it's, it's, it's great that, Dá. PERSON7, you have thought of PERSON11. And PERSON11 now has the time. There are other things where I was, thinking of PERSON11 and that would be training of, empty systems, so that they do the shortening. So if you, PERSON11, had the time. Obviously, there is no way we could do it for the next week. But we should really have the system – ready for –\n",
      "PERSON11: I looked at the tutorial from, from, from the NLP was it?\n",
      "\n",
      "1 - PERSON6: For the upcoming sessions and I've asked demand because I've seen the meme project demo. They do offline subtitling. So, that's sli – slightly easier than what we do. They still have the same segmentation issues and so on. But, their mission translation is doing shortening simply because the data is shortening. And that's because their target size, is – are the subtitles which are created for the hearing-impaired. So, there is like natural shortening in the data. It'd be great if we could also locate some, such type of the data where there is some natural shortening happening. We would – wou – We would put it in the architecture.\n",
      "PERSON11: That's also possible. But also, I looked at the, at the – Tutorial from the, from the –\n",
      "PERSON6: Yeah, it was.\n",
      "PERSON11: Yes. Actually, so – So, all of our models, basically work with, with, yeah, sequence to sequence where we just process the entire – Input sentence. And, then, when we have the final, output from, from, from the entire input sentence, we, start, generating, but, the output sentence. But, but, actually, so – The people from – I think, it was actually. They are doing it, so that they are just processing prefixes. So they pre – Process first key words as they, as they, give them into the input. And hen they generate the first word. And, and then, basically with every new token that they get. They generate, the new – One new token. So, basically, it is much faster because you just generate one word at a time. And also, I think it – It could be quite easy to implement the, shortening in this, in this model as well.\n",
      "PERSON6: Yeah.\n",
      "PERSON11: Because we can just stop generating after some time.\n",
      "PERSON6: Yeah. So, it would be shortening because we ran out of time, right?\n",
      "PERSON11: Yes. So basically we would just, call it like to – We would just train it, so that it s – Stops generating it after the – Some, some time. Yeah. So, so that could also work.\n",
      "PERSON6: Yeah. So they have talked to PERSON9. Or PERSON9 mentioned it in a call that is, PERSON3 is not ready, has no, specific things, for speech translation. So this and other strategies are no longer PERSON3.\n",
      "PERSON11: Okay, okay, so we would have to implement this.\n",
      "PERSON6: Yeah. And there is nobody – In Edinburgh, who would have the time to do that. So if you would have the time, then you are one possible candidate. And we actually don't have any other candidates. Where maybe I thought that, that maybe some students of PERSON1, I do not know if he is on the call already. But that is also like very risky and like distant. So it would be difficult, but, so that – The only other possible candidate would be, PERSON13, from the PROJECT1. Who, like, works halfway in Prague and halfway in Brno. But he is working on other things in PERSON3. So, I don't want to, like, to focus him too, too, much. So – PERSON11, Please, think about it. If –\n",
      "PERSON11: Okay, okay, bso right now I don't know if it is realistic, because I, I was just looking at the PERSON3 some time ago. And, I saw, basically, like, yeah. It's quite like, quite low level. It's written in. So, I don't know how, how hard it will be to change this.\n",
      "PERSON6: Yeah.\n",
      "PERSON11: But if I, I see that it is possible, if I understand what's going on in the code, then, yeah, I –\n",
      "PERSON6: Yeah.\n",
      "PERSON11: Will like, let you know, based on, yeah, what they thi –\n",
      "PERSON6: Yeah. Thanks. So let me check the – This is so – So poor. I would never use – So, we have PERSON2, PERSON4 and PERSON8 you here on the call further. So now, from all of you, I would like to hear an update for the sessions, for next week. So, one thing is the Monday seminar. That should be done very easily, don't bother yourself with that much. But I think that PERSON4 should just like, click, click on s – some buttons and get the get the, vocabulary, expanded for that, right?\n",
      "PERSON4: Well, yes – Will work on it tomorrow.\n",
      "\n",
      "2 - PERSON6: Yes, but then a lot of effort is to be put into – the preparation for the two setups. For, PROJECT2 and. And, PERSON4 you mentioned that you don't have the webpage for PROJECT2. Is that still true?\n",
      "PERSON4: No. I fi – found it. And I, I just saw the programme for PROJECT2, and I was checking the talks. And I am trying to, gather the data. The relevant from those parts that are mentioned in the programme.\n",
      "PERSON6: So, could you mer. Maybe, per – perhaps – Well, oh, you are you away? So, you are away the whole Friday? Or only at eleven?\n",
      "PERSON4: I'm away from eleven to one. No, ten to twelve.\n",
      "PERSON6: Ten to twelve. Okay, so in the afternoon, for example, in the Czech afternoon. You are able to, to do something. So, I would suggest if it's not too late for, for issue. And I guess it's not. That, you could have a Zoom call again with the videos and – And to, to have a dry run of some past similar talks to PROJECT2 talks. And see how that system works. And, at the same time, we can do the same thing with the for example. The, the, Supreme Audit talks. So they are in the elite, the death set. So I will. We have the links, some or else, maybe –\n",
      "PERSON4: I'm, I'm a bit afraid that the probably will not be prepared till tomorrow. Because tomorrow I will be working on the Monday seminar model as well. So I think we can run the dataset for Monday.\n",
      "PERSON6: Yeah, well –\n",
      "PERSON4: Is it too late?\n",
      "PERSON6: The more tests we do, the better. So, even if we do the test of, like, the two concurrent subtitlings without domain adaptation, it would be useful test.\n",
      "PERSON4: Okay. For sure.\n",
      "PERSON6: So, so, PERSON8, if you could plan for tomorrow afternoon, so that –\n",
      "PERSON8: Yeah, I'm planning to do that.\n",
      "PERSON6: So there – It will be two videos, played concurrently. So that actually means that we need you to operate two machines. That's another critical thing.\n",
      "PERSON8: I can't op – I can operate two machines. I have two laptops at home. So, I can do that, I guess.\n",
      "PERSON6: Yes, but you need two local machines. You need to unit ark, and one more machine with X to go.\n",
      "PERSON8: I can use black bird.\n",
      "PERSON6: Okay. Yeah. So Ark and blackbird, right? Yeah. So tomorrow in the afternoon, should we say, like one or two, Czech time. What is better for you?\n",
      "PERSON8: Both is okay with me.\n",
      "PERSON4: Both are good for me.\n",
      "PERSON6: So I suggest that at one. Czech time. So, like, Zoom Test for – Two – YouTube videos at the same time. So, PERSON8, would the, two, presentations be ready to paragraph use ready?\n",
      "PERSON8: So I got the access to, my engage, last night, so it was pretty late in India. So I didn't set up my account. Then, I will complete it today. Basically yesterday, I, worked with all the steps. So, it should be easy for me to do that now. Oh, it will be done today, I guess. Yeah. So tomorrow we are going –\n",
      "PERSON6: There is, there is some chance that – Yeah. So, and PERSON6 will provide – PERSON8, PERSON8, setting up, two presentations. So, and PERSON4, PERSON4 has been working on adaptation, for the two domains. PERSON8 setting up to online text – To paragraph setting. On quest plus virtual machines, behind. And then, Friday, test time for two concurrent sessions. So it will be arc plus blackbird. One will follow saw video, one will follow. I will say CL video. So PERSON4, if you put, could put a link here. Please add a link – PERSON4 – And, I will put a link, PERSON6 will put a link here. Yeah, so this will be the two videos. We will start them, and we will watch that. The pipeline will be probably the very same. But still, you should like, have it as two separate pipelines. And you must not mess it up. And later. Like later Friday, or on, in, on Monday. The models will be updated with the, with the domain elected ones.\n",
      "\n",
      "3 - PERSON4: Yeah.\n",
      "PERSON6: So, on Friday, use – Two separate pipelines, but each running actually the same thing. Update the – each of the pipelines – Each of the pipelines on Monday for the two different domain adaptations. Yeah, so that is, that. And I'm curious about the evaluation, the scores, so PERSON8, you have mentioned that you are already doing some ASR.\n",
      "PERSON8: Yeah, so, I am compiling some days, are tasked for that. But I am, facing some issues. It's basically that some videos are not, are not, some videos are not properly into a 16 cave format. So I'm looking into that. So PERSON10 told me yesterday that there are some issues with some audio, and I have to do that manually if that does not happen.\n",
      "PERSON6: Yeah. So, this is essential – This should be – We should, we all should know like how to do it. It should be part of the automatic evaluation of a leader test set, right?\n",
      "PERSON8: It is, yeah, it is.\n",
      "PERSON6: That is, that is not working properly.\n",
      "PERSON8: Yeah. But there are some audio files, where it, it gets converted to, the MP3 format. But when you pass it to the sound system, or the sound system will not work on that.\n",
      "PERSON6: So this is this is strange. Issues with some files – With the – The 16 c – format, converted from so – Yeah, PERSON8, seek for any help you can get. If PERSON10 can do that, then, please tell PERSON10 to do it.\n",
      "PERSON8: Yeah, he is here with me, to do it. So I am doing it today, but –\n",
      "PERSON6: Yeah –\n",
      "PERSON8: That, that takes a bit of time, because I need to figure out which one is the one which is are getting passes where they. So once I know that I can keep a track of it, so, for future – Or actually, for future I would not. Would not need it, because once I have the web be file, I probably won't, won't need to do convert.\n",
      "PERSON6: Well, this, this should be actually – Can you still hear me? The sound quality is a little worse. So this should really be done, all the time. So every time we run this evaluation, it should be, run from scratch. So, every time, there should be a fresh download of a and fresh conversion and a fresh evaluation.\n",
      "PERSON8: Yeah. But still, if I am keeping track of the files, which, are – need to be manually converted, so that I can write a script, and it could take care of at least the known ones. And of course, if we add some new files, I can see for that later.\n",
      "PERSON6: Yeah. So this is an important thing that we should have, like come across, or it is, a months ago. Remember, it is, is – since August that I've been telling you that, that we want to evaluate on a later test set. And, like every time, you, you all. It is not just you, you personally, PERSON8. There were other things, obviously. But like, every time, you thought about that, you thought that, well, this will be easy. We will just run it. And only when you actually do it, you will see all the problems. So this is known, common. It is always like that. So that's a message for everybody. Before you try, you never know what would be the problem. So for example, the call that I had, that, there was, someone was interviewing me so they, they, they wanted to record the video. Zoom never worked as badly for me as it, as it was today for the recording. So before you do, you cannot say whether it will work or, or not. And here we are running on the, in the problems of conversion, of the, of the file formats. So hopefully, we will be able to, like, quickly get the numbers. So do you have any word error rates so far?\n",
      "PERSON8: No, I have not processed it. So PERSON1 said that, once, they get the transcript, we will done it together. Because he also has not thoroughly the system. So he wanted to do it together.\n",
      "PERSON6: Yeah, ye – And you have the –\n",
      "PERSON8: And I'll have a call with –\n",
      "PERSON6: Today.\n",
      "PERSON8: Yes.\n",
      "\n",
      "4 - PERSON6: Yes, that is very important. So PERSON1 is going to be extremely busy, because he is organising some event, tomorrow and over the weekend. So we, we must not rely on PERSON1, so today is your last chance to get it running before the, the weekend. And then only from Monday onwards, probably he, he could help. So that is that thing.\n",
      "PERSON8: Yeah.\n",
      "PERSON6: Than maybe, have also PERSON10 on that call with PERSON1? Is that planned that way?\n",
      "PERSON8: Not right now. I will ask PERSON10 if he is available.\n",
      "PERSON6: Please do. And, who else could be of any help there? So, my only thinking, is of PERSON11 who was able to simply come by and help immediately.\n",
      "PERSON8: Well, in this – I do not think anything will be, any – I don't know. For now, there are like a lot of things to run, but I'm also simplifying everything, so that, we won't have – I think –\n",
      "PERSON6: Yeah, okay. Yeah, so let's hope it will all work out. So, as soon as you have any numbers, please send them to me. Just, regardless how low or high the numbers are, this – Just receiving the numbers will be a big relief for me.\n",
      "PERSON8: I will, at least for – I, at least for, I will send you the numbers today. Yeah, so for which data set, the –\n",
      "PERSON8: It is a khanic admitted, that, it is the 2020, it's part of that.\n",
      "PERSON6: Khan, Khan Academy? Ok, it is just – I mispronounced it. So probably, you know the correct pronunciation, and I do not recognise it. Yeah. So there is these saw files. And these are more important, because they reflect the domain that we have for the SG1 meeting. And there is the money dogs, and these are important for the, SL domain.\n",
      "PERSON8: Yes, oh, okay, so, I, I, I will all the three.\n",
      "PERSON6: Yeah, okay, great. Yeah. And, so, I know that PERSON4 is working on the adaptation for the two domains. We'll do a Monday seminar, tomorrow, that we will like, one shot think. And, I'm very curious. So, PERSON4, are you taking a part in that call, with PERSON1 as well?\n",
      "PERSON4: No.\n",
      "PERSON6: I think it is a, I think you – you also should, because, you should also evaluate, the – So, I'm hoping that you will be able to have the multiple custom dictionaries in the, our system. The dictionaries that come from PERSON2, and that you will choose, which is the best, one. That you will have some numbers to, to choose – which of the ASR systems should be used. Which of the vocabulary should be used. And for that you need the evaluation. So, whatever you see by, shown by PERSON1, will be also useful for you. Unless you already know how to run SLTF.\n",
      "PERSON4: No, I don't know yet. And, so, I think there are some things to discuss about the, the multiple dictionaries. I received your email yesterday with, the thing I was – I mentioned in the mail, that the ASR system without using people's pronunciation was better than the one used with people's generated pronunciations.\n",
      "PERSON6: So, so, sorry, say it again, and be more precise. So PERSON2 sent this email with the four words, the Watson, IBM –\n",
      "PERSON4: Yes. So this was. So, I sent the, files to PERSON2, three kinds of IBM and three kinds of Watson.\n",
      "PERSON6: Yeah. So he sent me, the phonemes spoken in those files.\n",
      "PERSON6: Yeah.\n",
      "PERSON4: And so, since his model works on some ESL. And so he first recognised the words in the audio file, and then converted into phonemes and then sent it to me.\n",
      "PERSON6: Yeah.\n",
      "\n",
      "5 - PERSON4: So there was – For example, there was one file in which the word was for IBM. And so – The ESL decoded it, as I think, four IBM, and so the phonemes were. So in this way, he sent me the phonemes, and I added those pronunciations in my dictionary. And so the performance of de – description was exactly the same with the – without adding these pronunciations in their dictionaries. And the one, domain adaptation model, that I developed with my manual, pronunciations. The perform is slightly better than, these models.\n",
      "PERSON6: Okay, yeah. Yeah, well, this is too small of a sample. And then I know that – PERSON2 produced, the long, word list, right? And you have not tested that one yet.\n",
      "PERSON4: Yes, there is, there is a phoneme to grapheme list.\n",
      "PERSON6: Yes.\n",
      "PERSON4: I do not – So, or I'm confused. How can I use it as it is? I think, that can be used by developing for some model, from forming the graphic model and then using it.\n",
      "PERSON6: No, no, no. This is – This is exactly what you did with the Watson. So, you just swap the columns.\n",
      "PERSON4: Okay, okay.\n",
      "PERSON6: So you just convert the, the international phonetic alphabet into the phonemes, that, that CMU knows.\n",
      "PERSON4: So it means that, that the list should contain Watson.\n",
      "PERSON6: Well, I don't know if the list contains Watson, but it's –\n",
      "PERSON4: But I mean, it assumed that the list should contain our words –\n",
      "PERSON6: Yes. Yeah, yeah. And then, I agree that there is a lot of noise in this dictionary. So, the thing that I asked for, is that you would have various versions of this dictionary by taking only the words that were observed, five times. And only the pronunciations that were observed three times or more, or something like that. So, that way, these random errors, such as the example with this four IBM instead of IBM. This will be not so frequent. But still, you will have the variants in pronunciation, because if the person, says this alzo, if you remember, if he says this alzo with Z 20 times in the in the talk, then you will see that in the data with the Z. And if he sometimes manages to say correctly also, then yeah, again, you will see that in the data. So, I would like, PERSON4 to be in touch with PERSON2. Maybe you continue on call, right? I have to – I, I will have to leave now, because I need to give the kids, the, the, the lunch and so on. But please stay on this call and figure out jointly how to use that dictionary. So PERSON4, please show to PERSON2 what is the dictionary that the system is accepting. Share your screen, and, and show it. And PERSON2, please, have a look at that and help with converting the dictionary that you emitted to that file. One thing that will be still needed, is the, language model substitute. But all these words, should be like the known words. So PERSON4, you need to figure out what words are in the – in the language model. And the words which are in the language model, should be simply copied. So the, the dictionary will have three columns. The grapheme, as it is output. One recognised. The phonemes, as PERSON2 proposed. And there will be multiple lines with different phoneme variations. And the third column, that will be also the same again for all of those, and there will be, again, the same grapheme form. So that is when the language model sees. And I think that this way, the – these systems should be able to load it. And you will also possibly run into one more problem, that is not ready for two big custom dictionaries. So this is also something that has to be tested, but please test it, the you two together. So PERSON2 knows what he created in the dictionary. And you know what the dictionary looks like, when you are creating it manually, and you need to put these two knowledges – Pieces of knowledge together. So that it works with the, with the generated dictionary.\n",
      "PERSON4: Okay, okay.\n",
      "PERSON6: So PERSON2, does this make sense?\n",
      "PERSON2: Yeah, sure, we'll discuss it.\n",
      "PERSON6: Yeah, so is there anything else, PERSON2, that you – that you have?\n",
      "\n",
      "6 - PERSON2: Well, maybe, maybe interesting information for Dominik. I'm finishing training of a German ASR that may be used for, for time stamping. I'm not sure, how, good it will be because I'm trying to do it on Libry Speech. And although, when I was downloading, it, they claimed it has more than 600 hours. But then the training said that the actual training set contains only around 300 hours. And I'm still not sure whether this 300 hours does not contain, similar sentences. Or actually the same sentences, but spoken by, by, by different speakers. Yeah, so it's, it is, because, well – For example, in English or Czech I was used to, used to observe more steep conversions. And now it – now it, won't convert so fast. So, if, if I'm a – I, take, some samples of – during the training. Then there are some, still some, serious errors in the ASR output. So, so, maybe, I'm, I'm hopeful that for, for the time stamping, it is good enough. Or at least we, we might try it.\n",
      "PERSON1: Okay, sure. And is it possible to enrich the language model by texts, because we have lots of relevant texts from your parliament.\n",
      "PERSON2: Oh well, for, for the decoding. I, my views also language model. Well, it depends on what we want to do. If we want to just infer like, like open transcripts, then we can, we can use the language model. And we can, we can also get, get the time stamps for, for, for the transcript. If, if you have transcript, and we want just, want to do just a time stamping then there is no way how we can use the language model.\n",
      "PERSON1: Yes, I – We may need both. Transcripts for set. Or, I mean, forced alignment for the fantast set. And then reco – Recognition for, for the rest. For around a 100 hours.\n",
      "PERSON2: Well, there are for the recognition, there is possibility to use language model.\n",
      "PERSON1: Yeah.\n",
      "PERSON6: Yeah, thanks for the progress. Please discuss this separately. I just – because I really have to leave. I would like PERSON4 to stay on the call with PERSON2, right? And discuss how to use the dictionary. And I see PERSON10 here. So PERSON10, how much time do you have in the coming days?\n",
      "PERSON10: It actually depends on what day are we asking, like, I have some presentations to make an assignments are piling up.\n",
      "PERSON6: Yeah. So, well there is a lot of things that PERSON8 needs to do. And I think it would be good if you two would like split it among yourselves so that PERSON8 can manage that in time. So there is this, the scoring, some meeting with PERSON1 this afternoon. So I think you should really join that as well.\n",
      "PERSON10: Okay – PERSON4.\n",
      "PERSON6: Because this is the numbers that we want to obtain for the different models. And then PERSON8 needs to prepare to have the double system running. We will do first test of this tomorrow at 1 Prague time. So I think that if you, PERSON10, focused more on getting the numbers, and PERSON8 focus more on getting these systems running, then it would – Then we will reach the goals.\n",
      "PERSON10: Okay, makes sense, all right.\n",
      "PERSON6: So please discuss this separately to find the time, I don't know the meeting time for, with PERSON1. And, yeah – But I really want to see the numbers. So I would like to have the ASR numbers, today. And improved numbers on Monday, when PERSON4 has the domain adaptation for those. And then we will, on Monday, decide which of the models to use. And we can still move Monday to Tuesday, but Tuesday is already the PROJECT2 day. So the, the CL decision really has to happen on Monday. And we need at least two numbers to compare. So, get one number the baselines now and the – the improved on Monday.\n",
      "PERSON10: Okay, okay.\n",
      "\n",
      "7 - PERSON6: Okay, so I'm leaving at the moment. And if it, asks me to know. Now, PERSON8 is the host, so that is that is good. As long as the PERSON8 is on the call – Like you, the call can run. So please, PERSON4 and PERSON2, synchronise and PERSON10 follow that as well. And PERSON8, and you synchronise – And get the numbers and send any numbers to me today. So as, as a baseline. So thanks and sorry for taking more time. And fingers crossed for – for all the, for these tests. Thanks. All right.\n",
      "PERSON8: PERSON10, I'll send you a text on Slack later or –\n",
      "PERSON10: Yes.\n",
      "PERSON8: So later today. Because, I was mentioned by you on the call, call yesterday, or the day before yesterday. I tried processing it but I think some of the files, even in khanic terminators are, are those files, which doesn't get converted into 16 format pretty easily.\n",
      "PERSON10: Okay, that is not, not a big issue. But I'll take care of it again. So, are we discussing anything else? I would stay in the call but I see silence, so –\n",
      "PERSON7: By the way, what do you want compare, PERSON8? All the workers and their quality and latency?\n",
      "PERSON8: Actually mostly about the – It is basically about the error rates in multitranslation and the ASR?\n",
      "PERSON1: Yes, I think we have only one option for ASR, don't we? Only one ASR, or there are two?\n",
      "PERSON8: Sorry?\n",
      "PERSON1: How many ASR workers do we have?\n",
      "PERSON8: Right now. One is from K80. One is what we use for our Monday Seminars. That's two. Even with K80, we have two. One is the nearest one –\n",
      "PERSON1: Okay.\n",
      "PERSON8: Sequence to sequence, the other one is a normal one.\n",
      "PERSON1: Yeah.\n",
      "PERSON8: And in the Monday Seminar one, PERSON4 is going, do the adaptation. For – For – both the different tasks. And, finally, on Monday, we'll see, or which model performs best.\n",
      "PERSON1: Yes. When I did the comparison of the workers for SLT. Then I observed that, that there are no big differences in machine translation parts. But the, the bottleneck in quality, was the ASR quality. So you may select the best ASR worker in quality. And then, then, then pick the MT worker with the lowest latency and, and some good flicker. And latency and flicker may test quite, quite easily, on one document. And not, not, on the whole test set.\n",
      "PERSON8: Yes.\n",
      "PERSON10: I also – During the month of August, we also had numbers for the MT models. Where – What do I say, the rainbow MT models. Scores were better than our, our – I think, yeah, maybe or PERSON11 –\n",
      "PERSON8: It was PERSON3.\n",
      "PERSON10: You just, PERSON3?\n",
      "PERSON8: Think so.\n",
      "PERSON10: I'm not sure. No, I, you – I think you were not there, at that moment so – You may not know about it.\n",
      "PERSON8: I have the school so –\n",
      "PERSON10: Okay, you have this course, so – So – Actually, PERSON5 compared this course between – I think, it was rainbow and, summer set of workers. And rainbows set – a set of rainbow workers were better. I think it was PERSON11's, two, 43 to 43 languages. And that were kind of – They had like little lesser scores, I mean – Rainbow workers had better scores, in, in short, yeah.\n",
      "PERSON8: Okay, basically. What on the remission on the call is divorced to use individual translation workers. You can see if they are performing better. So if not, then obviously we can fall back to, to the rainbow.\n",
      "PERSON8: Okay, so I'll make PERSON4 the host now, because I will go and have my lunch. It is pretty late here, and I did had my lunch.\n",
      "PERSON10: Thank you, bye, bye. And text me on Slack in the weekend.\n",
      "PERSON1: Yeah, bye.\n",
      "PERSON11: Okay, PERSON7. Okay, I am –\n",
      "PERSON8: Bye.\n",
      "\n",
      "8 - PERSON11: I am just – trying to commit it. But – so okay. I have it in the good format now, but I just – because I'm just checking the folders. And for some folders, the output is like totally terrible. I don't know why is this.\n",
      "PERSON1: Okay.\n",
      "PERSON11: But for some folders, it is okay, for some it's terrible. Like all the words are some, just –\n",
      "PERSON1: It may be caused by the speaker. Maybe he doesn't speak clearly for the ASR.\n",
      "PERSON11: Because, like, it is just like the, most common words in the language, I would say, which are, which are recognised over and over. Like half of the world is like aber.\n",
      "PERSON1: Yeah. It may happen. Maybe you can, if you want to inspect it, then listen to the to the, to the source audio, and you will see. This is yeah, and it.\n",
      "PERSON11: Yeah, I'm trying to do this, yes.\n",
      "PERSON1: And it doesn't matter if, if we miss some, some, me of them. And the annotator will – Can and filter them out, by herself. We can keep them there –\n",
      "PERSON11: Because like for the first files it worked. And now I have files with Czech names. And fo – for this, it is working quite bad. So, yeah, it could be this.\n",
      "PERSON1: Yeah.\n",
      "PERSON11: I'm just going to check it once more, and then I will push it.\n",
      "PERSON1: Great. And it will be good to commit or to save the, to –\n",
      "PERSON11: I'd say it's probably not the speaker, but it's the files, because often for the files. Like when I converted them even to the right format. It just told me like FFMPEG again told me that, that there were wrong time stamps in the file, whatever that means. And basically, the – so – the yes – So, so I, I now see that the transcripts for, for these files are – don't have the right length. So they were processed incorrectly. And I'm not sure how, how to convert them properly, because FFMPEG just returns an error for those files, so – Yeah, but it does not support the format, actually.\n",
      "PERSON1: You may try sox.\n",
      "PERSON11: Yeah, but it doesn't support the format, actually.\n",
      "PERSON1: Which for – format, is it? OGG?\n",
      "PERSON11: It is – Yes, it's actually O – Wait. Then it should – I don't know why I didn't. I will try it once more. Okay, yeah, I will, I will. Then I really use soxi, okay. I don't know what was actually the problem. Okay, yeah. Because, because for most of the folders that I transcribed later, there's this problem, that basically – The length is incorrect. Oh, okay, so I will change this to soxi? And actually, how many, how many work – workers can I run in parallel on CPU? Is it like – can I run, let's say 100?\n",
      "PERSON1: On, on one machine, or?\n",
      "PERSON11: I don't know, like on anywhere.\n",
      "PERSON1: Or in Q to F, you can run 100.\n",
      "PERSON11: Okay, because right now –\n",
      "PERSON1: Or –\n",
      "PERSON11: Yeah. Because I think that right now the best way is to throw away everything and to run everything in parallel, so that like in one hour everything would be done.\n",
      "PERSON1: Yes. No, no, no, no problem.\n",
      "PERSON11: Because, because like now, I think for – maybe half of the files it would be, you know, like totally wrong. And that would like confuse everyone, and I can't really find which files it is, be –\n",
      "PERSON1: Yes.\n",
      "PERSON11: Because it's a lot of files. So I would have to open everything now, or.\n",
      "PERSON1: Yeah.\n",
      "PERSON11: So maybe I'll just change the converting – Okay.\n",
      "PERSON1: And the converting command is called sox. S, O, X. S, O, X, I is another commanded. It gives you only information. And you may google of the format of the conversion – for the conversion.\n",
      "PERSON11: Sorry. I accidentally refreshed – Okay, I will try it for one file if it works better. For this guy called strejček.\n",
      "PERSON1: PERSON2, are you still here?\n",
      "\n",
      "9 - PERSON2: Yeah.\n",
      "PERSON1: And how much time do you have to work on the German ASR? Can we – Can we, or should we go forward with the language models to process the interpreters?\n",
      "PERSON2: Like you would like to train a language model.\n",
      "PERSON1: Yes or –\n",
      "PERSON2: Well – I am – continuously saving checkpoints so I can already run the ASR. So if you provide me a la – language model, then I –\n",
      "PERSON1: I can only provide you the texts. The monolingual German text. The – In the European domain. And so it will be in domain. And then I hope there will be good quality for the recognition.\n",
      "PERSON2: Well, one more thing. My ASR is – lowercase. Is it okay for you?\n",
      "PERSON1: Yes.\n",
      "PERSON2: Okay. And without punctuation also.\n",
      "PERSON1: Yes, we don't –\n",
      "PERSON2: Okay.\n",
      "PERSON1: We don't care, so far.\n",
      "PERSON2: Right. Then you can provide me with it. I'm not sure whether I, I, get it done by today, but –\n",
      "PERSON1: No problem.\n",
      "PERSON2: Tomorrow, I think it could be done.\n",
      "PERSON1: Yeah.\n",
      "PERSON11: Okay, yeah, one more thing. So I figured out that actually, in the – in some of the files, there is – You don't just hear the interpreter, but you also hear the person saying something in English in the background. So maybe that could also be the problem. The speaking of the wrong person, actually.\n",
      "PERSON1: Yeah, only – only at the beginning or during the whole –\n",
      "PERSON11: Everywhere. That is the thing, everywhere.\n",
      "PERSON1: Yeah.\n",
      "PERSON11: But, so, if it does work now, then okay. If it doesn't work, then I can apply some kind of filter to cut off the – This effort with low volume, maybe.\n",
      "PERSON1: It's, it's okay or –\n",
      "PERSON11: Okay, I will just try how it works.\n",
      "PERSON1: Or we can ask the, the annotator, whether the transcription work helped, to spare the – her time. And, if she says that not, even when the quality is good, then, then we don't need to care much about the rest.\n",
      "PERSON11: Okay.\n",
      "PERSON1: And we are the focus on PERSON2's high quality on, on the others.\n",
      "PERSON4: PERSON2, we may discuss now?\n",
      "PERSON2: Fine.\n",
      "PERSON4: Now, we discuss, no? Or some thi, PERSON7?\n",
      "PERSON1: No, I, I think we are done. I will send an email to PERSON2.\n",
      "PERSON4: Okay, thank you.\n",
      "PERSON1: And I may disconnect this call. So see you.\n",
      "PERSON2: Bye.\n",
      "PERSON4: So, if I am sharing my screen, just a minute. I think can you see my screen?\n",
      "PERSON2: Yes.\n",
      "PERSON4: So, actually, this is the format of dictionary that is used by the ASR. And, the, so first one is the word. And the next is the pronunciation of the word and –\n",
      "PERSON2: And – This, this curly brackets, wha –\n",
      "PERSON4: I actually do not know why is this here. But there are the curly brackets around the pronunciation and be curly brackets around first and the last phoneme WB in there.\n",
      "PERSON2: And, and that some special mark, or, or –\n",
      "PERSON4: Which one?\n",
      "PERSON2: The WB.\n",
      "PERSON4: Yes, this is, this is, I don't know. Probably the, the requirement of the two kit. So it is WB for all the words.\n",
      "PERSON2: Okay, okay.\n",
      "PERSON4: It is the right before starting and ending phoneme. And even if – this is not there, I think it is not a big issue for me to append. But the problem is, so this is the, CMU dictionary. And it is actually, is in at public format. So I think you can find that, over, on Wikipedia, as well. By this alphabet.\n",
      "\n",
      "10 - PERSON2: Yeah. So it appeared to two, two letter. Is also available on there. And I – there is a – I under – They found a package of our language, which, which automatically converts the IP to alphabet the other way around. So that can be converted easily but the problem is, that, there a – phonemes, there are some IP formats that are not in alphabet. Just let – This – I couldn't –\n",
      "PERSON2: Okay.\n",
      "PERSON4: That wasn't converted by s – This is the email window. And so, there was - were some phonemes that were not converted into the alphabet phonemes. And, so, I am afraid that when I will be processing this list of graph – List of graphemes to phonemes, so probably there will be some issues regarding the, such phonemes. So if – I can share the other package with you, if, if you are familiar with that. It is very easy to use. Various manual is also available for that package, so – You can use that package as well. Or in any way, if you would convert these – this IPA a into alphabet phonemes that would be great for me. Is it possible?\n",
      "PERSON2: I can, take a look, at the – Well, I have a – Send you some link once. But I'm not sure where it was. Was it done – It was on Skype, I guess. I found some dictionary.\n",
      "PERSON4: Is it – But I think –\n",
      "PERSON2: CMU to IPI and – Well, this strange A, you mentioned. Can you copy the, the, the letter to chat please?\n",
      "PERSON4: And just let me –\n",
      "PERSON2: There it is.\n",
      "PERSON4: There was another, as well, but I – I don't remember with one it was exactly.\n",
      "PERSON4: Se – send another one.\n",
      "PERSON2: It seems that, there is no – Well, maybe we could replace this phoneme with some other one. Because actually, we want t, we want to – produce some a – variable pronunciation. So actually, actually. It's okay if we substitute, substitute it. I don't know how to copy this, but, if – There is some nice chart in, in Wikipedia, that shows you the nearest, nearest phonemes to this one. And the nearest one are, for example. you did – the link. These two or this one. These three, so we can, just, so we can just, copy. We can just substitute each word with this phoneme. With two other words, with both, or, or three other versions of that word with using these three, this three phonemes?\n",
      "PERSON4: Can you share the link of Wikipedia please? Because I think there may be some further phonemes problems. So you with that I would be okay.\n",
      "PERSON2: If you go to the vowels paragraph, then there is some mapping or some map of how, which phonemes are actually near, and which are more, far apart.\n",
      "PERSON4: Are you talking about this chart?\n",
      "PERSON2: Can you open it in your window, because I'm still seeing your common line. Yeah, yeah, this one. Yeah.\n",
      "PERSON4: I don't know the pronunciation of any of this.\n",
      "PERSON2: Sorry?\n",
      "PERSON4: I don't know the pronunciation of any of these vowels. So are they actually near when they are spoken, or?\n",
      "PERSON2: I, I guess that they are so – If – no – just open them. There should be some – There should be some examples. For example, for the open-mid, the central open-mid, the first, first IPA phoneme. If you click on it, then, for example, it's not bird like bird. Like the flying, flying animal, a bird. And there's this example. And if we go for, for, for the letter, we do not have in CMU. And there is an example like a nut, nut, bird, nut. Or –\n",
      "PERSON4: That's right, I will see it then –\n",
      "PERSON2: Or maybe – And it's in which word in our dictionary? It is in – Where it is? I am blind. Where did you find this? This rotated A.\n",
      "PERSON4: I think – It is IPM, it is. I think the better example is this third E in Watson.\n",
      "PERSON2: I do not see it there.\n",
      "PERSON4: It's, it's –\n",
      "PERSON2: It's the E.\n",
      "\n",
      "11 - PERSON4: Yes, it is a Watson, son and som here. Well, I guess that's quite near. And en, what son. Maybe, I'm well somehow, if you pronounce it and pronounce it incorrectly. Well, Sorry, sure I need to go, because I have another meeting. And I. I need to prepare myself. So please, please. Let us have a call tomorrow, have, have – Are you free, free tomorrow? I'm. For example, let's say, Where is my calendar?\n",
      "PERSON4: I think probably it will be difficult to have a call tomorrow. I will let you know an email or Slack, because tomorrow I am off for Friday prayer on Friday for 10 to 12. And then we have a test run with PERSON8 that we were discussing.\n",
      "PERSON2: Okay, yeah, sure.\n",
      "PERSON4: I think it will be difficult tomorrow.\n",
      "PERSON2: Let's just – Please just a write me what do you need from me, if you need from me to, to remap my dictionary to CMU, well, I can definitely do that. So is it what you need?\n",
      "PERSON4: Yes, if, if that can be done, it would be very great. Because I can do that, but I'm too many adaptation models. And so if you have time and you are not too busy. So, if you have time and you are not too busy, it would be great if you can do it.\n",
      "PERSON2: Well, okay, I can do that.\n",
      "PERSON4: If you could just convert this list into the CMU phonemes. So that, that would be IPA rather than IP. There will be the phonemes of alphabet.\n",
      "PERSON2: Sorry, once again, please?\n",
      "PERSON4: I'm saying that if you could just change these IPS to the alphabet phonemes, that would be great.\n",
      "PERSON2: To the, you mean?\n",
      "PERSON4: Yeah.\n",
      "PERSON2: Yeah, sure. Sure thing, okay. I will, will be in touch with you, probably tomorrow. Bye.\n",
      "PERSON4: Thank you, bye. PERSON11, can I just end the meeting?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, i in enumerate(segmented_transcript_short[m_id]):\n",
    "  print(f\"{idx} - {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1682953573974,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "nmVyodp41J9j",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def summarize(input_text):\n",
    "  summarization = summarizer(input_text)[0][\"summary_text\"].strip()\n",
    "  return summarization\n",
    "\n",
    "def generate_summaries(segmented_transcripts):\n",
    "  summaries = {}\n",
    "\n",
    "  for meeting_id, segmented_transcript in segmented_transcripts.items():\n",
    "    summarized_segments = [summarize(transcript_segment) for transcript_segment in segmented_transcript]\n",
    "    summaries[meeting_id] = \" \".join(summarized_segments)\n",
    "\n",
    "  return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "{'meeting_en_test2023_001': \"PERSON6, PERSON8, PERSON11, PERSON2, PERSON1 and PERSON12 are on a conference call. They are discussing some technical issues with the system. PERSON11 is interested in doing offline subtitling for the upcoming sessions. PERSON6 would like to implement natural shortening in the model as well. PERSON6 and PERSON4 are preparing the setups for PROJECT2 and PROJECT4 is working on the Monday seminar model. PERSON6 advises to update the pipelines on Friday. PERSON8 is doing some ASR today. Some videos are not properly converted into a 16 c format and some audio files are not working properly. PERSON1 is going to be busy tomorrow and over the weekend, so today is the last chance for PERSON6 to get it running before the weekend. PERSON8 will ask PERSON10 if he can help. PERSON4 is not taking part in the call with PERSON1 as well. PERSON4 and PERSON2 are on a call. PERSON4 explains to PERSON2 how to create a custom word list and how to use it. PERSON2 is finishing training of a German ASR that may be used for time stamping. There are some serious errors in the ASR output. The decision on which model to use will be made on Monday. The language model may need both the Transcripts and the Language Model. PERSON6 is leaving the call. PERSON8 is the host. PERSON10, PERSON4 and PERSON11 will synchronise and send the numbers to PERSON8. PERSON1 compares the quality of the ASR workers and their latency and flicker. There is only one ASR worker PERSON11 is having problems with transcribing files. He's trying to convert them to the correct format, but it doesn't support the format. It's not the speaker's fault, but the files themselves. PERSON2 will train a language model for the German ASR tomorrow. PERSON1 will send an email to PERSON2. PERSON2 and PERSON4 are having problems with converting IPA phonemes into alphabet sounds. They ask each other for help. PERSON4 wants to have a call with PERSON2 tomorrow, but it will be difficult as he is off for Friday prayer on Friday for 10 to 12 and has a test run with PERSON8 that they were discussing. He also wants to change the IPA to the alphabet phonem\"}"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_short = generate_summaries(segmented_transcript_short)\n",
    "summary_short"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 62, but you input_length is only 50. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=25)\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'meeting_en_test2023_001': \"PERSON6, PERSON8, PERSON11, PERSON1 and PERSON12 are on a conference call. They are discussing technical issues with the call. PERSON6 supports the idea of training empty systems to do speech translation. PERSON11 is thinking about joining the call. There are no students in Edinburgh who would have the time to do that. The only other candidates would be, PERSON13 from the PROJECT1, who works halfway in Prague and halfway in Brno. The webpage for PROJECT2 PERSON6 suggests to have a dry run of some past similar talks to PROJECT2 talks and to do the same thing with the Supreme Audit talks. PERSON4 is afraid the files won't be ready till tomorrow. PERSON8 can operate two local machines, Ark and blackbird, PERSON8 is compiling some ASR files for the leader test set. Some of the videos are not properly converted into a 16 c format and some audio files are not working properly. PERSON6, PERSON8, PERSON1 and PERSON11 are working on a system evaluation. It's their last chance to get it running before the weekend. PERSON8 will send the numbers for the data set to PERSON6 today. PERSON4 is working on the adaptation for the two domains. PERSON2 sent the files with the four words, the IBM Watson, three kinds of Watson and the phonemes spoken in them to PERSON4 PERSON4 explains to PERSON6 how the phoneme to grapheme list was prepared and compared with the other models. PERSON4 and PERSON2 are on a conference call. They are discussing how to create and store a dictionary. PERSON2 is finishing training of a German ASR that may be used for time stamping. The training set contains around 300 hours of recordings. There are possibilities to enrich the language model by texts and to use language model. The first test of the system will take place tomorrow at PERSON6, PERSON1, PERSON4, PERSON10 and PERSON8 want to compare the ASR numbers today and the improved numbers on Monday, so they can decide which of the models to use. The rainbow MT models had better scores than the MT models of PERSON3, PERSON11 and PERSON4 during the month of August. Some of their files are okay, others are terrible. PERSON11 is having problems with converting OGG files. The length of some of the transcripts is incorrect. People 1 and 2 are working on the German ASR. PERSON1 will send the monolingual German text to PERSON2 tomorrow. They will focus on PERSON2's high quality on the others. PERSON4 asks PERSON2 and PERSON3 to help her with some pronunciation problems with her language. PERSON2 asks PERSON4 to help him with pronunciation of vowels and consonants. Person2 also asks Person4 to convert IPA and CMU phonemes into the alphabet sounds. PERSON2 and PPerson4 will have a call tomorrow. PERSON4 wants to end the meeting with PERSON11.\"}"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_avg = generate_summaries(segmented_transcript_avg)\n",
    "summary_avg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "{'meeting_en_test2023_001': \"PERSON6 was in a call until the very last minute, so he didn't remind everybody to connect. His machine crashed and he had to restart it. Now he can hear people. The transcripts for check are almost done. The transcriber of Germany's working until December the 10th. PERSON1's mother is writing the question for the German subti- subtitle user study. PERSON6 is starting to write deliverables. PERSON11 has just added the transcripts for the The meme project does offline subtitling. Their mission is to create subtitles for the hearing-impaired. Their models work with sequence to sequence. They generate one word at a time. It would be possible to implement natural shortening in their models. PERSON11 is thinking about taking over the work of PERSON3, which is not ready for speech translation. PERSON6 wants an update for the sessions for the next week. PERSON4 will work on the webpage for PROJECT2 tomorrow. PERSON4 is away from 11 to 12 on Friday from ten to twelve. PERSON6, PERSON4 and PERSON8 are going to do the Zoom Test for YouTube videos at the same time tomorrow at one o'clock in the afternoon. PERSON8, PERSON4 and PERSON6 will prepare two presentations for the two domains. On Friday, they will prepare a test time for two concurrent sessions. On Monday, the models will be updated with the, with the domain elected ones. Some of the videos are not properly converted PERSON8 is manually converting audio files to MP3 format today. The sound quality is getting worse when passed to the sound system. PERSON6 has been telling people since August that they should have a test set to evaluate on a later test set. Every time they try to run it, they find out that it's not as easy as they thought. For example, the call that PERSON8 had, someone was PERSON8 will send the numbers for the data set to PERSON6 today. PERSON6 needs them immediately. PERSON4 is working on the adaptation for the two domains. There will be a Monday seminar on it. PERSON6 wants to have multiple custom dictionaries in the system. PERSON4 doesn't know how to run SLTF. The ASR system without using people's pronunciation was better than the one with people's generated pronunciations. PERSON2 produced a long, word list. There is a phoneme to grapheme list. The list should contain our words. There is a lot of noise in the dictionary. PERSON6 wants the system to sort it out by taking only the words that were observed five times or more, and only the pronunciations that were recorded three or more times. This way, random errors won't be frequent. PERSON PERSON4 and PERSON2 will work on the language model substitute and the generated dictionary together. PERSON2 is finishing training of a German ASR that may be used for time stamping. The training set contains around 300 hours of data, but there are some serious errors in the ASR output. PERSON1 and PERSON2 discuss how to enrich the language model by texts and PERSON6 wants to split the work among herself, PERSON4 and PERSON8, so that PERSON8 can focus more on getting the numbers and getting the systems running. He wants to have the ASR numbers today and improved numbers on Monday, when PERSON4 has the domain adaptation for PERSON6 is leaving the call. PERSON8 is the host. There are two ASR workers from K80, one of them is from the nearest one. There is only one option for ASR for multitranslation and the other one is a normal sequence. On Monday, PERSON1 did a comparison of the workers for SLT. The bottleneck in quality was the ASR quality. The MT worker with the lowest latency and flicker was selected. The rainbow MT model had better scores. PERSON11 is trying to commit the file. The output is terrible for some folders, but okay for others. It may be caused by the speaker's accent. PERSON1 wants to keep some files with Czech names. PERSON11 is having problems with FFMPEG. The transcripts for some of the files he transcribed don't have the right length, because they were processed incorrectly. The length is incorrect for most of the folders. The best solution would be to throw away everything and run everything in PERSON1 and PERSON2 are working on the German ASR. PERSON1 will provide PERSON2 with monolingual German text in the European domain and the ASR will be in lower case. PERSON1 will send an email to PERSON2. PERSON11 will try to fix the audio quality issues in some files. PERSON2 asks PERSON4 to help him with translating IPA into alphabet phonemes. PERSON2 and PERSON4 are trying to solve a pronunciation problem. They need to substitute a phoneme with another one to produce a different pronunciation. PERSON2 and PERSON4 are having problems with a computer program they are using. They have a test run with PERSON8 that they were discussing. PERSON2 wants to have a call with PERSON4 tomorrow and remap his dictionary to CMU. PERSON4 wants PERSON2 to convert the list of IPA characters into the CMU phonemes. PERSON2 agrees to do it.\"}"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_long = generate_summaries(segmented_transcript_long)\n",
    "summary_long"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "def create_minutes(summary):\n",
    "  sentences = sent_tokenize(summary)\n",
    "  minutes = []\n",
    "\n",
    "  for sentence in sentences:\n",
    "    # TODO custom fixes? (Person -> PERSON...)\n",
    "    # TODO ignore short sentences?\n",
    "\n",
    "    if sentence.startswith(\"PERSON\") or len(minutes) == 0:\n",
    "      minutes.append(\" -\" + sentence)\n",
    "    else:\n",
    "      minutes[-1] += \"\\n  \" + sentence\n",
    "\n",
    "  minutes = '\\n'.join(minutes)\n",
    "\n",
    "  return minutes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "def format_minutes(attendees, minutes):\n",
    "  tday = datetime.date.today()\n",
    "  att = \", \".join(attendees[0])\n",
    "  return f\"DATE : {tday}\\nATTENDEES : {att}\\n\\n\\nSUMMARY-\\n{minutes}\\n\\n\\nMinuted by: Team Synapse\"\n",
    "\n",
    "def generate_minutes(preprocessed_transcripts, output_dir):\n",
    "  for length in [512, 768, 1024]:\n",
    "    segmented_transcripts, attendees = segment_transcripts(length, preprocessed_transcripts)\n",
    "    summaries = generate_summaries(segmented_transcripts)\n",
    "\n",
    "    for meeting_id, summary in summaries.items():\n",
    "      minutes = format_minutes(attendees, create_minutes(summary))\n",
    "\n",
    "      os.makedirs(os.path.join(output_dir, meeting_id), exist_ok=True)\n",
    "      with open(os.path.join(output_dir, meeting_id, f\"length_{length}.txt\"), \"w\") as f:\n",
    "        f.write(minutes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "WmQHCqjgo-Zf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[45], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mgenerate_minutes\u001B[49m\u001B[43m(\u001B[49m\u001B[43melitr_preprocessed\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mOUTPUT_DIR\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mMODEL_SHORT_NAME\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mELITR_DATA_PATH\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m generate_minutes(europarl_preprocessed, os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(OUTPUT_DIR, MODEL_SHORT_NAME, EUROPARL_DATA_PATH))\n",
      "Cell \u001B[0;32mIn[44], line 9\u001B[0m, in \u001B[0;36mgenerate_minutes\u001B[0;34m(preprocessed_transcripts, output_dir)\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m length \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;241m512\u001B[39m, \u001B[38;5;241m768\u001B[39m, \u001B[38;5;241m1024\u001B[39m]:\n\u001B[1;32m      8\u001B[0m   segmented_transcripts, attendees \u001B[38;5;241m=\u001B[39m segment_transcripts(length, preprocessed_transcripts)\n\u001B[0;32m----> 9\u001B[0m   summaries \u001B[38;5;241m=\u001B[39m \u001B[43mgenerate_summaries\u001B[49m\u001B[43m(\u001B[49m\u001B[43msegmented_transcripts\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m   \u001B[38;5;28;01mfor\u001B[39;00m meeting_id, summary \u001B[38;5;129;01min\u001B[39;00m summaries\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m     12\u001B[0m     minutes \u001B[38;5;241m=\u001B[39m format_minutes(attendees, create_minutes(summary))\n",
      "Cell \u001B[0;32mIn[31], line 9\u001B[0m, in \u001B[0;36mgenerate_summaries\u001B[0;34m(segmented_transcripts)\u001B[0m\n\u001B[1;32m      6\u001B[0m summaries \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m meeting_id, segmented_transcript \u001B[38;5;129;01min\u001B[39;00m segmented_transcripts\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m----> 9\u001B[0m   summarized_segments \u001B[38;5;241m=\u001B[39m [summarize(transcript_segment) \u001B[38;5;28;01mfor\u001B[39;00m transcript_segment \u001B[38;5;129;01min\u001B[39;00m segmented_transcript]\n\u001B[1;32m     10\u001B[0m   summaries[meeting_id] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(summarized_segments)\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m summaries\n",
      "Cell \u001B[0;32mIn[31], line 9\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m      6\u001B[0m summaries \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m meeting_id, segmented_transcript \u001B[38;5;129;01min\u001B[39;00m segmented_transcripts\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m----> 9\u001B[0m   summarized_segments \u001B[38;5;241m=\u001B[39m [\u001B[43msummarize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtranscript_segment\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m transcript_segment \u001B[38;5;129;01min\u001B[39;00m segmented_transcript]\n\u001B[1;32m     10\u001B[0m   summaries[meeting_id] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(summarized_segments)\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m summaries\n",
      "Cell \u001B[0;32mIn[31], line 2\u001B[0m, in \u001B[0;36msummarize\u001B[0;34m(input_text)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msummarize\u001B[39m(input_text):\n\u001B[0;32m----> 2\u001B[0m   summarization \u001B[38;5;241m=\u001B[39m \u001B[43msummarizer\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_text\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msummary_text\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mstrip()\n\u001B[1;32m      3\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m summarization\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/transformers/pipelines/text2text_generation.py:265\u001B[0m, in \u001B[0;36mSummarizationPipeline.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    241\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    242\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    243\u001B[0m \u001B[38;5;124;03m    Summarize the text(s) given as inputs.\u001B[39;00m\n\u001B[1;32m    244\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    263\u001B[0m \u001B[38;5;124;03m          ids of the summary.\u001B[39;00m\n\u001B[1;32m    264\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 265\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/transformers/pipelines/text2text_generation.py:165\u001B[0m, in \u001B[0;36mText2TextGenerationPipeline.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    136\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    137\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    138\u001B[0m \u001B[38;5;124;03m    Generate the output text(s) using text(s) given as inputs.\u001B[39;00m\n\u001B[1;32m    139\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    162\u001B[0m \u001B[38;5;124;03m          ids of the generated text.\u001B[39;00m\n\u001B[1;32m    163\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 165\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    166\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    167\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(args[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;28mlist\u001B[39m)\n\u001B[1;32m    168\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mall\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(el, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m el \u001B[38;5;129;01min\u001B[39;00m args[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m    169\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mall\u001B[39m(\u001B[38;5;28mlen\u001B[39m(res) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m result)\n\u001B[1;32m    170\u001B[0m     ):\n\u001B[1;32m    171\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [res[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m result]\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/transformers/pipelines/base.py:1109\u001B[0m, in \u001B[0;36mPipeline.__call__\u001B[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1101\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mnext\u001B[39m(\n\u001B[1;32m   1102\u001B[0m         \u001B[38;5;28miter\u001B[39m(\n\u001B[1;32m   1103\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_iterator(\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1106\u001B[0m         )\n\u001B[1;32m   1107\u001B[0m     )\n\u001B[1;32m   1108\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1109\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_single\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreprocess_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforward_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpostprocess_params\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/transformers/pipelines/base.py:1116\u001B[0m, in \u001B[0;36mPipeline.run_single\u001B[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001B[0m\n\u001B[1;32m   1114\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_single\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001B[1;32m   1115\u001B[0m     model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocess(inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpreprocess_params)\n\u001B[0;32m-> 1116\u001B[0m     model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mforward_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1117\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpostprocess(model_outputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpostprocess_params)\n\u001B[1;32m   1118\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/transformers/pipelines/base.py:1015\u001B[0m, in \u001B[0;36mPipeline.forward\u001B[0;34m(self, model_inputs, **forward_params)\u001B[0m\n\u001B[1;32m   1013\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m inference_context():\n\u001B[1;32m   1014\u001B[0m         model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ensure_tensor_on_device(model_inputs, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m-> 1015\u001B[0m         model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mforward_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1016\u001B[0m         model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ensure_tensor_on_device(model_outputs, device\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m   1017\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/transformers/pipelines/text2text_generation.py:187\u001B[0m, in \u001B[0;36mText2TextGenerationPipeline._forward\u001B[0;34m(self, model_inputs, **generate_kwargs)\u001B[0m\n\u001B[1;32m    185\u001B[0m generate_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_length\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m generate_kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_length\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mmax_length)\n\u001B[1;32m    186\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_inputs(input_length, generate_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmin_length\u001B[39m\u001B[38;5;124m\"\u001B[39m], generate_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_length\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m--> 187\u001B[0m output_ids \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mgenerate_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    188\u001B[0m out_b \u001B[38;5;241m=\u001B[39m output_ids\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    189\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mframework \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/transformers/generation/utils.py:1524\u001B[0m, in \u001B[0;36mGenerationMixin.generate\u001B[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, streamer, **kwargs)\u001B[0m\n\u001B[1;32m   1517\u001B[0m     input_ids, model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_expand_inputs_for_generation(\n\u001B[1;32m   1518\u001B[0m         input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[1;32m   1519\u001B[0m         expand_size\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mnum_beams,\n\u001B[1;32m   1520\u001B[0m         is_encoder_decoder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder,\n\u001B[1;32m   1521\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[1;32m   1522\u001B[0m     )\n\u001B[1;32m   1523\u001B[0m     \u001B[38;5;66;03m# 13. run beam search\u001B[39;00m\n\u001B[0;32m-> 1524\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbeam_search\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1525\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1526\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeam_scorer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1527\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlogits_processor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlogits_processor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1528\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstopping_criteria\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstopping_criteria\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpad_token_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpad_token_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1530\u001B[0m \u001B[43m        \u001B[49m\u001B[43meos_token_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meos_token_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1531\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_scores\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutput_scores\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1532\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_dict_in_generate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreturn_dict_in_generate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1533\u001B[0m \u001B[43m        \u001B[49m\u001B[43msynced_gpus\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msynced_gpus\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1534\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1535\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m is_beam_sample_gen_mode:\n\u001B[1;32m   1538\u001B[0m     \u001B[38;5;66;03m# 11. prepare logits warper\u001B[39;00m\n\u001B[1;32m   1539\u001B[0m     logits_warper \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_logits_warper(generation_config)\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/transformers/generation/utils.py:2810\u001B[0m, in \u001B[0;36mGenerationMixin.beam_search\u001B[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001B[0m\n\u001B[1;32m   2806\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m   2808\u001B[0m model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprepare_inputs_for_generation(input_ids, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs)\n\u001B[0;32m-> 2810\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2811\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2812\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   2813\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2814\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2815\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2817\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m synced_gpus \u001B[38;5;129;01mand\u001B[39;00m this_peer_finished:\n\u001B[1;32m   2818\u001B[0m     cur_len \u001B[38;5;241m=\u001B[39m cur_len \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/transformers/models/bart/modeling_bart.py:1378\u001B[0m, in \u001B[0;36mBartForConditionalGeneration.forward\u001B[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1373\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m decoder_input_ids \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m decoder_inputs_embeds \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1374\u001B[0m         decoder_input_ids \u001B[38;5;241m=\u001B[39m shift_tokens_right(\n\u001B[1;32m   1375\u001B[0m             labels, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mpad_token_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mdecoder_start_token_id\n\u001B[1;32m   1376\u001B[0m         )\n\u001B[0;32m-> 1378\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1379\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1380\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1381\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdecoder_input_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_input_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1382\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1383\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdecoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1384\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1385\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdecoder_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1386\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcross_attn_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcross_attn_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1387\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1388\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1389\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdecoder_inputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_inputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1390\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1391\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1392\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1393\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1394\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1396\u001B[0m lm_logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlm_head(outputs[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m   1397\u001B[0m lm_logits \u001B[38;5;241m=\u001B[39m lm_logits \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfinal_logits_bias\u001B[38;5;241m.\u001B[39mto(lm_logits\u001B[38;5;241m.\u001B[39mdevice)\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/transformers/models/bart/modeling_bart.py:1260\u001B[0m, in \u001B[0;36mBartModel.forward\u001B[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1253\u001B[0m     encoder_outputs \u001B[38;5;241m=\u001B[39m BaseModelOutput(\n\u001B[1;32m   1254\u001B[0m         last_hidden_state\u001B[38;5;241m=\u001B[39mencoder_outputs[\u001B[38;5;241m0\u001B[39m],\n\u001B[1;32m   1255\u001B[0m         hidden_states\u001B[38;5;241m=\u001B[39mencoder_outputs[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(encoder_outputs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1256\u001B[0m         attentions\u001B[38;5;241m=\u001B[39mencoder_outputs[\u001B[38;5;241m2\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(encoder_outputs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1257\u001B[0m     )\n\u001B[1;32m   1259\u001B[0m \u001B[38;5;66;03m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001B[39;00m\n\u001B[0;32m-> 1260\u001B[0m decoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1261\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_input_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1262\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1263\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_outputs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1264\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1265\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1266\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcross_attn_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcross_attn_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1267\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1268\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_inputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1269\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1270\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1271\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1272\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1273\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1275\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m return_dict:\n\u001B[1;32m   1276\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m decoder_outputs \u001B[38;5;241m+\u001B[39m encoder_outputs\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/transformers/models/bart/modeling_bart.py:1118\u001B[0m, in \u001B[0;36mBartDecoder.forward\u001B[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1107\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mcheckpoint\u001B[38;5;241m.\u001B[39mcheckpoint(\n\u001B[1;32m   1108\u001B[0m         create_custom_forward(decoder_layer),\n\u001B[1;32m   1109\u001B[0m         hidden_states,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1115\u001B[0m         \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1116\u001B[0m     )\n\u001B[1;32m   1117\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1118\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mdecoder_layer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1119\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1120\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1121\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1122\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1123\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1124\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcross_attn_layer_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1125\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcross_attn_head_mask\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcross_attn_head_mask\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\n\u001B[1;32m   1126\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1127\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1128\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1129\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1130\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1133\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache:\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/transformers/models/bart/modeling_bart.py:447\u001B[0m, in \u001B[0;36mBartDecoderLayer.forward\u001B[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001B[0m\n\u001B[1;32m    445\u001B[0m \u001B[38;5;66;03m# cross_attn cached key/values tuple is at positions 3,4 of present_key_value tuple\u001B[39;00m\n\u001B[1;32m    446\u001B[0m cross_attn_past_key_value \u001B[38;5;241m=\u001B[39m past_key_value[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m:] \u001B[38;5;28;01mif\u001B[39;00m past_key_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 447\u001B[0m hidden_states, cross_attn_weights, cross_attn_present_key_value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder_attn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    448\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    449\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkey_value_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    450\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    451\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcross_attn_layer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    452\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcross_attn_past_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    453\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    454\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    455\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mfunctional\u001B[38;5;241m.\u001B[39mdropout(hidden_states, p\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining)\n\u001B[1;32m    456\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m residual \u001B[38;5;241m+\u001B[39m hidden_states\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/transformers/models/bart/modeling_bart.py:194\u001B[0m, in \u001B[0;36mBartAttention.forward\u001B[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001B[0m\n\u001B[1;32m    191\u001B[0m bsz, tgt_len, _ \u001B[38;5;241m=\u001B[39m hidden_states\u001B[38;5;241m.\u001B[39msize()\n\u001B[1;32m    193\u001B[0m \u001B[38;5;66;03m# get query proj\u001B[39;00m\n\u001B[0;32m--> 194\u001B[0m query_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mq_proj\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscaling\n\u001B[1;32m    195\u001B[0m \u001B[38;5;66;03m# get key, value proj\u001B[39;00m\n\u001B[1;32m    196\u001B[0m \u001B[38;5;66;03m# `past_key_value[0].shape[2] == key_value_states.shape[1]`\u001B[39;00m\n\u001B[1;32m    197\u001B[0m \u001B[38;5;66;03m# is checking that the `sequence_length` of the `past_key_value` is the same as\u001B[39;00m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;66;03m# the provided `key_value_states` to support prefix tuning\u001B[39;00m\n\u001B[1;32m    199\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    200\u001B[0m     is_cross_attention\n\u001B[1;32m    201\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m past_key_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    202\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m past_key_value[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m2\u001B[39m] \u001B[38;5;241m==\u001B[39m key_value_states\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m    203\u001B[0m ):\n\u001B[1;32m    204\u001B[0m     \u001B[38;5;66;03m# reuse k,v, cross_attentions\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "generate_minutes(elitr_preprocessed, os.path.join(OUTPUT_DIR, MODEL_SHORT_NAME, ELITR_DATA_PATH))\n",
    "generate_minutes(europarl_preprocessed, os.path.join(OUTPUT_DIR, MODEL_SHORT_NAME, EUROPARL_DATA_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xJh02iTH2tGS"
   },
   "source": [
    "# TextRank Scipt for ranking sentences\n",
    "This method uses GloVe Embeddings to calculate similarity score with the help of cosine similairty, and ranks individual sentences with the help of the PageRank Algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1155,
     "status": "ok",
     "timestamp": 1682551898666,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "tBJaRqQAEHKV",
    "outputId": "f9b518e0-de5b-40a5-e88b-c735b179c040"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/michelle/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/michelle/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt') # one time execution\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import networkx as nx\n",
    "import os\n",
    "import math\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fwK8kem-33KA"
   },
   "outputs": [],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip glove*.zip -d models/glove\n",
    "!rm -rf glove*.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TPsMhR5S06FU"
   },
   "outputs": [],
   "source": [
    "def get_minutes(data_path):\n",
    "    minute_files = {}\n",
    "    data_folders = [os.path.basename(x[0]) for x in os.walk(data_path) if len(os.path.basename(x[0])) > 0]\n",
    "    for directory in sorted(data_folders):\n",
    "        minute_files[directory] = {}\n",
    "        for file_name in sorted(os.listdir(os.path.join(data_path, directory))):\n",
    "            file_path = os.path.join(data_path, directory, file_name)\n",
    "            with open(file_path, \"r\") as f:\n",
    "                minute_files[directory][file_name] = f.read().splitlines()\n",
    "    return minute_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WBLagKSM06FU"
   },
   "outputs": [],
   "source": [
    "minute_path_train = '../automin2023/minutes/en/train/'\n",
    "minute_path_dev = '../automin2023/minutes/en/dev/'\n",
    "minute_path_test = '../automin2023/minutes/en/test/'\n",
    "minute_path_test2 = '../automin2023/minutes/en/test2/'\n",
    "\n",
    "output_minute_path_train = '../automin2023/minutes/en/train/final/'\n",
    "output_minute_path_dev = '../automin2023/minutes/en/dev/final/'\n",
    "output_minute_path_test = '../automin2023/minutes/en/final/'\n",
    "output_minute_path_test2 = '../automin2023/minutes/en/test2/final/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cDcPcGai06FU"
   },
   "outputs": [],
   "source": [
    "def get_sentence_vectors(row, word_embeddings):\n",
    "    sentence_vector = None\n",
    "    sentence = row['sentence']\n",
    "    if len(sentence) != 0:\n",
    "      sentence_vector = sum([word_embeddings.get(w, np.zeros((100,))) for w in sentence.split()])/(len(sentence.split())+0.001)\n",
    "    else:\n",
    "      sentence_vector = np.zeros((100,))\n",
    "    return sentence_vector\n",
    "\n",
    "def add_sentence_vectors(clean_sentences, word_embeddings):\n",
    "\n",
    "  # EXTRACT SENTENCE VECTORS\n",
    "  clean_sentences['sentence_vector'] = clean_sentences.apply(lambda x: get_sentence_vectors(x, word_embeddings), axis=1)\n",
    "  return clean_sentences\n",
    "\n",
    "\n",
    "def clean_minute_sentences(summary):\n",
    "\n",
    "    # os.chdir(path)\n",
    "    summaries = []\n",
    "    # for file1 in sorted(os.listdir()):\n",
    "    summary = summary[5:-3]\n",
    "    text = ''\n",
    "    for line in summary:\n",
    "        line = line.replace(' -', '')\n",
    "        line = line.replace('  ', '')\n",
    "        line = line.replace('\\n', '')\n",
    "        text = text + line + ' '\n",
    "    summaries.append(text)\n",
    "\n",
    "    sentences = []\n",
    "    for s in summaries:\n",
    "        sentences.append(sent_tokenize(s))\n",
    "\n",
    "    sentences = [(idx, y) for x in sentences for idx, y in enumerate(x)] # flatten list\n",
    "    print('Total no. of sentences: ', len(sentences))\n",
    "\n",
    "    # REMOVE PUNCTUATIONS, NUMBERS AND SPECIAL CHARACTERS\n",
    "    clean_sentences = pd.DataFrame(sentences, columns = ['order', 'sentence'])\n",
    "\n",
    "\n",
    "    # MAKE ALPHABETS TO LOWERCASE\n",
    "    clean_sentences['sentence'] = clean_sentences['sentence'].str.replace(\"[^a-zA-Z]\", \" \").str.lower()\n",
    "\n",
    "    # REMOVE STOPWORDS\n",
    "    stop_words = stopwords.words('english')\n",
    "\n",
    "    def remove_stopwords(sen):\n",
    "        sen_new = \" \".join([i for i in sen if i not in stop_words])\n",
    "        return sen_new\n",
    "\n",
    "    clean_sentences['sentence'] = clean_sentences['sentence'].apply(lambda x: remove_stopwords(x.split()))\n",
    "    return sentences, clean_sentences\n",
    "\n",
    "\n",
    "\n",
    "def calculate_similarity_and_rank(sentences, clean_sentences):\n",
    "  # INITIALIZE A SIMILARITY MATRIX\n",
    "  sim_mat = np.zeros([len(sentences), len(sentences)])\n",
    "\n",
    "  for i in range(len(sentences)):\n",
    "    for j in range(len(sentences)):\n",
    "      if i != j:\n",
    "        sim_mat[i][j] = cosine_similarity(clean_sentences['sentence_vector'][i].reshape(1,100), clean_sentences['sentence_vector'][j].reshape(1,100))[0,0]\n",
    "        \n",
    "  # PAGERANK SCORING\n",
    "  nx_graph = nx.from_numpy_array(sim_mat)\n",
    "  scores = nx.pagerank(nx_graph)\n",
    "  ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)\n",
    "\n",
    "  # ENTER THE PERCENTAGE OF SENTENCES THAT SEEM UNIFORMATIONAL,  THIS NUMBER IS USUALLY AROUND ~15% FOR THE MINUTES BELONGING TO A LENGTHY TRANSCRIPT\n",
    "  informative_sentences = []\n",
    "  rem_perc = 0.15\n",
    "  remove_count = math.ceil(len(sentences)*rem_perc)\n",
    "  for i in range(len(ranked_sentences)-remove_count):\n",
    "    informative_sentences.append(ranked_sentences[i][1])\n",
    "\n",
    "  informative_sentences.sort(key=lambda sentence: sentence[1][0])\n",
    "  informative_sentences = ['- ' + sentence[1] for sentence in informative_sentences]\n",
    "\n",
    "  return '\\n'.join(informative_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nO2wMYWo33yP"
   },
   "outputs": [],
   "source": [
    "def rank_and_regenerate_minutes(input_path, output_path):\n",
    "    # EXTRACT WORD VECTORS\n",
    "    minute_files = get_minutes(input_path)\n",
    "\n",
    "    word_embeddings = {}\n",
    "    f = open('models/glove/glove.6B.100d.txt', encoding='utf-8')\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        word_embeddings[word] = coefs\n",
    "    f.close()\n",
    "    for min_id in minute_files.keys():\n",
    "        print('Meeting ID: ', min_id)\n",
    "        os.makedirs(output_path + min_id)\n",
    "        for file_name, minutes in minute_files[min_id].items():\n",
    "            sentences, clean_sentences = clean_minute_sentences(minutes)\n",
    "            clean_sentences = add_sentence_vectors(clean_sentences, word_embeddings)\n",
    "            informative_sentences = calculate_similarity_and_rank(sentences, clean_sentences)\n",
    "            final_minutes =  '\\n'.join(minutes[:5]) + informative_sentences + '\\n'.join(minutes[-3:])\n",
    "\n",
    "            with open(output_path + min_id + '/' + file_name + '_final.txt', 'w') as out_file:\n",
    "                out_file.write(final_minutes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZGKkO13s06FW",
    "outputId": "e99970fe-a018-457f-b1e8-354178cfeee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of sentences:  31\n",
      "Total no. of sentences:  31\n",
      "Total no. of sentences:  31\n",
      "Total no. of sentences:  57\n",
      "Total no. of sentences:  56\n",
      "Total no. of sentences:  56\n",
      "Total no. of sentences:  40\n",
      "Total no. of sentences:  40\n",
      "Total no. of sentences:  40\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  8\n",
      "Total no. of sentences:  8\n",
      "Total no. of sentences:  8\n",
      "Total no. of sentences:  23\n",
      "Total no. of sentences:  23\n",
      "Total no. of sentences:  23\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[50], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m rank_and_regenerate_minutes(minute_path_test, output_minute_path_test)\n",
      "Cell \u001B[0;32mIn[49], line 18\u001B[0m, in \u001B[0;36mrank_and_regenerate_minutes\u001B[0;34m(input_path, output_path)\u001B[0m\n\u001B[1;32m     16\u001B[0m sentences, clean_sentences \u001B[39m=\u001B[39m clean_minute_sentences(minutes)\n\u001B[1;32m     17\u001B[0m clean_sentences \u001B[39m=\u001B[39m add_sentence_vectors(clean_sentences, word_embeddings)\n\u001B[0;32m---> 18\u001B[0m informative_sentences \u001B[39m=\u001B[39m calculate_similarity_and_rank(sentences, clean_sentences)\n\u001B[1;32m     19\u001B[0m final_minutes \u001B[39m=\u001B[39m  \u001B[39m'\u001B[39m\u001B[39m\\n\u001B[39;00m\u001B[39m'\u001B[39m\u001B[39m.\u001B[39mjoin(minutes[:\u001B[39m5\u001B[39m]) \u001B[39m+\u001B[39m informative_sentences \u001B[39m+\u001B[39m \u001B[39m'\u001B[39m\u001B[39m\\n\u001B[39;00m\u001B[39m'\u001B[39m\u001B[39m.\u001B[39mjoin(minutes[\u001B[39m-\u001B[39m\u001B[39m3\u001B[39m:])\n\u001B[1;32m     21\u001B[0m \u001B[39mwith\u001B[39;00m \u001B[39mopen\u001B[39m(output_path \u001B[39m+\u001B[39m min_id \u001B[39m+\u001B[39m \u001B[39m'\u001B[39m\u001B[39m/\u001B[39m\u001B[39m'\u001B[39m \u001B[39m+\u001B[39m file_name \u001B[39m+\u001B[39m \u001B[39m'\u001B[39m\u001B[39m_final.txt\u001B[39m\u001B[39m'\u001B[39m, \u001B[39m'\u001B[39m\u001B[39mw\u001B[39m\u001B[39m'\u001B[39m) \u001B[39mas\u001B[39;00m out_file:\n",
      "Cell \u001B[0;32mIn[39], line 64\u001B[0m, in \u001B[0;36mcalculate_similarity_and_rank\u001B[0;34m(sentences, clean_sentences)\u001B[0m\n\u001B[1;32m     62\u001B[0m   \u001B[39mfor\u001B[39;00m j \u001B[39min\u001B[39;00m \u001B[39mrange\u001B[39m(\u001B[39mlen\u001B[39m(sentences)):\n\u001B[1;32m     63\u001B[0m     \u001B[39mif\u001B[39;00m i \u001B[39m!=\u001B[39m j:\n\u001B[0;32m---> 64\u001B[0m       sim_mat[i][j] \u001B[39m=\u001B[39m cosine_similarity(clean_sentences[\u001B[39m'\u001B[39;49m\u001B[39msentence_vector\u001B[39;49m\u001B[39m'\u001B[39;49m][i]\u001B[39m.\u001B[39;49mreshape(\u001B[39m1\u001B[39;49m,\u001B[39m100\u001B[39;49m), clean_sentences[\u001B[39m'\u001B[39;49m\u001B[39msentence_vector\u001B[39;49m\u001B[39m'\u001B[39;49m][j]\u001B[39m.\u001B[39;49mreshape(\u001B[39m1\u001B[39;49m,\u001B[39m100\u001B[39;49m))[\u001B[39m0\u001B[39m,\u001B[39m0\u001B[39m]\n\u001B[1;32m     66\u001B[0m \u001B[39m# PAGERANK SCORING\u001B[39;00m\n\u001B[1;32m     67\u001B[0m nx_graph \u001B[39m=\u001B[39m nx\u001B[39m.\u001B[39mfrom_numpy_array(sim_mat)\n",
      "File \u001B[0;32m~/Desktop/LCT/Year1-CharlesUniversity/Summer Term/Statistical Machine Translation/AutoMin2023/venv/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:1395\u001B[0m, in \u001B[0;36mcosine_similarity\u001B[0;34m(X, Y, dense_output)\u001B[0m\n\u001B[1;32m   1391\u001B[0m \u001B[39m# to avoid recursive import\u001B[39;00m\n\u001B[1;32m   1393\u001B[0m X, Y \u001B[39m=\u001B[39m check_pairwise_arrays(X, Y)\n\u001B[0;32m-> 1395\u001B[0m X_normalized \u001B[39m=\u001B[39m normalize(X, copy\u001B[39m=\u001B[39;49m\u001B[39mTrue\u001B[39;49;00m)\n\u001B[1;32m   1396\u001B[0m \u001B[39mif\u001B[39;00m X \u001B[39mis\u001B[39;00m Y:\n\u001B[1;32m   1397\u001B[0m     Y_normalized \u001B[39m=\u001B[39m X_normalized\n",
      "File \u001B[0;32m~/Desktop/LCT/Year1-CharlesUniversity/Summer Term/Statistical Machine Translation/AutoMin2023/venv/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:1817\u001B[0m, in \u001B[0;36mnormalize\u001B[0;34m(X, norm, axis, copy, return_norm)\u001B[0m\n\u001B[1;32m   1814\u001B[0m \u001B[39melse\u001B[39;00m:\n\u001B[1;32m   1815\u001B[0m     \u001B[39mraise\u001B[39;00m \u001B[39mValueError\u001B[39;00m(\u001B[39m\"\u001B[39m\u001B[39m'\u001B[39m\u001B[39m%d\u001B[39;00m\u001B[39m'\u001B[39m\u001B[39m is not a supported axis\u001B[39m\u001B[39m\"\u001B[39m \u001B[39m%\u001B[39m axis)\n\u001B[0;32m-> 1817\u001B[0m X \u001B[39m=\u001B[39m check_array(\n\u001B[1;32m   1818\u001B[0m     X,\n\u001B[1;32m   1819\u001B[0m     accept_sparse\u001B[39m=\u001B[39;49msparse_format,\n\u001B[1;32m   1820\u001B[0m     copy\u001B[39m=\u001B[39;49mcopy,\n\u001B[1;32m   1821\u001B[0m     estimator\u001B[39m=\u001B[39;49m\u001B[39m\"\u001B[39;49m\u001B[39mthe normalize function\u001B[39;49m\u001B[39m\"\u001B[39;49m,\n\u001B[1;32m   1822\u001B[0m     dtype\u001B[39m=\u001B[39;49mFLOAT_DTYPES,\n\u001B[1;32m   1823\u001B[0m )\n\u001B[1;32m   1824\u001B[0m \u001B[39mif\u001B[39;00m axis \u001B[39m==\u001B[39m \u001B[39m0\u001B[39m:\n\u001B[1;32m   1825\u001B[0m     X \u001B[39m=\u001B[39m X\u001B[39m.\u001B[39mT\n",
      "File \u001B[0;32m~/Desktop/LCT/Year1-CharlesUniversity/Summer Term/Statistical Machine Translation/AutoMin2023/venv/lib/python3.10/site-packages/sklearn/utils/validation.py:879\u001B[0m, in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[1;32m    877\u001B[0m         array \u001B[39m=\u001B[39m xp\u001B[39m.\u001B[39mastype(array, dtype, copy\u001B[39m=\u001B[39m\u001B[39mFalse\u001B[39;00m)\n\u001B[1;32m    878\u001B[0m     \u001B[39melse\u001B[39;00m:\n\u001B[0;32m--> 879\u001B[0m         array \u001B[39m=\u001B[39m _asarray_with_order(array, order\u001B[39m=\u001B[39;49morder, dtype\u001B[39m=\u001B[39;49mdtype, xp\u001B[39m=\u001B[39;49mxp)\n\u001B[1;32m    880\u001B[0m \u001B[39mexcept\u001B[39;00m ComplexWarning \u001B[39mas\u001B[39;00m complex_warning:\n\u001B[1;32m    881\u001B[0m     \u001B[39mraise\u001B[39;00m \u001B[39mValueError\u001B[39;00m(\n\u001B[1;32m    882\u001B[0m         \u001B[39m\"\u001B[39m\u001B[39mComplex data not supported\u001B[39m\u001B[39m\\n\u001B[39;00m\u001B[39m{}\u001B[39;00m\u001B[39m\\n\u001B[39;00m\u001B[39m\"\u001B[39m\u001B[39m.\u001B[39mformat(array)\n\u001B[1;32m    883\u001B[0m     ) \u001B[39mfrom\u001B[39;00m \u001B[39mcomplex_warning\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/LCT/Year1-CharlesUniversity/Summer Term/Statistical Machine Translation/AutoMin2023/venv/lib/python3.10/site-packages/sklearn/utils/_array_api.py:168\u001B[0m, in \u001B[0;36m_asarray_with_order\u001B[0;34m(array, dtype, order, copy, xp)\u001B[0m\n\u001B[1;32m    163\u001B[0m         \u001B[39mreturn\u001B[39;00m xp\u001B[39m.\u001B[39masarray(special\u001B[39m.\u001B[39mexpit(numpy\u001B[39m.\u001B[39masarray(X)))\n\u001B[1;32m    165\u001B[0m     \u001B[39mreturn\u001B[39;00m \u001B[39m1.0\u001B[39m \u001B[39m/\u001B[39m (\u001B[39m1.0\u001B[39m \u001B[39m+\u001B[39m xp\u001B[39m.\u001B[39mexp(\u001B[39m-\u001B[39mX))\n\u001B[0;32m--> 168\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39m_asarray_with_order\u001B[39m(array, dtype\u001B[39m=\u001B[39m\u001B[39mNone\u001B[39;00m, order\u001B[39m=\u001B[39m\u001B[39mNone\u001B[39;00m, copy\u001B[39m=\u001B[39m\u001B[39mNone\u001B[39;00m, xp\u001B[39m=\u001B[39m\u001B[39mNone\u001B[39;00m):\n\u001B[1;32m    169\u001B[0m \u001B[39m    \u001B[39m\u001B[39m\"\"\"Helper to support the order kwarg only for NumPy-backed arrays\u001B[39;00m\n\u001B[1;32m    170\u001B[0m \n\u001B[1;32m    171\u001B[0m \u001B[39m    Memory layout parameter `order` is not exposed in the Array API standard,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    179\u001B[0m \u001B[39m    is NumPy based, otherwise `order` is just silently ignored.\u001B[39;00m\n\u001B[1;32m    180\u001B[0m \u001B[39m    \"\"\"\u001B[39;00m\n\u001B[1;32m    181\u001B[0m     \u001B[39mif\u001B[39;00m xp \u001B[39mis\u001B[39;00m \u001B[39mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/Desktop/LCT/Year1-CharlesUniversity/Summer Term/Statistical Machine Translation/AutoMin2023/venv/lib/python3.10/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_trace_dispatch_regular.py:326\u001B[0m, in \u001B[0;36mThreadTracer.__call__\u001B[0;34m(self, frame, event, arg)\u001B[0m\n\u001B[1;32m    323\u001B[0m         \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_args \u001B[39m=\u001B[39m args\n\u001B[1;32m    324\u001B[0m \u001B[39m# ENDIF\u001B[39;00m\n\u001B[0;32m--> 326\u001B[0m     \u001B[39mdef\u001B[39;00m \u001B[39m__call__\u001B[39m(\u001B[39mself\u001B[39m, frame, event, arg):\n\u001B[1;32m    327\u001B[0m \u001B[39m        \u001B[39m\u001B[39m''' This is the callback used when we enter some context in the debugger.\u001B[39;00m\n\u001B[1;32m    328\u001B[0m \n\u001B[1;32m    329\u001B[0m \u001B[39m        We also decorate the thread we are in with info about the debugging.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    337\u001B[0m \u001B[39m            This is the global debugger (this method should actually be added as a method to it).\u001B[39;00m\n\u001B[1;32m    338\u001B[0m \u001B[39m        '''\u001B[39;00m\n\u001B[1;32m    339\u001B[0m         \u001B[39m# IFDEF CYTHON\u001B[39;00m\n\u001B[1;32m    340\u001B[0m         \u001B[39m# cdef str filename;\u001B[39;00m\n\u001B[1;32m    341\u001B[0m         \u001B[39m# cdef str base;\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    350\u001B[0m         \u001B[39m# DEBUG = 'code_to_debug' in frame.f_code.co_filename\u001B[39;00m\n\u001B[1;32m    351\u001B[0m         \u001B[39m# if DEBUG: print('ENTER: trace_dispatch: %s %s %s %s' % (frame.f_code.co_filename, frame.f_lineno, event, frame.f_code.co_name))\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "rank_and_regenerate_minutes(minute_path_test, output_minute_path_test)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "dfff6636e432470c9f9b5e9327e06775": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f4e959e848074a36b692316a35c0ea44",
       "IPY_MODEL_c1b768bc7bda4f4bb72e1d9455d848f6",
       "IPY_MODEL_54b753d573ba4af5aae6e90eae730525"
      ],
      "layout": "IPY_MODEL_b91a7e309ec244f6bdbc1ee5cf4a748b"
     }
    },
    "f4e959e848074a36b692316a35c0ea44": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b2884184297c4ae2b72dc1653f473912",
      "placeholder": "​",
      "style": "IPY_MODEL_a48425092997483c97880427e1b370f8",
      "value": "Downloading (…)okenizer_config.json: 100%"
     }
    },
    "c1b768bc7bda4f4bb72e1d9455d848f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2dbae29561d44d00ba018fa6050f9651",
      "max": 26,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e359d34b57044c8290f114084129edbc",
      "value": 26
     }
    },
    "54b753d573ba4af5aae6e90eae730525": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_293cd5f4623e47819f237dfe800917d9",
      "placeholder": "​",
      "style": "IPY_MODEL_f1405f3c93e7431bad45566b04d28092",
      "value": " 26.0/26.0 [00:00&lt;00:00, 1.74kB/s]"
     }
    },
    "b91a7e309ec244f6bdbc1ee5cf4a748b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b2884184297c4ae2b72dc1653f473912": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a48425092997483c97880427e1b370f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2dbae29561d44d00ba018fa6050f9651": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e359d34b57044c8290f114084129edbc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "293cd5f4623e47819f237dfe800917d9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f1405f3c93e7431bad45566b04d28092": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b0e05b95d78949c2b5248144b4b53ef8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3419a24159d245e09f24a6de15579537",
       "IPY_MODEL_95d5b07289a5461e90d2863d52651437",
       "IPY_MODEL_0258c0f831864d76b8da412c72e1bcec"
      ],
      "layout": "IPY_MODEL_15fcefddfe1241e1912308a3e0369feb"
     }
    },
    "3419a24159d245e09f24a6de15579537": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_37d46921f77e433a8ee85fc5b26f731c",
      "placeholder": "​",
      "style": "IPY_MODEL_1c565184f62047d4ac2310ea0274954b",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "95d5b07289a5461e90d2863d52651437": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_210f248fc74a4f2cb2671e5f1850e784",
      "max": 1515,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_be16aa0d06634e559f5754a382902314",
      "value": 1515
     }
    },
    "0258c0f831864d76b8da412c72e1bcec": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9d5196deb05549d0b7ba47c8e2bd9b70",
      "placeholder": "​",
      "style": "IPY_MODEL_413d836d8a2049d684557a931b29459d",
      "value": " 1.51k/1.51k [00:00&lt;00:00, 116kB/s]"
     }
    },
    "15fcefddfe1241e1912308a3e0369feb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "37d46921f77e433a8ee85fc5b26f731c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c565184f62047d4ac2310ea0274954b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "210f248fc74a4f2cb2671e5f1850e784": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be16aa0d06634e559f5754a382902314": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9d5196deb05549d0b7ba47c8e2bd9b70": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "413d836d8a2049d684557a931b29459d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f7edb77d5a314f67879c075773f9f10d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_687c56454d1043f2b79d171810dfeb7f",
       "IPY_MODEL_551bbd9e8cdd445594f93bb87fc94720",
       "IPY_MODEL_356744cd08f64f9c9977b18e90101745"
      ],
      "layout": "IPY_MODEL_7e6273c05af04dba8538019b5dabe5e4"
     }
    },
    "687c56454d1043f2b79d171810dfeb7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a966c0de188464d8e40e0cdd3c8d50a",
      "placeholder": "​",
      "style": "IPY_MODEL_2e9b7e1831de42b19c7a7c2959bc683d",
      "value": "Downloading (…)olve/main/vocab.json: 100%"
     }
    },
    "551bbd9e8cdd445594f93bb87fc94720": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a6d6153c476f4df28d5ff439a15f4a68",
      "max": 898822,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_db78284b8e654440af7b8d3a69dd0aa0",
      "value": 898822
     }
    },
    "356744cd08f64f9c9977b18e90101745": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e907706ca3845e891c9fd380d44d92f",
      "placeholder": "​",
      "style": "IPY_MODEL_af05bfefe9a444b09286c8716d72b8c3",
      "value": " 899k/899k [00:00&lt;00:00, 14.8MB/s]"
     }
    },
    "7e6273c05af04dba8538019b5dabe5e4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a966c0de188464d8e40e0cdd3c8d50a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e9b7e1831de42b19c7a7c2959bc683d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a6d6153c476f4df28d5ff439a15f4a68": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db78284b8e654440af7b8d3a69dd0aa0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9e907706ca3845e891c9fd380d44d92f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af05bfefe9a444b09286c8716d72b8c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "37c98c759b094742b2fdb16d06296b17": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d4171be7b8b949fa8300301a06e3cb4c",
       "IPY_MODEL_46bcad2ebe4f42ac8f3c1766d5ccec49",
       "IPY_MODEL_9b24d42bb3f74204b63024820b670156"
      ],
      "layout": "IPY_MODEL_9ed9bc7814264744acb089f4dd53c453"
     }
    },
    "d4171be7b8b949fa8300301a06e3cb4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_29b916fbd0844450a84f25c1352068b4",
      "placeholder": "​",
      "style": "IPY_MODEL_fac3824f4c3a4c24a4e86a523e0dc8fd",
      "value": "Downloading (…)olve/main/merges.txt: 100%"
     }
    },
    "46bcad2ebe4f42ac8f3c1766d5ccec49": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d7f3dc64f3cf495b9cbcd7050cdd7502",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1ac19fa9c73d42e89ab53b515a439758",
      "value": 456318
     }
    },
    "9b24d42bb3f74204b63024820b670156": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f2fb7df4991e472a9f5307c7a4cce042",
      "placeholder": "​",
      "style": "IPY_MODEL_79cdbad0d1dc4f6ab324ac13dd317b8f",
      "value": " 456k/456k [00:00&lt;00:00, 716kB/s]"
     }
    },
    "9ed9bc7814264744acb089f4dd53c453": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "29b916fbd0844450a84f25c1352068b4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fac3824f4c3a4c24a4e86a523e0dc8fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d7f3dc64f3cf495b9cbcd7050cdd7502": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ac19fa9c73d42e89ab53b515a439758": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f2fb7df4991e472a9f5307c7a4cce042": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "79cdbad0d1dc4f6ab324ac13dd317b8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "79a8b1dd39ab4e4db3d9b099692e955a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2fa95194cd614752a83fd964a6af9839",
       "IPY_MODEL_f4e14fdbc7124a2c927f8ceae7837577",
       "IPY_MODEL_892b5f7aa84b4ae981379c09f5397a21"
      ],
      "layout": "IPY_MODEL_be362682da394b65beb1a67c6eec6a1f"
     }
    },
    "2fa95194cd614752a83fd964a6af9839": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_436643afb6404e03a3f3fe554dfb8a72",
      "placeholder": "​",
      "style": "IPY_MODEL_261c2a72381e40cb94c5c60cf0237d50",
      "value": "Downloading (…)/main/tokenizer.json: 100%"
     }
    },
    "f4e14fdbc7124a2c927f8ceae7837577": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_407d2cb054564c46881e2fff1b48705f",
      "max": 1355863,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2076cd74bf534668b7a85e8fc4ea2cc0",
      "value": 1355863
     }
    },
    "892b5f7aa84b4ae981379c09f5397a21": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4367fe694cd54f26b800f9ae19d2a8e2",
      "placeholder": "​",
      "style": "IPY_MODEL_a8ad1c8f7ebe44de9298c3c68241ee51",
      "value": " 1.36M/1.36M [00:00&lt;00:00, 6.57MB/s]"
     }
    },
    "be362682da394b65beb1a67c6eec6a1f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "436643afb6404e03a3f3fe554dfb8a72": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "261c2a72381e40cb94c5c60cf0237d50": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "407d2cb054564c46881e2fff1b48705f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2076cd74bf534668b7a85e8fc4ea2cc0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4367fe694cd54f26b800f9ae19d2a8e2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8ad1c8f7ebe44de9298c3c68241ee51": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b5d4c6556d5f4927a90780c4ea2cd515": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_98807b0cbaaa42bfbefe464c1c194166",
       "IPY_MODEL_5906ee8507074480b59086e52120b132",
       "IPY_MODEL_c50d2fec73aa4dc2a4d22bf266bbe322"
      ],
      "layout": "IPY_MODEL_4102431c863e43bd8e35567c14d89c64"
     }
    },
    "98807b0cbaaa42bfbefe464c1c194166": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a3de526b5d246df981d7714133a784d",
      "placeholder": "​",
      "style": "IPY_MODEL_a5f5e7d780c341efb20e1a60dd511261",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "5906ee8507074480b59086e52120b132": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_149ccf52c9b84a6b8791139bf5c1abe5",
      "max": 1625270765,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_de54ef26639f47e6b3c148d6ee025b86",
      "value": 1625270765
     }
    },
    "c50d2fec73aa4dc2a4d22bf266bbe322": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4a274883440848e1895d4c37911b1531",
      "placeholder": "​",
      "style": "IPY_MODEL_883614ba846d460895201d82bb29f597",
      "value": " 1.63G/1.63G [00:24&lt;00:00, 68.4MB/s]"
     }
    },
    "4102431c863e43bd8e35567c14d89c64": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a3de526b5d246df981d7714133a784d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a5f5e7d780c341efb20e1a60dd511261": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "149ccf52c9b84a6b8791139bf5c1abe5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de54ef26639f47e6b3c148d6ee025b86": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4a274883440848e1895d4c37911b1531": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "883614ba846d460895201d82bb29f597": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8ad79bc9e7604cad94978c3d51f5fe64": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_78f6244dbe4d4f69a77241ca759a0f76",
       "IPY_MODEL_32171595336644219238ca6aa86a3987",
       "IPY_MODEL_789e1174eb834523aa2d996da8d4f624"
      ],
      "layout": "IPY_MODEL_8e1a4e3068c94492a7c65486cf59b82c"
     }
    },
    "78f6244dbe4d4f69a77241ca759a0f76": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f836df9ac66c4415910f0da952f44461",
      "placeholder": "​",
      "style": "IPY_MODEL_0f5f1407d88845d388871e827eb377e8",
      "value": "Downloading (…)neration_config.json: 100%"
     }
    },
    "32171595336644219238ca6aa86a3987": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_693b5dd44a2e48a1b9634500713ecfa8",
      "max": 309,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2d708f20e51d46fa8da7e624f3f84c78",
      "value": 309
     }
    },
    "789e1174eb834523aa2d996da8d4f624": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e83b1ae3ea7246d7b2b7222b78c3df1d",
      "placeholder": "​",
      "style": "IPY_MODEL_d80cafc5015c456e8cf27031815aa841",
      "value": " 309/309 [00:00&lt;00:00, 10.9kB/s]"
     }
    },
    "8e1a4e3068c94492a7c65486cf59b82c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f836df9ac66c4415910f0da952f44461": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f5f1407d88845d388871e827eb377e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "693b5dd44a2e48a1b9634500713ecfa8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2d708f20e51d46fa8da7e624f3f84c78": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e83b1ae3ea7246d7b2b7222b78c3df1d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d80cafc5015c456e8cf27031815aa841": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}