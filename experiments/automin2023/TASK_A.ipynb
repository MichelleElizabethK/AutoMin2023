{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-8T_Vr4G76dv"
   },
   "source": [
    "# TEAM SYNAPSE : SUBMISSION FOR AUTOMIN 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48079,
     "status": "ok",
     "timestamp": 1682953253275,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "7e8XSCDO1M7w",
    "outputId": "b7f80afe-9436-47a2-9d81-b5837159c56d"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "#\n",
    "# %cd drive/MyDrive/AutoMin\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1682953502889,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "RSwS9Q7s1J9c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "PREPROCESSED_DIR = \"preprocessed_data\"\n",
    "OUTPUT_DIR = \"minutes\"\n",
    "\n",
    "EUROPARL_DATA_PATH = \"europarl/test1\"\n",
    "ELITR_DATA_PATH = \"elitr/en/test2023-en\"\n",
    "\n",
    "# MODEL_SHORT_NAME = \"bart-large-xsum\"\n",
    "MODEL_SHORT_NAME = \"MEETING_SUMMARY\"\n",
    "\n",
    "# MODEL = f\"facebook/{MODEL_SHORT_NAME}/\"\n",
    "MODEL = f\"knkarthick/{MODEL_SHORT_NAME}\"\n",
    "\n",
    "# SUMMARIZER_MODEL = f\"models/{MODEL_SHORT_NAME}/checkpoint-5500\"\n",
    "SUMMARIZER_MODEL = f\"knkarthick/{MODEL_SHORT_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "executionInfo": {
     "elapsed": 18359,
     "status": "ok",
     "timestamp": 1682953291212,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "vnvGXjEt06FF",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/kristyna/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/kristyna/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, pipeline, AutoModelForSeq2SeqLM\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import math\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 877,
     "status": "ok",
     "timestamp": 1682953307185,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "qB92jNAF5zg_",
    "outputId": "5130825e-1a39-493d-88bd-86f0cee851be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name())\n",
    "    torch.cuda.set_device(0)\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241,
     "referenced_widgets": [
      "dfff6636e432470c9f9b5e9327e06775",
      "f4e959e848074a36b692316a35c0ea44",
      "c1b768bc7bda4f4bb72e1d9455d848f6",
      "54b753d573ba4af5aae6e90eae730525",
      "b91a7e309ec244f6bdbc1ee5cf4a748b",
      "b2884184297c4ae2b72dc1653f473912",
      "a48425092997483c97880427e1b370f8",
      "2dbae29561d44d00ba018fa6050f9651",
      "e359d34b57044c8290f114084129edbc",
      "293cd5f4623e47819f237dfe800917d9",
      "f1405f3c93e7431bad45566b04d28092",
      "b0e05b95d78949c2b5248144b4b53ef8",
      "3419a24159d245e09f24a6de15579537",
      "95d5b07289a5461e90d2863d52651437",
      "0258c0f831864d76b8da412c72e1bcec",
      "15fcefddfe1241e1912308a3e0369feb",
      "37d46921f77e433a8ee85fc5b26f731c",
      "1c565184f62047d4ac2310ea0274954b",
      "210f248fc74a4f2cb2671e5f1850e784",
      "be16aa0d06634e559f5754a382902314",
      "9d5196deb05549d0b7ba47c8e2bd9b70",
      "413d836d8a2049d684557a931b29459d",
      "f7edb77d5a314f67879c075773f9f10d",
      "687c56454d1043f2b79d171810dfeb7f",
      "551bbd9e8cdd445594f93bb87fc94720",
      "356744cd08f64f9c9977b18e90101745",
      "7e6273c05af04dba8538019b5dabe5e4",
      "5a966c0de188464d8e40e0cdd3c8d50a",
      "2e9b7e1831de42b19c7a7c2959bc683d",
      "a6d6153c476f4df28d5ff439a15f4a68",
      "db78284b8e654440af7b8d3a69dd0aa0",
      "9e907706ca3845e891c9fd380d44d92f",
      "af05bfefe9a444b09286c8716d72b8c3",
      "37c98c759b094742b2fdb16d06296b17",
      "d4171be7b8b949fa8300301a06e3cb4c",
      "46bcad2ebe4f42ac8f3c1766d5ccec49",
      "9b24d42bb3f74204b63024820b670156",
      "9ed9bc7814264744acb089f4dd53c453",
      "29b916fbd0844450a84f25c1352068b4",
      "fac3824f4c3a4c24a4e86a523e0dc8fd",
      "d7f3dc64f3cf495b9cbcd7050cdd7502",
      "1ac19fa9c73d42e89ab53b515a439758",
      "f2fb7df4991e472a9f5307c7a4cce042",
      "79cdbad0d1dc4f6ab324ac13dd317b8f",
      "79a8b1dd39ab4e4db3d9b099692e955a",
      "2fa95194cd614752a83fd964a6af9839",
      "f4e14fdbc7124a2c927f8ceae7837577",
      "892b5f7aa84b4ae981379c09f5397a21",
      "be362682da394b65beb1a67c6eec6a1f",
      "436643afb6404e03a3f3fe554dfb8a72",
      "261c2a72381e40cb94c5c60cf0237d50",
      "407d2cb054564c46881e2fff1b48705f",
      "2076cd74bf534668b7a85e8fc4ea2cc0",
      "4367fe694cd54f26b800f9ae19d2a8e2",
      "a8ad1c8f7ebe44de9298c3c68241ee51",
      "b5d4c6556d5f4927a90780c4ea2cd515",
      "98807b0cbaaa42bfbefe464c1c194166",
      "5906ee8507074480b59086e52120b132",
      "c50d2fec73aa4dc2a4d22bf266bbe322",
      "4102431c863e43bd8e35567c14d89c64",
      "5a3de526b5d246df981d7714133a784d",
      "a5f5e7d780c341efb20e1a60dd511261",
      "149ccf52c9b84a6b8791139bf5c1abe5",
      "de54ef26639f47e6b3c148d6ee025b86",
      "4a274883440848e1895d4c37911b1531",
      "883614ba846d460895201d82bb29f597",
      "8ad79bc9e7604cad94978c3d51f5fe64",
      "78f6244dbe4d4f69a77241ca759a0f76",
      "32171595336644219238ca6aa86a3987",
      "789e1174eb834523aa2d996da8d4f624",
      "8e1a4e3068c94492a7c65486cf59b82c",
      "f836df9ac66c4415910f0da952f44461",
      "0f5f1407d88845d388871e827eb377e8",
      "693b5dd44a2e48a1b9634500713ecfa8",
      "2d708f20e51d46fa8da7e624f3f84c78",
      "e83b1ae3ea7246d7b2b7222b78c3df1d",
      "d80cafc5015c456e8cf27031815aa841"
     ]
    },
    "executionInfo": {
     "elapsed": 90439,
     "status": "ok",
     "timestamp": 1682953400077,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "0ukVZnIADqw8",
    "outputId": "3df6d7ec-427d-4b06-ffbe-035aa297d712"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "device = 0 if torch.cuda.is_available() else None\n",
    "summarizer = pipeline(\"summarization\", model=SUMMARIZER_MODEL, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1682953509170,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "Wupr-PBc1J9g",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_preprocessed_transcripts(file_name):\n",
    "  with open(f\"{file_name}.json\", \"r\") as f:\n",
    "    preprocessed_transcripts = json.load(f)\n",
    "\n",
    "  return preprocessed_transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "executionInfo": {
     "elapsed": 2712,
     "status": "ok",
     "timestamp": 1682953512503,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "st2y7Snb1J9h",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "elitr_preprocessed = load_preprocessed_transcripts(os.path.join(PREPROCESSED_DIR, ELITR_DATA_PATH))\n",
    "europarl_preprocessed = load_preprocessed_transcripts(os.path.join(PREPROCESSED_DIR, EUROPARL_DATA_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "executionInfo": {
     "elapsed": 414,
     "status": "ok",
     "timestamp": 1682953851880,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "2zMtAUGgyq9I",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def segment_transcript(max_input_length, transcript, tokenizer):\n",
    "  def split_line(line, role, tokenizer):\n",
    "    splits = []\n",
    "\n",
    "    sentences = sent_tokenize(line)\n",
    "    split_idx = len(sentences)//2\n",
    "    line1 = \" \".join(sentences[:split_idx]) + '.\\n'\n",
    "    line2 = role + \": \" + \" \".join(sentences[split_idx:])\n",
    "\n",
    "    for line in [line1, line2]:\n",
    "      if len(tokenizer.encode(line)) >= max_input_length:\n",
    "        splits += split_line(line, role, tokenizer)\n",
    "      else:\n",
    "        splits.append(line)\n",
    "\n",
    "    return splits\n",
    "\n",
    "  roles = transcript['roles']\n",
    "  attendees = sorted(list(set(roles)))\n",
    "  utterances = transcript['utterances']\n",
    "  segmented_transcript = [\"\"]\n",
    "\n",
    "  for role, utterance in zip(roles, utterances):\n",
    "    line = role + ': ' + utterance + '\\n'\n",
    "    # TODO remove short lines?\n",
    "    tokenized_line = tokenizer.encode(line)\n",
    "\n",
    "    if len(tokenized_line)>=max_input_length:\n",
    "        line_splits = split_line(line, role, tokenizer)\n",
    "    else:\n",
    "        line_splits = [line]\n",
    "\n",
    "    for line_split in line_splits:\n",
    "        tokenized = tokenizer.encode(segmented_transcript[-1]+line_split)\n",
    "        if len(tokenized)>=max_input_length:\n",
    "            segmented_transcript.append(line_split)\n",
    "        else:\n",
    "            segmented_transcript[-1] += line_split\n",
    "\n",
    "  return segmented_transcript, attendees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1335,
     "status": "ok",
     "timestamp": 1682953553740,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "-6_e2PWcU30k",
    "outputId": "927c7d2c-bd0b-4a0a-cb67-ab59e2899258"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSON6: Hi, hello. Can you hear me?\n",
      "PERSON2: Yes.\n",
      "PERSON6: I do not hear anyone. I have to reconnect again. Or maybe can someone else, give it a try as well, because –\n",
      "PERSON2: I can hear you.\n",
      "PERSON6: PERSON11, can you say something as well. Because with PERSON2, I remember that PERSON2 also had some microphone issues at times.\n",
      "PERSON2: And you can hear – You cannot hear me or –\n",
      "PERSON6: Yeah. So. I'll try to reconnect. I'll – Yeah – So, PERSON8. Hello, can you say something?\n",
      "PERSON8: Oh yeah. Hi.\n",
      "PERSON6: Oh, yeah. I. I have to reconnect. Making PERSON8 the host, for now. Yeah. So, I'll make PERSON8 the host for now, and I reconnect. Leave meeting.\n",
      "PERSON8: Oh, okay. I hear you, by the way. Hello.\n",
      "PERSON6: Yeah, yeah. Now I can hear it. So, for some reason I have always to connect a few times until zoom starts sending also the sound to me. So, It's annoying. Yeah. So. I was in a call until the very last minute. So, sorry that I didn't remind everybody to – to connect. And – I'm happy to see that you are here. So, let's start. And also my machine crashed in the meantime, so I had to, like, restart it. And now it's all, like, starting up. So, so, I would like to start, maybe in the other order. In the opposite order than last week. So, PERSON7, if you could start. You were one of those –\n",
      "PERSON1: So, you want to hear, what did I do?\n",
      "PERSON6: Yeah. Yeah, yeah, yeah.\n",
      "PERSON1: So. The transcripts for check are almost done. And one – one transcriber of Germany's working. And she wants to do it alone, until December the 10th. And my mother is writing the question for the German subti – subtitle user study. And she – and she has some progress, and then – then she will move it to the spreadsheet, so we can get, her feedback and – and continue with that. And I started to write deliverables.\n",
      "PERSON6: Okay, that's great. Starting to write de – That's – That's excellent. I'm hopeful about PERSON12, but I haven't heard from him back. And he is not on the call either. So let's – Feel free to ping PERSON12 – Yourself as well. So the more –\n",
      "PERSON8: Okay.\n",
      "PERSON6: The more – the more, we do, the better. Great. Yeah, then.\n",
      "PERSON1: Can I ask PERSON11 to do, the transcripts of – By German ASR for the German transcriber.\n",
      "PERSON6: Yeah, yeah, that –\n",
      "PERSON11: So – So, I have just added the transcripts for the first 30 parts, and for the next ten parts, it's still running.\n",
      "PERSON1: Okay.\n",
      "PERSON11: But for some folders, for some reason, the audio format is wrong, so, something is wrongly – Basically, the big trade, or something is wrong. So, some files are still – Have still weird output. But – but for most folders, it should be already fine.\n",
      "PERSON1: Okay, thanks.\n",
      "PERSON6: Yeah, that's great. So, I support this, it's, it's, it's great that, Dá. PERSON7, you have thought of PERSON11. And PERSON11 now has the time. There are other things where I was, thinking of PERSON11 and that would be training of, empty systems, so that they do the shortening. So if you, PERSON11, had the time. Obviously, there is no way we could do it for the next week. But we should really have the system – ready for –\n",
      "PERSON11: I looked at the tutorial from, from, from the NLP was it?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m_id = 'meeting_en_test2023_001'\n",
    "\n",
    "segmented_transcript_long, attendees_long = segment_transcript(512, elitr_preprocessed[m_id], tokenizer)\n",
    "segmented_transcript_avg, _ = segment_transcript(768, elitr_preprocessed[m_id], tokenizer)\n",
    "segmented_transcript_short, _ = segment_transcript(1024, elitr_preprocessed[m_id], tokenizer)\n",
    "\n",
    "print(segmented_transcript_short[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1682953563674,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "mKc5wZQp1J9h",
    "outputId": "22a6e62d-2edd-49bf-f128-3c461e3f374c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "17\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "print(len(segmented_transcript_short))\n",
    "print(len(segmented_transcript_avg))\n",
    "print(len(segmented_transcript_long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1682953573974,
     "user": {
      "displayName": "Kristýna Klesnilová",
      "userId": "09175592057727468376"
     },
     "user_tz": -120
    },
    "id": "nmVyodp41J9j",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def summarize(input_text, summarizer):\n",
    "  summarization = summarizer(input_text)[0][\"summary_text\"].strip()\n",
    "  return summarization\n",
    "\n",
    "def generate_summary(segmented_transcript, summarizer):\n",
    "  summarized_segments = [summarize(transcript_segment, summarizer) for transcript_segment in segmented_transcript]\n",
    "  return \" \".join(summarized_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\"PERSON6, PERSON8, PERSON11, PERSON2, PERSON1 and PERSON12 are on a conference call. They are discussing some technical issues with the system. PERSON11 is interested in doing offline subtitling for the upcoming sessions. PERSON6 would like to implement natural shortening in the model as well. PERSON6 and PERSON4 are preparing the setups for PROJECT2 and PROJECT4 is working on the Monday seminar model. PERSON6 advises to update the pipelines on Friday. PERSON8 is doing some ASR today. Some videos are not properly converted into a 16 c format and some audio files are not working properly. PERSON1 is going to be busy tomorrow and over the weekend, so today is the last chance for PERSON6 to get it running before the weekend. PERSON8 will ask PERSON10 if he can help. PERSON4 is not taking part in the call with PERSON1 as well. PERSON4 and PERSON2 are on a call. PERSON4 explains to PERSON2 how to create a custom word list and how to use it. PERSON2 is finishing training of a German ASR that may be used for time stamping. There are some serious errors in the ASR output. The decision on which model to use will be made on Monday. The language model may need both the Transcripts and the Language Model. PERSON6 is leaving the call. PERSON8 is the host. PERSON10, PERSON4 and PERSON11 will synchronise and send the numbers to PERSON8. PERSON1 compares the quality of the ASR workers and their latency and flicker. There is only one ASR worker PERSON11 is having problems with transcribing files. He's trying to convert them to the correct format, but it doesn't support the format. It's not the speaker's fault, but the files themselves. PERSON2 will train a language model for the German ASR tomorrow. PERSON1 will send an email to PERSON2. PERSON2 and PERSON4 are having problems with converting IPA phonemes into alphabet sounds. They ask each other for help. PERSON4 wants to have a call with PERSON2 tomorrow, but it will be difficult as he is off for Friday prayer on Friday for 10 to 12 and has a test run with PERSON8 that they were discussing. He also wants to change the IPA to the alphabet phonem\""
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_short = generate_summary(segmented_transcript_short, summarizer)\n",
    "summary_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 62, but you input_length is only 50. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=25)\n"
     ]
    },
    {
     "data": {
      "text/plain": "\"PERSON6, PERSON8, PERSON11, PERSON1 and PERSON12 are on a conference call. They are discussing technical issues with the call. PERSON6 supports the idea of training empty systems to do speech translation. PERSON11 is thinking about joining the call. There are no students in Edinburgh who would have the time to do that. The only other candidates would be, PERSON13 from the PROJECT1, who works halfway in Prague and halfway in Brno. The webpage for PROJECT2 PERSON6 suggests to have a dry run of some past similar talks to PROJECT2 talks and to do the same thing with the Supreme Audit talks. PERSON4 is afraid the files won't be ready till tomorrow. PERSON8 can operate two local machines, Ark and blackbird, PERSON8 is compiling some ASR files for the leader test set. Some of the videos are not properly converted into a 16 c format and some audio files are not working properly. PERSON6, PERSON8, PERSON1 and PERSON11 are working on a system evaluation. It's their last chance to get it running before the weekend. PERSON8 will send the numbers for the data set to PERSON6 today. PERSON4 is working on the adaptation for the two domains. PERSON2 sent the files with the four words, the IBM Watson, three kinds of Watson and the phonemes spoken in them to PERSON4 PERSON4 explains to PERSON6 how the phoneme to grapheme list was prepared and compared with the other models. PERSON4 and PERSON2 are on a conference call. They are discussing how to create and store a dictionary. PERSON2 is finishing training of a German ASR that may be used for time stamping. The training set contains around 300 hours of recordings. There are possibilities to enrich the language model by texts and to use language model. The first test of the system will take place tomorrow at PERSON6, PERSON1, PERSON4, PERSON10 and PERSON8 want to compare the ASR numbers today and the improved numbers on Monday, so they can decide which of the models to use. The rainbow MT models had better scores than the MT models of PERSON3, PERSON11 and PERSON4 during the month of August. Some of their files are okay, others are terrible. PERSON11 is having problems with converting OGG files. The length of some of the transcripts is incorrect. People 1 and 2 are working on the German ASR. PERSON1 will send the monolingual German text to PERSON2 tomorrow. They will focus on PERSON2's high quality on the others. PERSON4 asks PERSON2 and PERSON3 to help her with some pronunciation problems with her language. PERSON2 asks PERSON4 to help him with pronunciation of vowels and consonants. Person2 also asks Person4 to convert IPA and CMU phonemes into the alphabet sounds. PERSON2 and PPerson4 will have a call tomorrow. PERSON4 wants to end the meeting with PERSON11.\""
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_avg = generate_summary(segmented_transcript_avg, summarizer)\n",
    "summary_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\"PERSON6 was in a call until the very last minute, so he didn't remind everybody to connect. His machine crashed and he had to restart it. Now he can hear people. The transcripts for check are almost done. The transcriber of Germany's working until December the 10th. PERSON1's mother is writing the question for the German subti- subtitle user study. PERSON6 is starting to write deliverables. PERSON11 has just added the transcripts for the The meme project does offline subtitling. Their mission is to create subtitles for the hearing-impaired. Their models work with sequence to sequence. They generate one word at a time. It would be possible to implement natural shortening in their models. PERSON11 is thinking about taking over the work of PERSON3, which is not ready for speech translation. PERSON6 wants an update for the sessions for the next week. PERSON4 will work on the webpage for PROJECT2 tomorrow. PERSON4 is away from 11 to 12 on Friday from ten to twelve. PERSON6, PERSON4 and PERSON8 are going to do the Zoom Test for YouTube videos at the same time tomorrow at one o'clock in the afternoon. PERSON8, PERSON4 and PERSON6 will prepare two presentations for the two domains. On Friday, they will prepare a test time for two concurrent sessions. On Monday, the models will be updated with the, with the domain elected ones. Some of the videos are not properly converted PERSON8 is manually converting audio files to MP3 format today. The sound quality is getting worse when passed to the sound system. PERSON6 has been telling people since August that they should have a test set to evaluate on a later test set. Every time they try to run it, they find out that it's not as easy as they thought. For example, the call that PERSON8 had, someone was PERSON8 will send the numbers for the data set to PERSON6 today. PERSON6 needs them immediately. PERSON4 is working on the adaptation for the two domains. There will be a Monday seminar on it. PERSON6 wants to have multiple custom dictionaries in the system. PERSON4 doesn't know how to run SLTF. The ASR system without using people's pronunciation was better than the one with people's generated pronunciations. PERSON2 produced a long, word list. There is a phoneme to grapheme list. The list should contain our words. There is a lot of noise in the dictionary. PERSON6 wants the system to sort it out by taking only the words that were observed five times or more, and only the pronunciations that were recorded three or more times. This way, random errors won't be frequent. PERSON PERSON4 and PERSON2 will work on the language model substitute and the generated dictionary together. PERSON2 is finishing training of a German ASR that may be used for time stamping. The training set contains around 300 hours of data, but there are some serious errors in the ASR output. PERSON1 and PERSON2 discuss how to enrich the language model by texts and PERSON6 wants to split the work among herself, PERSON4 and PERSON8, so that PERSON8 can focus more on getting the numbers and getting the systems running. He wants to have the ASR numbers today and improved numbers on Monday, when PERSON4 has the domain adaptation for PERSON6 is leaving the call. PERSON8 is the host. There are two ASR workers from K80, one of them is from the nearest one. There is only one option for ASR for multitranslation and the other one is a normal sequence. On Monday, PERSON1 did a comparison of the workers for SLT. The bottleneck in quality was the ASR quality. The MT worker with the lowest latency and flicker was selected. The rainbow MT model had better scores. PERSON11 is trying to commit the file. The output is terrible for some folders, but okay for others. It may be caused by the speaker's accent. PERSON1 wants to keep some files with Czech names. PERSON11 is having problems with FFMPEG. The transcripts for some of the files he transcribed don't have the right length, because they were processed incorrectly. The length is incorrect for most of the folders. The best solution would be to throw away everything and run everything in PERSON1 and PERSON2 are working on the German ASR. PERSON1 will provide PERSON2 with monolingual German text in the European domain and the ASR will be in lower case. PERSON1 will send an email to PERSON2. PERSON11 will try to fix the audio quality issues in some files. PERSON2 asks PERSON4 to help him with translating IPA into alphabet phonemes. PERSON2 and PERSON4 are trying to solve a pronunciation problem. They need to substitute a phoneme with another one to produce a different pronunciation. PERSON2 and PERSON4 are having problems with a computer program they are using. They have a test run with PERSON8 that they were discussing. PERSON2 wants to have a call with PERSON4 tomorrow and remap his dictionary to CMU. PERSON4 wants PERSON2 to convert the list of IPA characters into the CMU phonemes. PERSON2 agrees to do it.\""
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_long = generate_summary(segmented_transcript_long, summarizer)\n",
    "summary_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [],
   "source": [
    "def fix_entities(text):\n",
    "  text = re.sub(r\"Person\\s*(\\d+)\", lambda m: \"PERSON\" + m.group(1), text)\n",
    "  text = re.sub(r\"Organization\\s*(\\d+)\", lambda m: \"ORGANIZATION\" + m.group(1), text)\n",
    "  text = re.sub(r\"Project\\s*(\\d+)\", lambda m: \"PROJECT\" + m.group(1), text)\n",
    "  text = re.sub(r\"Location\\s*(\\d+)\", lambda m: \"LOCATION\" + m.group(1), text)\n",
    "  text = re.sub(r\"Annotator\\s*(\\d+)\", lambda m: \"ANNOTATOR\" + m.group(1), text)\n",
    "  text = re.sub(r\"Url\\s*(\\d+)\", lambda m: \"URL\" + m.group(1), text)\n",
    "  text = re.sub(r\"Number\\s*(\\d+)\", lambda m: \"NUMBER\" + m.group(1), text)\n",
    "  text = re.sub(r\"Password\\s*(\\d+)\", lambda m: \"PASSWORD\" + m.group(1), text)\n",
    "  text = re.sub(r\"Phone\\s*(\\d+)\", lambda m: \"PHONE\" + m.group(1), text)\n",
    "  text = re.sub(r\"Path\\s*(\\d+)\", lambda m: \"PATH\" + m.group(1), text)\n",
    "  text = re.sub(r\"Path\\s*(\\d+)\", lambda m: \"PATH\" + m.group(1), text)\n",
    "  text = re.sub(r\"Email\\s*(\\d+)\", lambda m: \"EMAIL\" + m.group(1), text)\n",
    "  text = re.sub(r\"Other\\s*(\\d+)\", lambda m: \"OTHER\" + m.group(1), text)\n",
    "\n",
    "  return text\n",
    "\n",
    "def create_minutes(summary):\n",
    "  summary = fix_entities(summary)\n",
    "  sentences = sent_tokenize(summary)\n",
    "  minutes = \"\\n\".join([f\"- {sent}\" for sent in sentences])\n",
    "\n",
    "  return minutes\n",
    "\n",
    "def format_minutes(attendees, minutes):\n",
    "  tday = datetime.date.today()\n",
    "  att = \", \".join(attendees)\n",
    "  return f\"DATE : {tday}\\nATTENDEES : {att}\\n\\n\\nSUMMARY\\n{minutes}\\n\\n\\nMinuted by: Team Synapse\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATE : 2023-05-02\n",
      "ATTENDEES : PERSON1, PERSON10, PERSON11, PERSON2, PERSON4, PERSON6, PERSON7, PERSON8\n",
      "\n",
      "\n",
      "SUMMARY-\n",
      "- PERSON6 was in a call until the very last minute, so he didn't remind everybody to connect.\n",
      "- His machine crashed and he had to restart it.\n",
      "- Now he can hear people.\n",
      "- The transcripts for check are almost done.\n",
      "- The transcriber of Germany's working until December the 10th.\n",
      "- PERSON1's mother is writing the question for the German subti- subtitle user study.\n",
      "- PERSON6 is starting to write deliverables.\n",
      "- PERSON11 has just added the transcripts for the The meme project does offline subtitling.\n",
      "- Their mission is to create subtitles for the hearing-impaired.\n",
      "- Their models work with sequence to sequence.\n",
      "- They generate one word at a time.\n",
      "- It would be possible to implement natural shortening in their models.\n",
      "- PERSON11 is thinking about taking over the work of PERSON3, which is not ready for speech translation.\n",
      "- PERSON6 wants an update for the sessions for the next week.\n",
      "- PERSON4 will work on the webpage for PROJECT2 tomorrow.\n",
      "- PERSON4 is away from 11 to 12 on Friday from ten to twelve.\n",
      "- PERSON6, PERSON4 and PERSON8 are going to do the Zoom Test for YouTube videos at the same time tomorrow at one o'clock in the afternoon.\n",
      "- PERSON8, PERSON4 and PERSON6 will prepare two presentations for the two domains.\n",
      "- On Friday, they will prepare a test time for two concurrent sessions.\n",
      "- On Monday, the models will be updated with the, with the domain elected ones.\n",
      "- Some of the videos are not properly converted PERSON8 is manually converting audio files to MP3 format today.\n",
      "- The sound quality is getting worse when passed to the sound system.\n",
      "- PERSON6 has been telling people since August that they should have a test set to evaluate on a later test set.\n",
      "- Every time they try to run it, they find out that it's not as easy as they thought.\n",
      "- For example, the call that PERSON8 had, someone was PERSON8 will send the numbers for the data set to PERSON6 today.\n",
      "- PERSON6 needs them immediately.\n",
      "- PERSON4 is working on the adaptation for the two domains.\n",
      "- There will be a Monday seminar on it.\n",
      "- PERSON6 wants to have multiple custom dictionaries in the system.\n",
      "- PERSON4 doesn't know how to run SLTF.\n",
      "- The ASR system without using people's pronunciation was better than the one with people's generated pronunciations.\n",
      "- PERSON2 produced a long, word list.\n",
      "- There is a phoneme to grapheme list.\n",
      "- The list should contain our words.\n",
      "- There is a lot of noise in the dictionary.\n",
      "- PERSON6 wants the system to sort it out by taking only the words that were observed five times or more, and only the pronunciations that were recorded three or more times.\n",
      "- This way, random errors won't be frequent.\n",
      "- PERSON PERSON4 and PERSON2 will work on the language model substitute and the generated dictionary together.\n",
      "- PERSON2 is finishing training of a German ASR that may be used for time stamping.\n",
      "- The training set contains around 300 hours of data, but there are some serious errors in the ASR output.\n",
      "- PERSON1 and PERSON2 discuss how to enrich the language model by texts and PERSON6 wants to split the work among herself, PERSON4 and PERSON8, so that PERSON8 can focus more on getting the numbers and getting the systems running.\n",
      "- He wants to have the ASR numbers today and improved numbers on Monday, when PERSON4 has the domain adaptation for PERSON6 is leaving the call.\n",
      "- PERSON8 is the host.\n",
      "- There are two ASR workers from K80, one of them is from the nearest one.\n",
      "- There is only one option for ASR for multitranslation and the other one is a normal sequence.\n",
      "- On Monday, PERSON1 did a comparison of the workers for SLT.\n",
      "- The bottleneck in quality was the ASR quality.\n",
      "- The MT worker with the lowest latency and flicker was selected.\n",
      "- The rainbow MT model had better scores.\n",
      "- PERSON11 is trying to commit the file.\n",
      "- The output is terrible for some folders, but okay for others.\n",
      "- It may be caused by the speaker's accent.\n",
      "- PERSON1 wants to keep some files with Czech names.\n",
      "- PERSON11 is having problems with FFMPEG.\n",
      "- The transcripts for some of the files he transcribed don't have the right length, because they were processed incorrectly.\n",
      "- The length is incorrect for most of the folders.\n",
      "- The best solution would be to throw away everything and run everything in PERSON1 and PERSON2 are working on the German ASR.\n",
      "- PERSON1 will provide PERSON2 with monolingual German text in the European domain and the ASR will be in lower case.\n",
      "- PERSON1 will send an email to PERSON2.\n",
      "- PERSON11 will try to fix the audio quality issues in some files.\n",
      "- PERSON2 asks PERSON4 to help him with translating IPA into alphabet phonemes.\n",
      "- PERSON2 and PERSON4 are trying to solve a pronunciation problem.\n",
      "- They need to substitute a phoneme with another one to produce a different pronunciation.\n",
      "- PERSON2 and PERSON4 are having problems with a computer program they are using.\n",
      "- They have a test run with PERSON8 that they were discussing.\n",
      "- PERSON2 wants to have a call with PERSON4 tomorrow and remap his dictionary to CMU.\n",
      "- PERSON4 wants PERSON2 to convert the list of IPA characters into the CMU phonemes.\n",
      "- PERSON2 agrees to do it.\n",
      "\n",
      "\n",
      "Minuted by: Team Synapse\n"
     ]
    }
   ],
   "source": [
    "print(format_minutes(attendees_long, create_minutes(summary_long)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_minutes(preprocessed_transcripts, output_dir, tokenizer, summarizer):\n",
    "  for meeting_id, transcript in preprocessed_transcripts.items():\n",
    "    for length in [512, 768, 1024]:\n",
    "      segmented_transcript, attendees = segment_transcript(length, transcript, tokenizer)\n",
    "      summary = generate_summary(segmented_transcript, summarizer)\n",
    "      minutes = format_minutes(attendees, create_minutes(summary))\n",
    "\n",
    "      os.makedirs(os.path.join(output_dir, meeting_id), exist_ok=True)\n",
    "      with open(os.path.join(output_dir, meeting_id, f\"length_{length}.txt\"), \"w\") as f:\n",
    "        f.write(minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "id": "WmQHCqjgo-Zf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[169], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mgenerate_minutes\u001B[49m\u001B[43m(\u001B[49m\u001B[43melitr_preprocessed\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mOUTPUT_DIR\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mMODEL_SHORT_NAME\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mELITR_DATA_PATH\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m generate_minutes(europarl_preprocessed, os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(OUTPUT_DIR, MODEL_SHORT_NAME, EUROPARL_DATA_PATH), tokenizer)\n",
      "Cell \u001B[0;32mIn[166], line 5\u001B[0m, in \u001B[0;36mgenerate_minutes\u001B[0;34m(preprocessed_transcripts, output_dir, tokenizer)\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m meeting_id, transcript \u001B[38;5;129;01min\u001B[39;00m preprocessed_transcripts\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m      4\u001B[0m   segmented_transcript, attendees \u001B[38;5;241m=\u001B[39m segment_transcript(length, transcript, tokenizer)\n\u001B[0;32m----> 5\u001B[0m   summary \u001B[38;5;241m=\u001B[39m \u001B[43mgenerate_summary\u001B[49m\u001B[43m(\u001B[49m\u001B[43msegmented_transcript\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m   minutes \u001B[38;5;241m=\u001B[39m format_minutes(attendees, create_minutes(summary))\n\u001B[1;32m      8\u001B[0m   os\u001B[38;5;241m.\u001B[39mmakedirs(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(output_dir, meeting_id), exist_ok\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "Cell \u001B[0;32mIn[135], line 6\u001B[0m, in \u001B[0;36mgenerate_summary\u001B[0;34m(segmented_transcript)\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgenerate_summary\u001B[39m(segmented_transcript):\n\u001B[0;32m----> 6\u001B[0m   summarized_segments \u001B[38;5;241m=\u001B[39m [summarize(transcript_segment) \u001B[38;5;28;01mfor\u001B[39;00m transcript_segment \u001B[38;5;129;01min\u001B[39;00m segmented_transcript]\n\u001B[1;32m      7\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(summarized_segments)\n",
      "Cell \u001B[0;32mIn[135], line 6\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgenerate_summary\u001B[39m(segmented_transcript):\n\u001B[0;32m----> 6\u001B[0m   summarized_segments \u001B[38;5;241m=\u001B[39m [\u001B[43msummarize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtranscript_segment\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m transcript_segment \u001B[38;5;129;01min\u001B[39;00m segmented_transcript]\n\u001B[1;32m      7\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(summarized_segments)\n",
      "Cell \u001B[0;32mIn[135], line 2\u001B[0m, in \u001B[0;36msummarize\u001B[0;34m(input_text)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msummarize\u001B[39m(input_text):\n\u001B[0;32m----> 2\u001B[0m   summarization \u001B[38;5;241m=\u001B[39m \u001B[43msummarizer\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_text\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msummary_text\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mstrip()\n\u001B[1;32m      3\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m summarization\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/transformers/pipelines/text2text_generation.py:265\u001B[0m, in \u001B[0;36mSummarizationPipeline.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    241\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    242\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    243\u001B[0m \u001B[38;5;124;03m    Summarize the text(s) given as inputs.\u001B[39;00m\n\u001B[1;32m    244\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    263\u001B[0m \u001B[38;5;124;03m          ids of the summary.\u001B[39;00m\n\u001B[1;32m    264\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 265\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/transformers/pipelines/text2text_generation.py:165\u001B[0m, in \u001B[0;36mText2TextGenerationPipeline.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    136\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    137\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    138\u001B[0m \u001B[38;5;124;03m    Generate the output text(s) using text(s) given as inputs.\u001B[39;00m\n\u001B[1;32m    139\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    162\u001B[0m \u001B[38;5;124;03m          ids of the generated text.\u001B[39;00m\n\u001B[1;32m    163\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 165\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    166\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    167\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(args[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;28mlist\u001B[39m)\n\u001B[1;32m    168\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mall\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(el, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m el \u001B[38;5;129;01min\u001B[39;00m args[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m    169\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mall\u001B[39m(\u001B[38;5;28mlen\u001B[39m(res) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m result)\n\u001B[1;32m    170\u001B[0m     ):\n\u001B[1;32m    171\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [res[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m result]\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/transformers/pipelines/base.py:1109\u001B[0m, in \u001B[0;36mPipeline.__call__\u001B[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1101\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mnext\u001B[39m(\n\u001B[1;32m   1102\u001B[0m         \u001B[38;5;28miter\u001B[39m(\n\u001B[1;32m   1103\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_iterator(\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1106\u001B[0m         )\n\u001B[1;32m   1107\u001B[0m     )\n\u001B[1;32m   1108\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1109\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_single\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreprocess_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforward_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpostprocess_params\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/transformers/pipelines/base.py:1116\u001B[0m, in \u001B[0;36mPipeline.run_single\u001B[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001B[0m\n\u001B[1;32m   1114\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_single\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001B[1;32m   1115\u001B[0m     model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocess(inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpreprocess_params)\n\u001B[0;32m-> 1116\u001B[0m     model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mforward_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1117\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpostprocess(model_outputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpostprocess_params)\n\u001B[1;32m   1118\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/transformers/pipelines/base.py:1015\u001B[0m, in \u001B[0;36mPipeline.forward\u001B[0;34m(self, model_inputs, **forward_params)\u001B[0m\n\u001B[1;32m   1013\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m inference_context():\n\u001B[1;32m   1014\u001B[0m         model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ensure_tensor_on_device(model_inputs, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m-> 1015\u001B[0m         model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mforward_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1016\u001B[0m         model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ensure_tensor_on_device(model_outputs, device\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m   1017\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/transformers/pipelines/text2text_generation.py:187\u001B[0m, in \u001B[0;36mText2TextGenerationPipeline._forward\u001B[0;34m(self, model_inputs, **generate_kwargs)\u001B[0m\n\u001B[1;32m    185\u001B[0m generate_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_length\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m generate_kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_length\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mmax_length)\n\u001B[1;32m    186\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_inputs(input_length, generate_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmin_length\u001B[39m\u001B[38;5;124m\"\u001B[39m], generate_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_length\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m--> 187\u001B[0m output_ids \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mgenerate_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    188\u001B[0m out_b \u001B[38;5;241m=\u001B[39m output_ids\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    189\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mframework \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/transformers/generation/utils.py:1524\u001B[0m, in \u001B[0;36mGenerationMixin.generate\u001B[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, streamer, **kwargs)\u001B[0m\n\u001B[1;32m   1517\u001B[0m     input_ids, model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_expand_inputs_for_generation(\n\u001B[1;32m   1518\u001B[0m         input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[1;32m   1519\u001B[0m         expand_size\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mnum_beams,\n\u001B[1;32m   1520\u001B[0m         is_encoder_decoder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder,\n\u001B[1;32m   1521\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[1;32m   1522\u001B[0m     )\n\u001B[1;32m   1523\u001B[0m     \u001B[38;5;66;03m# 13. run beam search\u001B[39;00m\n\u001B[0;32m-> 1524\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbeam_search\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1525\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1526\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeam_scorer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1527\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlogits_processor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlogits_processor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1528\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstopping_criteria\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstopping_criteria\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpad_token_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpad_token_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1530\u001B[0m \u001B[43m        \u001B[49m\u001B[43meos_token_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meos_token_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1531\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_scores\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutput_scores\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1532\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_dict_in_generate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreturn_dict_in_generate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1533\u001B[0m \u001B[43m        \u001B[49m\u001B[43msynced_gpus\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msynced_gpus\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1534\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1535\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m is_beam_sample_gen_mode:\n\u001B[1;32m   1538\u001B[0m     \u001B[38;5;66;03m# 11. prepare logits warper\u001B[39;00m\n\u001B[1;32m   1539\u001B[0m     logits_warper \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_logits_warper(generation_config)\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/transformers/generation/utils.py:2810\u001B[0m, in \u001B[0;36mGenerationMixin.beam_search\u001B[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001B[0m\n\u001B[1;32m   2806\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m   2808\u001B[0m model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprepare_inputs_for_generation(input_ids, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs)\n\u001B[0;32m-> 2810\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2811\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2812\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   2813\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2814\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2815\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2817\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m synced_gpus \u001B[38;5;129;01mand\u001B[39;00m this_peer_finished:\n\u001B[1;32m   2818\u001B[0m     cur_len \u001B[38;5;241m=\u001B[39m cur_len \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/transformers/models/bart/modeling_bart.py:1378\u001B[0m, in \u001B[0;36mBartForConditionalGeneration.forward\u001B[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1373\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m decoder_input_ids \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m decoder_inputs_embeds \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1374\u001B[0m         decoder_input_ids \u001B[38;5;241m=\u001B[39m shift_tokens_right(\n\u001B[1;32m   1375\u001B[0m             labels, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mpad_token_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mdecoder_start_token_id\n\u001B[1;32m   1376\u001B[0m         )\n\u001B[0;32m-> 1378\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1379\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1380\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1381\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdecoder_input_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_input_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1382\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1383\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdecoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1384\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1385\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdecoder_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1386\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcross_attn_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcross_attn_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1387\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1388\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1389\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdecoder_inputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_inputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1390\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1391\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1392\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1393\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1394\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1396\u001B[0m lm_logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlm_head(outputs[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m   1397\u001B[0m lm_logits \u001B[38;5;241m=\u001B[39m lm_logits \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfinal_logits_bias\u001B[38;5;241m.\u001B[39mto(lm_logits\u001B[38;5;241m.\u001B[39mdevice)\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/transformers/models/bart/modeling_bart.py:1260\u001B[0m, in \u001B[0;36mBartModel.forward\u001B[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1253\u001B[0m     encoder_outputs \u001B[38;5;241m=\u001B[39m BaseModelOutput(\n\u001B[1;32m   1254\u001B[0m         last_hidden_state\u001B[38;5;241m=\u001B[39mencoder_outputs[\u001B[38;5;241m0\u001B[39m],\n\u001B[1;32m   1255\u001B[0m         hidden_states\u001B[38;5;241m=\u001B[39mencoder_outputs[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(encoder_outputs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1256\u001B[0m         attentions\u001B[38;5;241m=\u001B[39mencoder_outputs[\u001B[38;5;241m2\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(encoder_outputs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1257\u001B[0m     )\n\u001B[1;32m   1259\u001B[0m \u001B[38;5;66;03m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001B[39;00m\n\u001B[0;32m-> 1260\u001B[0m decoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1261\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_input_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1262\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1263\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_outputs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1264\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1265\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1266\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcross_attn_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcross_attn_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1267\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1268\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_inputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1269\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1270\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1271\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1272\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1273\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1275\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m return_dict:\n\u001B[1;32m   1276\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m decoder_outputs \u001B[38;5;241m+\u001B[39m encoder_outputs\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/transformers/models/bart/modeling_bart.py:1118\u001B[0m, in \u001B[0;36mBartDecoder.forward\u001B[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1107\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mcheckpoint\u001B[38;5;241m.\u001B[39mcheckpoint(\n\u001B[1;32m   1108\u001B[0m         create_custom_forward(decoder_layer),\n\u001B[1;32m   1109\u001B[0m         hidden_states,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1115\u001B[0m         \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1116\u001B[0m     )\n\u001B[1;32m   1117\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1118\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mdecoder_layer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1119\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1120\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1121\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1122\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1123\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1124\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcross_attn_layer_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1125\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcross_attn_head_mask\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcross_attn_head_mask\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\n\u001B[1;32m   1126\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1127\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1128\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1129\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1130\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1133\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache:\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/transformers/models/bart/modeling_bart.py:447\u001B[0m, in \u001B[0;36mBartDecoderLayer.forward\u001B[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001B[0m\n\u001B[1;32m    445\u001B[0m \u001B[38;5;66;03m# cross_attn cached key/values tuple is at positions 3,4 of present_key_value tuple\u001B[39;00m\n\u001B[1;32m    446\u001B[0m cross_attn_past_key_value \u001B[38;5;241m=\u001B[39m past_key_value[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m:] \u001B[38;5;28;01mif\u001B[39;00m past_key_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 447\u001B[0m hidden_states, cross_attn_weights, cross_attn_present_key_value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder_attn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    448\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    449\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkey_value_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    450\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    451\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcross_attn_layer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    452\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcross_attn_past_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    453\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    454\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    455\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mfunctional\u001B[38;5;241m.\u001B[39mdropout(hidden_states, p\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining)\n\u001B[1;32m    456\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m residual \u001B[38;5;241m+\u001B[39m hidden_states\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/transformers/models/bart/modeling_bart.py:194\u001B[0m, in \u001B[0;36mBartAttention.forward\u001B[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001B[0m\n\u001B[1;32m    191\u001B[0m bsz, tgt_len, _ \u001B[38;5;241m=\u001B[39m hidden_states\u001B[38;5;241m.\u001B[39msize()\n\u001B[1;32m    193\u001B[0m \u001B[38;5;66;03m# get query proj\u001B[39;00m\n\u001B[0;32m--> 194\u001B[0m query_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mq_proj\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscaling\n\u001B[1;32m    195\u001B[0m \u001B[38;5;66;03m# get key, value proj\u001B[39;00m\n\u001B[1;32m    196\u001B[0m \u001B[38;5;66;03m# `past_key_value[0].shape[2] == key_value_states.shape[1]`\u001B[39;00m\n\u001B[1;32m    197\u001B[0m \u001B[38;5;66;03m# is checking that the `sequence_length` of the `past_key_value` is the same as\u001B[39;00m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;66;03m# the provided `key_value_states` to support prefix tuning\u001B[39;00m\n\u001B[1;32m    199\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    200\u001B[0m     is_cross_attention\n\u001B[1;32m    201\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m past_key_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    202\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m past_key_value[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m2\u001B[39m] \u001B[38;5;241m==\u001B[39m key_value_states\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m    203\u001B[0m ):\n\u001B[1;32m    204\u001B[0m     \u001B[38;5;66;03m# reuse k,v, cross_attentions\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Documents/Study/MFF/2_semestr/npfl087/automin/AutoMin2023/experiments/automin2023/venv/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "generate_minutes(elitr_preprocessed, os.path.join(OUTPUT_DIR, MODEL_SHORT_NAME, ELITR_DATA_PATH), tokenizer, summarizer)\n",
    "generate_minutes(europarl_preprocessed, os.path.join(OUTPUT_DIR, MODEL_SHORT_NAME, EUROPARL_DATA_PATH), tokenizer, summarizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xJh02iTH2tGS"
   },
   "source": [
    "# TextRank Scipt for ranking sentences\n",
    "This method uses GloVe Embeddings to calculate similarity score with the help of cosine similairty, and ranks individual sentences with the help of the PageRank Algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fwK8kem-33KA"
   },
   "outputs": [],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip glove*.zip -d models/glove\n",
    "!rm -rf glove*.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "TPsMhR5S06FU"
   },
   "outputs": [],
   "source": [
    "def get_minutes(data_path):\n",
    "    minute_files = {}\n",
    "    data_folders = [os.path.basename(x[0]) for x in os.walk(data_path) if len(os.path.basename(x[0])) > 0]\n",
    "    for directory in sorted(data_folders):\n",
    "        minute_files[directory] = {}\n",
    "        for file_name in sorted(os.listdir(os.path.join(data_path, directory))):\n",
    "            file_path = os.path.join(data_path, directory, file_name)\n",
    "            with open(file_path, \"r\") as f:\n",
    "                minute_files[directory][file_name] = f.read().splitlines()\n",
    "    return minute_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "WBLagKSM06FU"
   },
   "outputs": [],
   "source": [
    "elitr_minute_path_test = '../automin2023/minutes/MEETING_SUMMARY/elitr/en/test2023-en/'\n",
    "elitr_output_minute_path_test = '../automin2023/minutes/MEETING_SUMMARY/elitr/en/test2023-en/final/'\n",
    "\n",
    "europarl_minute_path_test = '../automin2023/minutes/MEETING_SUMMARY/europarl/test1/'\n",
    "europarl_output_minute_path_test = '../automin2023/minutes/MEETING_SUMMARY/europarl/test1/final/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "cDcPcGai06FU"
   },
   "outputs": [],
   "source": [
    "def get_sentence_vectors(row, word_embeddings):\n",
    "    sentence_vector = None\n",
    "    sentence = row['sentence']\n",
    "    if len(sentence) != 0:\n",
    "      sentence_vector = sum([word_embeddings.get(w, np.zeros((100,))) for w in sentence.split()])/(len(sentence.split())+0.001)\n",
    "    else:\n",
    "      sentence_vector = np.zeros((100,))\n",
    "    return sentence_vector\n",
    "\n",
    "def add_sentence_vectors(clean_sentences, word_embeddings):\n",
    "\n",
    "  # EXTRACT SENTENCE VECTORS\n",
    "  clean_sentences['sentence_vector'] = clean_sentences.apply(lambda x: get_sentence_vectors(x, word_embeddings), axis=1)\n",
    "  return clean_sentences\n",
    "\n",
    "\n",
    "def clean_minute_sentences(summary):\n",
    "\n",
    "    # os.chdir(path)\n",
    "    summaries = []\n",
    "    # for file1 in sorted(os.listdir()):\n",
    "    summary = summary[5:-3]\n",
    "    text = ''\n",
    "    for line in summary:\n",
    "        line = line.replace(' -', '')\n",
    "        line = line.replace('  ', '')\n",
    "        line = line.replace('\\n', '')\n",
    "        text = text + line + ' '\n",
    "    summaries.append(text)\n",
    "\n",
    "    sentences = []\n",
    "    for s in summaries:\n",
    "        sentences.append(sent_tokenize(s))\n",
    "\n",
    "    sentences = [(idx, y) for x in sentences for idx, y in enumerate(x)] # flatten list\n",
    "    print('Total no. of sentences: ', len(sentences))\n",
    "\n",
    "    # REMOVE PUNCTUATIONS, NUMBERS AND SPECIAL CHARACTERS\n",
    "    clean_sentences = pd.DataFrame(sentences, columns = ['order', 'sentence'])\n",
    "\n",
    "\n",
    "    # MAKE ALPHABETS TO LOWERCASE\n",
    "    clean_sentences['sentence'] = clean_sentences['sentence'].str.replace(\"[^a-zA-Z]\", \" \").str.lower()\n",
    "\n",
    "    # REMOVE STOPWORDS\n",
    "    stop_words = stopwords.words('english')\n",
    "\n",
    "    def remove_stopwords(sen):\n",
    "        sen_new = \" \".join([i for i in sen if i not in stop_words])\n",
    "        return sen_new\n",
    "\n",
    "    clean_sentences['sentence'] = clean_sentences['sentence'].apply(lambda x: remove_stopwords(x.split()))\n",
    "    return sentences, clean_sentences\n",
    "\n",
    "\n",
    "\n",
    "def calculate_similarity_and_rank(sentences, clean_sentences):\n",
    "  # INITIALIZE A SIMILARITY MATRIX\n",
    "  sim_mat = np.zeros([len(sentences), len(sentences)])\n",
    "\n",
    "  for i in range(len(sentences)):\n",
    "    for j in range(len(sentences)):\n",
    "      if i != j:\n",
    "        sim_mat[i][j] = cosine_similarity(clean_sentences['sentence_vector'][i].reshape(1,100), clean_sentences['sentence_vector'][j].reshape(1,100))[0,0]\n",
    "        \n",
    "  # PAGERANK SCORING\n",
    "  nx_graph = nx.from_numpy_array(sim_mat)\n",
    "  scores = nx.pagerank(nx_graph)\n",
    "  ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)\n",
    "\n",
    "  # ENTER THE PERCENTAGE OF SENTENCES THAT SEEM UNIFORMATIONAL,  THIS NUMBER IS USUALLY AROUND ~15% FOR THE MINUTES BELONGING TO A LENGTHY TRANSCRIPT\n",
    "  informative_sentences = []\n",
    "  rem_perc = 0.15\n",
    "  remove_count = math.ceil(len(sentences)*rem_perc)\n",
    "  final_sentence_count = len(ranked_sentences)\n",
    "  if len(ranked_sentences)-remove_count > 5:\n",
    "     final_sentence_count = len(ranked_sentences) - remove_count\n",
    "  for i in range(final_sentence_count):\n",
    "    informative_sentences.append(ranked_sentences[i][1])\n",
    "\n",
    "  informative_sentences.sort(key=lambda sentence: sentence[1][0])\n",
    "  informative_sentences = ['- ' + sentence[1] for sentence in informative_sentences]\n",
    "\n",
    "  return '\\n'.join(informative_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "nO2wMYWo33yP"
   },
   "outputs": [],
   "source": [
    "def rank_and_regenerate_minutes(input_path, output_path):\n",
    "    # EXTRACT WORD VECTORS\n",
    "    minute_files = get_minutes(input_path)\n",
    "    word_embeddings = {}\n",
    "    f = open('models/glove/glove.6B.100d.txt', encoding='utf-8')\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        word_embeddings[word] = coefs\n",
    "    f.close()\n",
    "    os.makedirs(output_path)\n",
    "    for min_id in minute_files.keys():\n",
    "        print('Meeting ID: ', min_id)\n",
    "        os.makedirs(output_path + min_id)\n",
    "        for file_name, minutes in minute_files[min_id].items():\n",
    "            sentences, clean_sentences = clean_minute_sentences(minutes)\n",
    "            clean_sentences = add_sentence_vectors(clean_sentences, word_embeddings)\n",
    "            informative_sentences = calculate_similarity_and_rank(sentences, clean_sentences)\n",
    "            final_minutes =  '\\n'.join(minutes[:5]) + '\\n' + informative_sentences + '\\n'.join(minutes[-3:])\n",
    "\n",
    "            with open(output_path + min_id + '/' + file_name + '_final.txt', 'w') as out_file:\n",
    "                out_file.write(final_minutes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "ZGKkO13s06FW",
    "outputId": "e99970fe-a018-457f-b1e8-354178cfeee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meeting ID:  meeting_en_test2023_001\n",
      "Total no. of sentences:  30\n",
      "Total no. of sentences:  68\n",
      "Total no. of sentences:  33\n",
      "Meeting ID:  meeting_en_test2023_002\n",
      "Total no. of sentences:  30\n",
      "Total no. of sentences:  53\n",
      "Total no. of sentences:  39\n",
      "Meeting ID:  meeting_en_test2023_003\n",
      "Total no. of sentences:  30\n",
      "Total no. of sentences:  63\n",
      "Total no. of sentences:  45\n",
      "Meeting ID:  meeting_en_test2023_004\n",
      "Total no. of sentences:  17\n",
      "Total no. of sentences:  31\n",
      "Total no. of sentences:  25\n",
      "Meeting ID:  meeting_en_test2023_005\n",
      "Total no. of sentences:  36\n",
      "Total no. of sentences:  63\n",
      "Total no. of sentences:  43\n",
      "Meeting ID:  meeting_en_test2023_006\n",
      "Total no. of sentences:  30\n",
      "Total no. of sentences:  62\n",
      "Total no. of sentences:  43\n",
      "Meeting ID:  meeting_en_test2023_007\n",
      "Total no. of sentences:  21\n",
      "Total no. of sentences:  37\n",
      "Total no. of sentences:  26\n",
      "Meeting ID:  meeting_en_test2023_008\n",
      "Total no. of sentences:  20\n",
      "Total no. of sentences:  34\n",
      "Total no. of sentences:  24\n",
      "Meeting ID:  meeting_en_test2023_009\n",
      "Total no. of sentences:  24\n",
      "Total no. of sentences:  33\n",
      "Total no. of sentences:  24\n",
      "Meeting ID:  meeting_en_test2023_010\n",
      "Total no. of sentences:  19\n",
      "Total no. of sentences:  28\n",
      "Total no. of sentences:  20\n",
      "Meeting ID:  meeting_en_test2023_011\n",
      "Total no. of sentences:  14\n",
      "Total no. of sentences:  22\n",
      "Total no. of sentences:  14\n",
      "Meeting ID:  meeting_en_test2023_012\n",
      "Total no. of sentences:  29\n",
      "Total no. of sentences:  57\n",
      "Total no. of sentences:  39\n"
     ]
    }
   ],
   "source": [
    "rank_and_regenerate_minutes(elitr_minute_path_test, elitr_output_minute_path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meeting ID:  2008-03-11-ch003-00\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2008-03-12-ch004-00\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2008-03-12-ch012-00\n",
      "Total no. of sentences:  7\n",
      "Total no. of sentences:  21\n",
      "Total no. of sentences:  17\n",
      "Meeting ID:  2008-04-10-ch009-12\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2008-04-10-ch009-13\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2008-04-10-ch010-00\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2008-04-10-ch011-01\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2008-04-10-ch011-02\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2008-04-21-ch016-00\n",
      "Total no. of sentences:  8\n",
      "Total no. of sentences:  20\n",
      "Total no. of sentences:  12\n",
      "Meeting ID:  2008-04-21-ch017-00\n",
      "Total no. of sentences:  13\n",
      "Total no. of sentences:  30\n",
      "Total no. of sentences:  16\n",
      "Meeting ID:  2008-04-22-ch005-05\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2008-04-22-ch005-06\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2008-04-22-ch005-09\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2008-04-22-ch005-10\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  5\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2008-04-22-ch005-18\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2008-04-23-ch004-03\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2008-04-23-ch004-09\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2008-04-23-ch004-10\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2008-05-08-ch005-03\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2008-05-08-ch005-07\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2008-05-08-ch005-08\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2008-05-08-ch005-11\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2008-05-19-ch027-00\n",
      "Total no. of sentences:  26\n",
      "Total no. of sentences:  56\n",
      "Total no. of sentences:  41\n",
      "Meeting ID:  2008-05-21-ch002-00\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2008-05-21-ch005-01\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  5\n",
      "Total no. of sentences:  6\n",
      "Meeting ID:  2008-05-21-ch005-02\n",
      "Total no. of sentences:  4\n",
      "Total no. of sentences:  4\n",
      "Total no. of sentences:  4\n",
      "Meeting ID:  2008-05-21-ch005-03\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2008-05-21-ch005-04\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2008-05-21-ch005-06\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2008-05-21-ch005-12\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2008-05-21-ch005-13\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2008-05-21-ch019-00\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  4\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2008-06-04-ch003-00\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2008-06-04-ch018-00\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2008-06-05-ch004-00\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  5\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2008-06-05-ch006-04\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2008-06-05-ch006-05\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2008-06-05-ch006-09\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2008-06-05-ch006-21\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2008-06-17-ch002-00\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2008-06-17-ch007-01\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2008-06-17-ch007-20\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  4\n",
      "Total no. of sentences:  5\n",
      "Meeting ID:  2008-06-17-ch007-23\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2008-06-17-ch007-24\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2008-06-18-ch004-00\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2008-07-07-ch002-00\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  5\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2008-07-07-ch014-00\n",
      "Total no. of sentences:  4\n",
      "Total no. of sentences:  4\n",
      "Total no. of sentences:  5\n",
      "Meeting ID:  2008-07-07-ch016-00\n",
      "Total no. of sentences:  24\n",
      "Total no. of sentences:  60\n",
      "Total no. of sentences:  39\n",
      "Meeting ID:  2008-07-08-ch008-14\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2008-07-08-ch008-22\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  5\n",
      "Total no. of sentences:  5\n",
      "Meeting ID:  2008-07-08-ch008-23\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2008-07-09-ch005-06\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2008-07-09-ch005-10\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2008-07-09-ch005-14\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2008-07-09-ch009-00\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  6\n",
      "Total no. of sentences:  5\n",
      "Meeting ID:  2008-07-09-ch013-00\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2008-07-10-ch001-00\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2008-07-10-ch012-00\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2008-09-01-ch002-00\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2008-09-01-ch003-00\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  6\n",
      "Total no. of sentences:  6\n",
      "Meeting ID:  2008-09-02-ch005-01\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2008-09-02-ch005-14\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2008-09-02-ch015-00\n",
      "Total no. of sentences:  5\n",
      "Total no. of sentences:  11\n",
      "Total no. of sentences:  7\n",
      "Meeting ID:  2008-09-02-ch016-00\n",
      "Total no. of sentences:  12\n",
      "Total no. of sentences:  25\n",
      "Total no. of sentences:  18\n",
      "Meeting ID:  2008-09-04-ch007-01\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2008-09-04-ch013-02\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2008-09-24-ch002-00\n",
      "Total no. of sentences:  4\n",
      "Total no. of sentences:  4\n",
      "Total no. of sentences:  4\n",
      "Meeting ID:  2008-09-24-ch006-10\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  8\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2008-09-24-ch008-01\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2008-09-24-ch010-01\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2008-09-24-ch010-05\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2008-09-25-ch005-00\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  6\n",
      "Total no. of sentences:  5\n",
      "Meeting ID:  2008-09-25-ch006-00\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2008-09-25-ch007-03\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2008-09-25-ch007-04\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  6\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2008-09-25-ch007-05\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2008-09-25-ch007-08\n",
      "Total no. of sentences:  4\n",
      "Total no. of sentences:  4\n",
      "Total no. of sentences:  4\n",
      "Meeting ID:  2008-09-25-ch007-09\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2008-10-09-ch007-06\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2008-10-09-ch007-07\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2008-10-09-ch007-12\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2008-10-09-ch007-14\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2008-10-09-ch007-15\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2008-10-20-ch004-00\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2008-10-21-ch008-26\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2008-10-23-ch005-00\n",
      "Total no. of sentences:  4\n",
      "Total no. of sentences:  6\n",
      "Total no. of sentences:  4\n",
      "Meeting ID:  2008-10-23-ch008-05\n",
      "Total no. of sentences:  4\n",
      "Total no. of sentences:  4\n",
      "Total no. of sentences:  4\n",
      "Meeting ID:  2008-10-23-ch008-06\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2008-10-23-ch008-08\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2008-11-17-ch021-00\n",
      "Total no. of sentences:  55\n",
      "Total no. of sentences:  124\n",
      "Total no. of sentences:  85\n",
      "Meeting ID:  2008-11-18-ch007-10\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2008-11-18-ch007-14\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2008-11-18-ch007-16\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2008-11-19-ch001-00\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2008-11-20-ch013-03\n",
      "Total no. of sentences:  4\n",
      "Total no. of sentences:  5\n",
      "Total no. of sentences:  5\n",
      "Meeting ID:  2008-12-03-ch005-00\n",
      "Total no. of sentences:  7\n",
      "Total no. of sentences:  9\n",
      "Total no. of sentences:  7\n",
      "Meeting ID:  2008-12-03-ch010-00\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  4\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2008-12-16-ch003-17\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  4\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2008-12-16-ch003-19\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2008-12-16-ch003-23\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  4\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2008-12-16-ch003-24\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2008-12-16-ch003-25\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2008-12-16-ch007-00\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  4\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2008-12-16-ch008-00\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  4\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2008-12-17-ch004-00\n",
      "Total no. of sentences:  4\n",
      "Total no. of sentences:  4\n",
      "Total no. of sentences:  4\n",
      "Meeting ID:  2008-12-17-ch005-02\n",
      "Total no. of sentences:  4\n",
      "Total no. of sentences:  4\n",
      "Total no. of sentences:  4\n",
      "Meeting ID:  2008-12-17-ch005-06\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  4\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2008-12-17-ch005-07\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2008-12-17-ch006-00\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2008-12-18-ch004-00\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2008-12-18-ch006-07\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2008-12-18-ch006-08\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2008-12-18-ch006-10\n",
      "Total no. of sentences:  4\n",
      "Total no. of sentences:  4\n",
      "Total no. of sentences:  4\n",
      "Meeting ID:  2008-12-18-ch006-11\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  4\n",
      "Total no. of sentences:  4\n",
      "Meeting ID:  2008-12-18-ch006-18\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2008-12-18-ch006-19\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2008-12-18-ch006-21\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2008-12-18-ch006-22\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2009-01-12-ch012-00\n",
      "Total no. of sentences:  4\n",
      "Total no. of sentences:  7\n",
      "Total no. of sentences:  5\n",
      "Meeting ID:  2009-02-04-ch010-00\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2009-02-05-ch005-02\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-02-05-ch005-03\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2009-02-05-ch005-07\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-02-05-ch005-08\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-02-05-ch012-01\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  5\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2009-02-05-ch012-02\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-02-18-ch002-00\n",
      "Total no. of sentences:  4\n",
      "Total no. of sentences:  7\n",
      "Total no. of sentences:  5\n",
      "Meeting ID:  2009-02-19-ch005-02\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2009-02-19-ch005-11\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-02-19-ch006-00\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2009-02-19-ch009-02\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2009-02-19-ch009-05\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2009-03-09-ch025-00\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-03-10-ch004-00\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2009-03-10-ch008-10\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2009-03-10-ch008-12\n",
      "Total no. of sentences:  4\n",
      "Total no. of sentences:  5\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2009-03-10-ch008-13\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-03-10-ch008-14\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2009-03-10-ch008-19\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-03-12-ch007-08\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-03-12-ch007-09\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2009-03-12-ch007-10\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-03-12-ch007-11\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-03-12-ch007-13\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2009-03-12-ch007-17\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-03-12-ch012-00\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2009-03-23-ch005-00\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-03-24-ch004-09\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-03-24-ch004-15\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2009-03-24-ch004-16\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-03-24-ch004-17\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  4\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2009-03-25-ch003-03\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2009-03-25-ch003-09\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-03-25-ch003-12\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2009-03-25-ch003-13\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2009-03-25-ch003-17\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  4\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-03-25-ch003-18\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-03-25-ch003-20\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-03-26-ch004-02\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-03-26-ch004-05\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-03-26-ch004-06\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  5\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2009-03-26-ch004-08\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-03-26-ch004-10\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-04-01-ch002-00\n",
      "Total no. of sentences:  4\n",
      "Total no. of sentences:  4\n",
      "Total no. of sentences:  4\n",
      "Meeting ID:  2009-04-02-ch009-04\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-04-02-ch009-07\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-04-02-ch009-08\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-04-02-ch009-14\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2009-04-02-ch009-17\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2009-04-02-ch009-19\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-04-02-ch009-20\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-04-02-ch009-23\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-04-22-ch006-06\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-04-22-ch006-07\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2009-04-22-ch006-08\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-04-22-ch006-13\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2009-04-22-ch006-14\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2009-04-22-ch006-25\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-04-22-ch006-31\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2009-04-22-ch006-33\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-04-22-ch006-34\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2009-04-22-ch006-35\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2009-04-22-ch006-36\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  8\n",
      "Total no. of sentences:  5\n",
      "Meeting ID:  2009-04-23-ch007-00\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-04-23-ch008-03\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-04-23-ch008-04\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2009-04-23-ch008-05\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2009-04-23-ch008-07\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-04-23-ch008-08\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2009-04-23-ch008-12\n",
      "Total no. of sentences:  7\n",
      "Total no. of sentences:  9\n",
      "Total no. of sentences:  5\n",
      "Meeting ID:  2009-04-23-ch008-21\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2009-04-24-ch007-03\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2009-04-24-ch007-04\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2009-04-24-ch007-07\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-04-24-ch007-18\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2009-04-24-ch007-19\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2009-04-24-ch007-20\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2009-04-24-ch007-24\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-05-04-ch002-00\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  8\n",
      "Total no. of sentences:  6\n",
      "Meeting ID:  2009-05-05-ch005-01\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2009-05-05-ch005-06\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2009-05-05-ch005-07\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2009-05-05-ch005-08\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2009-05-05-ch005-09\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2009-05-05-ch005-10\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2009-05-05-ch005-13\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2009-05-05-ch011-00\n",
      "Total no. of sentences:  29\n",
      "Total no. of sentences:  56\n",
      "Total no. of sentences:  38\n",
      "Meeting ID:  2009-05-07-ch009-01\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2009-05-07-ch009-02\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2009-05-07-ch009-03\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2009-05-07-ch009-14\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2009-05-07-ch009-16\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-05-07-ch009-18\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2009-05-07-ch009-19\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-07-14-ch001-00\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2009-09-14-ch015-00\n",
      "Total no. of sentences:  5\n",
      "Total no. of sentences:  9\n",
      "Total no. of sentences:  7\n",
      "Meeting ID:  2009-09-15-ch009-00\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2009-09-16-ch007-01\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  8\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2009-09-16-ch010-00\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-10-07-ch012-00\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  6\n",
      "Total no. of sentences:  6\n",
      "Meeting ID:  2009-10-07-ch017-00\n",
      "Total no. of sentences:  13\n",
      "Total no. of sentences:  36\n",
      "Total no. of sentences:  16\n",
      "Meeting ID:  2009-10-07-ch018-00\n",
      "Total no. of sentences:  20\n",
      "Total no. of sentences:  51\n",
      "Total no. of sentences:  29\n",
      "Meeting ID:  2009-10-07-ch022-00\n",
      "Total no. of sentences:  25\n",
      "Total no. of sentences:  41\n",
      "Total no. of sentences:  33\n",
      "Meeting ID:  2009-10-19-ch002-00\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  5\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2009-10-19-ch015-00\n",
      "Total no. of sentences:  6\n",
      "Total no. of sentences:  7\n",
      "Total no. of sentences:  7\n",
      "Meeting ID:  2009-10-19-ch018-00\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  13\n",
      "Total no. of sentences:  6\n",
      "Meeting ID:  2009-10-20-ch007-22\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2009-10-21-ch007-00\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2009-11-11-ch017-00\n",
      "Total no. of sentences:  33\n",
      "Total no. of sentences:  53\n",
      "Total no. of sentences:  35\n",
      "Meeting ID:  2009-11-11-ch018-00\n",
      "Total no. of sentences:  13\n",
      "Total no. of sentences:  30\n",
      "Total no. of sentences:  20\n",
      "Meeting ID:  2009-11-11-ch019-00\n",
      "Total no. of sentences:  14\n",
      "Total no. of sentences:  34\n",
      "Total no. of sentences:  29\n",
      "Meeting ID:  2009-11-11-ch020-00\n",
      "Total no. of sentences:  18\n",
      "Total no. of sentences:  34\n",
      "Total no. of sentences:  19\n",
      "Meeting ID:  2009-11-12-ch007-00\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2009-11-23-ch002-00\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2009-11-23-ch016-00\n",
      "Total no. of sentences:  11\n",
      "Total no. of sentences:  24\n",
      "Total no. of sentences:  15\n",
      "Meeting ID:  2009-11-23-ch018-00\n",
      "Total no. of sentences:  36\n",
      "Total no. of sentences:  71\n",
      "Total no. of sentences:  43\n",
      "Meeting ID:  2009-11-25-ch007-01\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2009-11-25-ch007-04\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  2\n",
      "Meeting ID:  2009-11-25-ch007-05\n",
      "Total no. of sentences:  1\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  1\n",
      "Meeting ID:  2009-11-25-ch007-06\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Meeting ID:  2009-11-25-ch010-00\n",
      "Total no. of sentences:  2\n",
      "Total no. of sentences:  4\n",
      "Total no. of sentences:  5\n",
      "Meeting ID:  2009-11-26-ch007-00\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n",
      "Total no. of sentences:  3\n"
     ]
    }
   ],
   "source": [
    "rank_and_regenerate_minutes(europarl_minute_path_test, europarl_output_minute_path_test)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0258c0f831864d76b8da412c72e1bcec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9d5196deb05549d0b7ba47c8e2bd9b70",
      "placeholder": "​",
      "style": "IPY_MODEL_413d836d8a2049d684557a931b29459d",
      "value": " 1.51k/1.51k [00:00&lt;00:00, 116kB/s]"
     }
    },
    "0f5f1407d88845d388871e827eb377e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "149ccf52c9b84a6b8791139bf5c1abe5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "15fcefddfe1241e1912308a3e0369feb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ac19fa9c73d42e89ab53b515a439758": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1c565184f62047d4ac2310ea0274954b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2076cd74bf534668b7a85e8fc4ea2cc0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "210f248fc74a4f2cb2671e5f1850e784": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "261c2a72381e40cb94c5c60cf0237d50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "293cd5f4623e47819f237dfe800917d9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "29b916fbd0844450a84f25c1352068b4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2d708f20e51d46fa8da7e624f3f84c78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2dbae29561d44d00ba018fa6050f9651": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e9b7e1831de42b19c7a7c2959bc683d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2fa95194cd614752a83fd964a6af9839": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_436643afb6404e03a3f3fe554dfb8a72",
      "placeholder": "​",
      "style": "IPY_MODEL_261c2a72381e40cb94c5c60cf0237d50",
      "value": "Downloading (…)/main/tokenizer.json: 100%"
     }
    },
    "32171595336644219238ca6aa86a3987": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_693b5dd44a2e48a1b9634500713ecfa8",
      "max": 309,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2d708f20e51d46fa8da7e624f3f84c78",
      "value": 309
     }
    },
    "3419a24159d245e09f24a6de15579537": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_37d46921f77e433a8ee85fc5b26f731c",
      "placeholder": "​",
      "style": "IPY_MODEL_1c565184f62047d4ac2310ea0274954b",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "356744cd08f64f9c9977b18e90101745": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e907706ca3845e891c9fd380d44d92f",
      "placeholder": "​",
      "style": "IPY_MODEL_af05bfefe9a444b09286c8716d72b8c3",
      "value": " 899k/899k [00:00&lt;00:00, 14.8MB/s]"
     }
    },
    "37c98c759b094742b2fdb16d06296b17": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d4171be7b8b949fa8300301a06e3cb4c",
       "IPY_MODEL_46bcad2ebe4f42ac8f3c1766d5ccec49",
       "IPY_MODEL_9b24d42bb3f74204b63024820b670156"
      ],
      "layout": "IPY_MODEL_9ed9bc7814264744acb089f4dd53c453"
     }
    },
    "37d46921f77e433a8ee85fc5b26f731c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "407d2cb054564c46881e2fff1b48705f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4102431c863e43bd8e35567c14d89c64": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "413d836d8a2049d684557a931b29459d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "436643afb6404e03a3f3fe554dfb8a72": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4367fe694cd54f26b800f9ae19d2a8e2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46bcad2ebe4f42ac8f3c1766d5ccec49": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d7f3dc64f3cf495b9cbcd7050cdd7502",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1ac19fa9c73d42e89ab53b515a439758",
      "value": 456318
     }
    },
    "4a274883440848e1895d4c37911b1531": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54b753d573ba4af5aae6e90eae730525": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_293cd5f4623e47819f237dfe800917d9",
      "placeholder": "​",
      "style": "IPY_MODEL_f1405f3c93e7431bad45566b04d28092",
      "value": " 26.0/26.0 [00:00&lt;00:00, 1.74kB/s]"
     }
    },
    "551bbd9e8cdd445594f93bb87fc94720": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a6d6153c476f4df28d5ff439a15f4a68",
      "max": 898822,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_db78284b8e654440af7b8d3a69dd0aa0",
      "value": 898822
     }
    },
    "5906ee8507074480b59086e52120b132": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_149ccf52c9b84a6b8791139bf5c1abe5",
      "max": 1625270765,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_de54ef26639f47e6b3c148d6ee025b86",
      "value": 1625270765
     }
    },
    "5a3de526b5d246df981d7714133a784d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a966c0de188464d8e40e0cdd3c8d50a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "687c56454d1043f2b79d171810dfeb7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a966c0de188464d8e40e0cdd3c8d50a",
      "placeholder": "​",
      "style": "IPY_MODEL_2e9b7e1831de42b19c7a7c2959bc683d",
      "value": "Downloading (…)olve/main/vocab.json: 100%"
     }
    },
    "693b5dd44a2e48a1b9634500713ecfa8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "789e1174eb834523aa2d996da8d4f624": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e83b1ae3ea7246d7b2b7222b78c3df1d",
      "placeholder": "​",
      "style": "IPY_MODEL_d80cafc5015c456e8cf27031815aa841",
      "value": " 309/309 [00:00&lt;00:00, 10.9kB/s]"
     }
    },
    "78f6244dbe4d4f69a77241ca759a0f76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f836df9ac66c4415910f0da952f44461",
      "placeholder": "​",
      "style": "IPY_MODEL_0f5f1407d88845d388871e827eb377e8",
      "value": "Downloading (…)neration_config.json: 100%"
     }
    },
    "79a8b1dd39ab4e4db3d9b099692e955a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2fa95194cd614752a83fd964a6af9839",
       "IPY_MODEL_f4e14fdbc7124a2c927f8ceae7837577",
       "IPY_MODEL_892b5f7aa84b4ae981379c09f5397a21"
      ],
      "layout": "IPY_MODEL_be362682da394b65beb1a67c6eec6a1f"
     }
    },
    "79cdbad0d1dc4f6ab324ac13dd317b8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7e6273c05af04dba8538019b5dabe5e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "883614ba846d460895201d82bb29f597": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "892b5f7aa84b4ae981379c09f5397a21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4367fe694cd54f26b800f9ae19d2a8e2",
      "placeholder": "​",
      "style": "IPY_MODEL_a8ad1c8f7ebe44de9298c3c68241ee51",
      "value": " 1.36M/1.36M [00:00&lt;00:00, 6.57MB/s]"
     }
    },
    "8ad79bc9e7604cad94978c3d51f5fe64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_78f6244dbe4d4f69a77241ca759a0f76",
       "IPY_MODEL_32171595336644219238ca6aa86a3987",
       "IPY_MODEL_789e1174eb834523aa2d996da8d4f624"
      ],
      "layout": "IPY_MODEL_8e1a4e3068c94492a7c65486cf59b82c"
     }
    },
    "8e1a4e3068c94492a7c65486cf59b82c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "95d5b07289a5461e90d2863d52651437": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_210f248fc74a4f2cb2671e5f1850e784",
      "max": 1515,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_be16aa0d06634e559f5754a382902314",
      "value": 1515
     }
    },
    "98807b0cbaaa42bfbefe464c1c194166": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a3de526b5d246df981d7714133a784d",
      "placeholder": "​",
      "style": "IPY_MODEL_a5f5e7d780c341efb20e1a60dd511261",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "9b24d42bb3f74204b63024820b670156": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f2fb7df4991e472a9f5307c7a4cce042",
      "placeholder": "​",
      "style": "IPY_MODEL_79cdbad0d1dc4f6ab324ac13dd317b8f",
      "value": " 456k/456k [00:00&lt;00:00, 716kB/s]"
     }
    },
    "9d5196deb05549d0b7ba47c8e2bd9b70": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e907706ca3845e891c9fd380d44d92f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ed9bc7814264744acb089f4dd53c453": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a48425092997483c97880427e1b370f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a5f5e7d780c341efb20e1a60dd511261": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a6d6153c476f4df28d5ff439a15f4a68": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8ad1c8f7ebe44de9298c3c68241ee51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "af05bfefe9a444b09286c8716d72b8c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b0e05b95d78949c2b5248144b4b53ef8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3419a24159d245e09f24a6de15579537",
       "IPY_MODEL_95d5b07289a5461e90d2863d52651437",
       "IPY_MODEL_0258c0f831864d76b8da412c72e1bcec"
      ],
      "layout": "IPY_MODEL_15fcefddfe1241e1912308a3e0369feb"
     }
    },
    "b2884184297c4ae2b72dc1653f473912": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b5d4c6556d5f4927a90780c4ea2cd515": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_98807b0cbaaa42bfbefe464c1c194166",
       "IPY_MODEL_5906ee8507074480b59086e52120b132",
       "IPY_MODEL_c50d2fec73aa4dc2a4d22bf266bbe322"
      ],
      "layout": "IPY_MODEL_4102431c863e43bd8e35567c14d89c64"
     }
    },
    "b91a7e309ec244f6bdbc1ee5cf4a748b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be16aa0d06634e559f5754a382902314": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "be362682da394b65beb1a67c6eec6a1f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c1b768bc7bda4f4bb72e1d9455d848f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2dbae29561d44d00ba018fa6050f9651",
      "max": 26,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e359d34b57044c8290f114084129edbc",
      "value": 26
     }
    },
    "c50d2fec73aa4dc2a4d22bf266bbe322": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4a274883440848e1895d4c37911b1531",
      "placeholder": "​",
      "style": "IPY_MODEL_883614ba846d460895201d82bb29f597",
      "value": " 1.63G/1.63G [00:24&lt;00:00, 68.4MB/s]"
     }
    },
    "d4171be7b8b949fa8300301a06e3cb4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_29b916fbd0844450a84f25c1352068b4",
      "placeholder": "​",
      "style": "IPY_MODEL_fac3824f4c3a4c24a4e86a523e0dc8fd",
      "value": "Downloading (…)olve/main/merges.txt: 100%"
     }
    },
    "d7f3dc64f3cf495b9cbcd7050cdd7502": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d80cafc5015c456e8cf27031815aa841": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "db78284b8e654440af7b8d3a69dd0aa0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "de54ef26639f47e6b3c148d6ee025b86": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "dfff6636e432470c9f9b5e9327e06775": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f4e959e848074a36b692316a35c0ea44",
       "IPY_MODEL_c1b768bc7bda4f4bb72e1d9455d848f6",
       "IPY_MODEL_54b753d573ba4af5aae6e90eae730525"
      ],
      "layout": "IPY_MODEL_b91a7e309ec244f6bdbc1ee5cf4a748b"
     }
    },
    "e359d34b57044c8290f114084129edbc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e83b1ae3ea7246d7b2b7222b78c3df1d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f1405f3c93e7431bad45566b04d28092": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f2fb7df4991e472a9f5307c7a4cce042": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4e14fdbc7124a2c927f8ceae7837577": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_407d2cb054564c46881e2fff1b48705f",
      "max": 1355863,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2076cd74bf534668b7a85e8fc4ea2cc0",
      "value": 1355863
     }
    },
    "f4e959e848074a36b692316a35c0ea44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b2884184297c4ae2b72dc1653f473912",
      "placeholder": "​",
      "style": "IPY_MODEL_a48425092997483c97880427e1b370f8",
      "value": "Downloading (…)okenizer_config.json: 100%"
     }
    },
    "f7edb77d5a314f67879c075773f9f10d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_687c56454d1043f2b79d171810dfeb7f",
       "IPY_MODEL_551bbd9e8cdd445594f93bb87fc94720",
       "IPY_MODEL_356744cd08f64f9c9977b18e90101745"
      ],
      "layout": "IPY_MODEL_7e6273c05af04dba8538019b5dabe5e4"
     }
    },
    "f836df9ac66c4415910f0da952f44461": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fac3824f4c3a4c24a4e86a523e0dc8fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}