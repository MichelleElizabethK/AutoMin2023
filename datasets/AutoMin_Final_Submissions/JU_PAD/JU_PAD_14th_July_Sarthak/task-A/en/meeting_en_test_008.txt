Attendees: [PERSON10], [PERSON3], [PERSON5], [PERSON6], [PERSON7], [PERSON8]

Summary:
We see [PERSON10] twice now , but only one of [PERSON10] is moving . 

[PERSON3] have been working it could be done it seems like [PERSON4] came out of paper . 

[PERSON7] still not hear very good , but , . And [PERSON3] should [PERSON3] can try to probe on [PROJECT2] , or [OTHER5] or these of GPT tool , or [PERSON7] do not know . but , that [PERSON3] can use the [ORGANIZATION2] and [PERSON3] can use SL the word the read the context word and manning . 

[PERSON7] mean the individual positions . Another one was especially would [PERSON7] like [OTHER9] , can doing rows and stuff . And maybe , [PERSON3] can focus on [OTHER9] or [PERSON7] dunno . 

[PERSON3] have not attended a course in here . 

[PERSON10] asked  For means do [PERSON10] mean functors ? maybe [PERSON10] can [PERSON10] can start with that . Actually , what have [PERSON10] used in the paper with we need ? [PERSON7] mean , on top of the on top of the transformer [PERSON10] used a perceptor or . 

[PERSON3] mean prepare to better practise just do that . maybe we can shift to proceed to [PERSON6] . and [PERSON5] checked there is a measure , which measure is [out] the attention matrice is a line with particulations and actually [PERSON5] got this from other paper . And we have to look what are the patterns of the what difference actually our results from [though] measure for [PERSON2] proposed one from different photo one observation was that [for the] , let us say easier find the determiners or multifiers . Actually [PERSON5] only focuse on those heads that is for instance was quite good at finding subjects eem the verb . 

[PERSON5] only look at this [balustrades] heads . it seems they do different stuffsit makes sense to try to seek which head those what try to hide them supportly , [PERSON10] guess . 

[PERSON7] [PERSON7] want to say that it is not easy to that there maybe different settings and little bit difference settings of transformer that generates completely different results . It was like normalization token , we even know what [PERSON1] mean in transformer . But if [PERSON7] we get it and we have [balustrades] as well . and we should also , [PERSON3] , [PERSON3] send [PERSON7] the paper where they they had two heads which are trained differently . 

[PERSON7] can [PERSON7] can try to read it and . 

[PERSON3] do not know what , do [PERSON7] have any other ideas , ? [PERSON7] wanted to ask [PERSON8] about [PROJECT2] secure . And right prophans cause [PERSON3] think this gonna be trying to get more reliable . 

[PERSON3] basic write [PERSON3]'s  email . And to analyse [PERSON6] to have [PERSON6]'s  own call there is a poor based . 

[PERSON10] asked them mostly common base are we don t here . And still the waiting if [PERSON8] reappears . 

[PERSON10] do not actually know where it comes from . 

[PROJECT4] wolud better answer in syntactic questions and recognize more than [PERSON3] have . And it is anybody published anything like that more syntactic [PERSON10] get in . 

[PERSON10] guess our assumption is that we have probably the attentions are what task . 

[PERSON10] do not know what we should expect . 

[PERSON10] think make something who model . 

[PERSON10] do not know [PERSON10] do not know these comming in December while [PERSON10] is staying where is . And [PERSON6] think that he was planning to stay here after that but then deserving maybe going back for another 2 weeks after New year's . The make sense try to set up some more frequent with [PERSON1] like model one on one . 

[PERSON10] can always submit it lenght tomorrow . 

[PERSON6] asked  , [PERSON3] should have it , [PERSON3] know . Actually [PERSON10] think there is no little bit like . We can [PERSON1] send today and then tomorrow as well . It make sense that [PERSON6] know better .