Ehm, hmm, this is just an update, ehm,


so let's follow the agenda on the [ORGANIZATION7] document,


the presentation platform, uh,


[PERSON9], what do you mean by functionalities to be checked?We have refined the function of analyses of presentation platform 


and ehm, we would like to share it with you [PERSON4] and [PERSON5] can your team.In order to check if we misunderstood something,


or if there something  we need to add to our analyses, 


to check in- in this.So if you scroll down little bit in the agenda,


there is a slot on pr- presentation platform.You have the the plan,


you also has a timeline, 


like after we agree, 


if we agree on the functions that should there you in the next week.So, what it


(PERSON9) But, mmm...


First of all we have to check the function analysis.Let's just think that uh, we already need it really working in well tested, uh,at the end of June.So I think that the first prototype should be ideally ready, uh, on the 7th of June, like the first very first shot with with box and all of that.<laugh>


So, are you when is your earliest date for uh, for technical call, eeeeh,


tomoo-


To to like this the next week would-


(PERSON9) Yes, sure.(PERSON4) Monday, Monday morning?(PERSON9) Nn, Monday morning, ahh, 


actually, we have a call twelve o'clock,


but early it's perfectly fine for us.(PERSON4) Okay, yes, so Monday, at nine, or ten or as you wish.(PERSON9) Well, Monday at 10, let's see.(PERSON4) So Monday the 20th of May at ten, 


and will discuss what what we need in the platform and-.(PERSON1) Okay, okay, ehm,


I refuse the [ORGANIZATION3] tutorial,


I have taking a look at the some work <unintelligible>.I don't think <unintelligible> dusted off my copy <unintelligible> 


(PERSON4) Okay.I, yeah I think I know what I need to do.I can have a prototype soon like within a couple of weeks <unintelligible>


(PERSON4) Yeah.(PERSON1) Yeah, that's where the big question mark so at the moment, that's what I'm not so sure.So, [PERSON2], could you disclose,


how should we best handle the- the incomplete sentences, 


because what we do not want to do is to rely on the cashing client.So what we really want to have is ehm to translation of incomplete sentences for the user experience.So the question is, ehhhm, ho- 


what is the output of the ASR actually, 


when does the ASR decide to to start a new segment, 


like to close the the previous segment.When I 'm looking at the outputs of of the ASR,


it's not complete sentences,


but it's closing off every now and then, 


so how does this work?<unintelligible> is continues sequent <unintelligible>


(PERSON4) Okay.(PERSON5) Sequence labeling task which labels were <unintelligible> 


 And eventually will place a label to end the sentence.(PERSON4) And that's where if you if you like bur-


If you run into in in the EB client, 


and you see the lines great deal extending, 


and then suddenly the lines being cut short.(PERSON2) If you request in the EB client text, 


then yes.If you want to see right ASR output I'm not sure if <unintelligible> you will have to request the unsegmented text.And there is-


you see individual words there, uh, 


in the vertical format, so that one word per line


and the time stamps, 


yeh, 


so the the question is,


which approach should we take as the input for for [PROJECT2] client.(PERSON5) <unintelligible> Both we calls <unintelligible> completely spokens of <unintelligible> and ASR can change <unintelligible>


When when ASR decides that given given that (causes) so far, maybe <unintelligible> sentence would be better.(PERSON4) Yeah, so and the output, if you look at the individual segmen-, 


individual tokens from the if you if you look at the unsegmented output.But with the same timestamp there would be new token,


and if this if the timestamp still falls in the range, 


which is like operational in the segmentation worker, 


then it will correct it.But the ASR signals is explicitly, but come a time when the when the sentences markets final 


And that will also <unintelligible>


(PERSON4) Yeah, so what do-


in general if we run the the segmentation worker,


if you run pipeline and if we look at the outputs of segmentation workers,


we should train our empty systems to work on all the individual lines that we are getting from these.(PERSON5) Yes,


I 'm-


I 'm not train with these system myself I think we're in the process of doing them,


but my intuition would be do not put too much emphasis the incomplete sentences.(PERSON5) The (algoritm) what the system will be judged by the final translation, 


and you should <unintelligible>  the translation was by having incomplete sentences, 


which I 'm probably not going to be useful translations.Let me-


yeah, let me let me do copy paste of an ugly, or-


Actually, I might try share a screen if that works,


how do I share the screen,


that one select window or screen.So hopefully I'm now sharing my screen, 


if you yes, 


and this is this is the output that we get that we got at the last conference, 


the mock conference with the interpreters.So uh, 


is this the type of input that our empty system should be ready for,


which is starting in the middle of a sentence, 


having full sentence.I think that we should proceed, 


[PERSON] play with [PERSON5] and you.This is not far from the context,


dependent mission translation that we have tried for for this [PROJECT3] so technically the segments are not too long, 


they never spent too too much beyond this,


what what beyond  this language that your looking at now, 


and we just need to make sure that the the transform model handle that well.(PERSON1) Sorry, [PERSON4], why does segmentation change, though it it sort of- it has.(PERSON4) [PERSON2] would know, 


I have, I have no idea 


(PERSON2) Um <unintelligible> for one thing it's also possible that if it is (I'm it knew hypothesis, the segmentation as we run output segmentation might be different.Um, I would have to be at the coding <unintelligible>


(PERSON1) Hmm, cause cause the first segmentation is fine.And the segmentation worker is not emitting timestamps,


it receives timestamps with the individual tokens from the ASR,


but it doesn't emit them.I think that this is something that [ORGANIZATION1] needs to investigate and and improve the the segmentation worker so that it emits the timestamps 


because these timestamps would then allow us to like handle the translation well.This saw statistics on the internet,


actually starts in the middle of or like is it some continuation ehm of of something which already output.And then the alignment <unintelligible>


[PERSON6]


(PERSON5) I 'm not sure it is <unintelligible> here.If the are-


If these are the timestamps of the beginning


and the end of this later and not,


then we we are not uhm,


we do not know the the timestamps for the individual parts like here internet full stop.We need to ask [PERSON2], 


or someone from [ORGANIZATION1] to validate these locks to to help us create a reliable locks from the ASR workers,


so that we are seeing what we are supposed to be seeing,


and this should include timestamps.And then we should, eehm, yeah,


and then we should decide how to-


the baseline would be indeed to follow the segmentation coming from the segmentation worker, 


which uh, 


which get worse, here with the- with the eyes (saw) statistics, 


and then the final experience of the the user experience the of translation would not be good, 


because the statistics of on the internet will translate only the later part of of sentence.So I think for the user experience it will be better


if we translate these incomplete and slightly damaging sentences, 


uhm, rather than having the cashing worker, 


which we have had in the past, uh, as as a fair.So we could uh, this this-


This cleverness could be part of the empty empty worker


(PERSON2)  I don't want to <unintelligible>


and the risk of false information for for the most part I think the empty worker does do these things 


and <unintelligible> details I <unintelligible> recommend  you have to <unintelligible> that I posted last time <unintelligible> 


which is the code for the emptyworker, 


not the actual MT part


but every everything from the moment it's <unintelligible> your network and after it get back from your network


So all the the change  together, were <unintelligible> this part and <unintelligible>


(PERSON4) Yeah.If you and [PERSON1] could like synchronize


and make sure that [PERSON1] will know where the relevant code is,


then [PERSON1] can decide whether in his re-implementation for [PROJECT2].(PERSON4) Yeah, so [PERSON1] please, take an old, 


and and make sure to try to look up of this thing in the existing code, uh, in the <unintelligible>  ticket.And then let me know, 


maybe in the call next week, 


like  whether whether do this worked but for the-


I think that [PERSON1] we should try to train the models to be ready to accept like partial sentences, 


and even inputs that started at the middle of of of sentence.So me and [PERSON5] will try to get the  this part working, which is like finetuning normal empty models for a bad-  


badly segmented inputs.So [PERSON5] please take the note on your side, 


but we need to figure out what why we failed


and we should get that running, 


and that way, hopefully uh, 


will have the correct segmentation from the existing old from the [ORGANIZATION1] emtpty workers, 


available also in the new [PROJECT2] empty worker.But as a fall back we should have a models that are ready for for such input.And that the segmentation worker trained for Czech,


but that that is also really depended obviously on the on the ASR for Czech.So I'll stop sharing the screen, 


and let's move to the- let's move to the [ORGANIZATION7] document again.So, still not sure how to best handle two options, 


two options reuse called from [ORGANIZATION1].And this will make a fall back solution for <unintelligible>


Well,


fully following uhm the segmentation from the segmentation worker.we don't have [PERSON10] here English and German ASR, 


what is the status there.(PERSON5) We spoke yesterday <unintelligible>


(PERSON4) Yeah, one thing is the language model adaptation.We can have plain text files with relevant well slide-


from the slides from related documents, 


and we can give it to you at the level of individual presentations, 


or we can lump all of those together for the day, 


or for the whole today workshop.(PERSON5) Generally any any sort of text is <unintelligible>,


on sure exactly how detailed it has to be


I'm, I'm not sure.So please investigate 


whether in the end, you are going to lumb them all together, 


and prepare one language model


and like start the workers with the one language model for this workshop, 


or whether there is a mechanism that we could make it presentation or per day.I do not know how difficult is it,


to get it change to a different language model.(PERSON5) So the minds of the mechanism,


we are not using such a mechanism anymore <unintelligible>


we have one thing it's a lot of effort <unintelligible> language models and it's also possible that models system don't need adaptation any more.If you decide that you don't want to do any ASR adaptation to the text, 


that's fine,


if you do it and because you you, you find it like useless,


If it is the model is is the domin indepedant enough that that will be sufficient.If you decide that you would like it from us at the level of individual presentations,


we will have to discuss the technical details like where to put the files and all that we're surely collecting the files.And will try to do fine tuning of the machine translation models based on <unintelligible> that that we can get based on the mono- monolingual include files.Well, [PERSON8] is not here, 


but he is working hard to get the pipeline, 


the training for call the running, 


what we are.So this is still very risky, uhm,


whether we will have Czech ASR for the work- workshop or not, 


but still-


the workshop runs in English.There will be one interpretation of from English into Czech and one interpretation from Czech into German.And we can have the ASR from, uh, from German,


if that's if that appears the best.[PERSON5] should be able to speak now,


but-


(PERSON5) Yes, can you hear me now?(PERSON4) Yes, yes,


(PERSON5) Perfect.So I think we should as weeks pause we should indeed do this on a daily basis.But it's-


(PERSON5) Yes.And then the machine translation systems,


multilingual English tool any is currently training,


okay,


that's good, because the the student I have for this is not delivering anything.<laugh>


Uh, and the <unintelligible>


I think we have discussed this 


(PERSON5) Yeah, we already cover that point, I guess um, 


you mentioned you will gonna try to get some data from Taos.Well,


I have not emailed, ehm, you know him as well <unintelligible>, 


but I've talked to him before,


and I don't have the data, the input data now,


because we are still collecting them from-


Actually we're,


shortly we should be deploying the platform, 


the tiny webpage to collect the documents,


then  the [ORGANIZATION6] will populate this with the documents, 


then I will convert the documents the plain text.So this is something that well has a long pipeline, 


but we'll get there, uh, someday.So, we need the MT domain dependent data for MT fine tuning by.Yeah, [PERSON2] is  empty that's on a German to English, 


mainly because the the English ASR will be a uhm,


so so then, our main input will be the English ASR 


or one of those from the rich speakers,


the secondary, like the fall back input could be from German to English, 


and then I would indeed ehm rely on the [ORGANIZATION3]  platform to do to do the pipoting.So I would now like to learn from [PERSON2], 


that this empty system works and emits outputs in such way that the the subsequent English to something, 


and the system can directly connect and [ORGANIZATION3] platform will will do it,


is that true?(PERSON7) So it depends emits output, 


I don't think that the the the <unintelligible> that should work, 


I I can report back to you.But I can say that English- German to English is probably our best translations systems <unintelligible>  transform model so would get better.And tested whether the platform indeed support pivoting, 


cause you, at the [ORGANIZATION1] you also have English to something empty systems.So please try a pipeline where you use your-


where you use German ASR,


German to English empty system


and then English to anything just for the sake of testing this this pipeline.We see German ASR,


German to English machine translation, 


(PERSON4) Yeah.(PERSON9) English to anything..translation... 


(PERSON4) Yes, this pipeline, ehm,


and German, yes, the German ASR [ORGANIZATION1] German English empty,


[ORGANIZATION1] English whatever,


whatever empty and then presentation.(PERSON9) Okay, ehm,


sorry what do you mean for pivoting.(PERSON4) Well, the pivoting is that you connect these two empty systems.(PERSON4) So please, test this, 


and let us know again next week, 


if this works, 


because then we will be replacing this part was the [PROJECT2] worker that [PERSON1] will be developing,


but we need to know that the rest works.(PERSON2) I will alreday  report everything works.(PERSON5) <unintelligible> ASR outputs


(PERSON4) [PERSON2], what were you saying?[PERSON2]  are-


[PERSON2], are you looking at the [ORGANIZATION7] document?[PERSON2] confirms this works except the new [ORGANIZATION3]  except the nonexisting


<laugh> 


[ORGANIZATION3]  presentation platform.(PERSON2) Yeah,


so I just tested by starting one about English workers and pivoting over English worker.(PERSON4) Yeah, 


and it was in the at the level of partial sentences?(PERSON4) Yeah, 


okay, 


right.So than [PERSON5]


can you very briefly say about this, 


because we were discussing this ehm, what is your idea.(PERSON5) Ehm, 


so I tried to fine tunder original model on on on sub sentence window of size three to fifty words 


and we did to cuts on alignments.(PERSON5) But for it we need to the final hypoteses from ASR.And now I had publick-


Now, now I have new idea that we can take paralel big paralel text only corpus then we are text to speech on it,


and then ASR,


and we try and on the output from ASR with- with errors against the original targets.(PERSON2) Yeah, so would I on this very most important thing would be text to speech on models one speaker.(PERSON7) But it will do the same errors on name entities and rire works as usual speaker at least.Looked to one of the the top as SLT systems in last year 's <unintelligible>, 


and they were using this technique as-


It was only one aspect of their systems.So I'm not sure exactly how- 


(PERSON5) Important-


(PERSON7) How effective it was but they were using this.(PERSON4) So,


Let's us keep this idea in mind.We need to run [ORGANIZATION1] ASR on the <unintelligible> docks,


record the locks, 


ah including timestamps, 


and then, and then like fiddle with the alignments and segmentation ,


uhm, 


yeah making our paralel data for training of empty similar to the uh segmentation 


or like miss segmentation ehm that we get from the ASR segmentation worker.And then we can use this segmentation with uh the paralel data to change the paralel data,


so that are segmentation mimics what the what the segmentation workers is doing, 


and this would be the uh, the data for fine tuning the empty systems.Okay, so we will let you know uh the next week, 


how this whether we've succeeded, 


whether we were able to uh, to proceed to to process that docks with [ORGANIZATION1] with the existing workers or whether we failed,


and so on.It's not a priority at the moment 


because we are planning to rely on the on the [PROJECT2],


then anything, uh, yeah, yeah,


so anyone coming to [LOCATION1] in person?(PERSON4) So let us know, 


or especially [PERSON11] know, 


if you were planning to come in person to to see it live.It would be useful, 


but we could do it,


ehm, even say, would be extremely useful for you to see the whole thing in in practice, 


because the last person we had here were [PERSON3].So we know from experience that [ORGANIZATION1] is running age ASR workers for English, 


and four of them don't emit any output.And if we run the same client, 


the same pipeline concurently six times,


we will end up with four lines four pipelines four sessions ineffective, 


and the fith and sixth one working well.So like in in search for components that work,


it would be better if we could simply say please start this pipeline again 


and avoid this worker, 


because it's under the control of [ORGANIZATION1] the worker claims it's working, 


but it's not delivering the output.So we would like to as the users at the end of the client, 


would like to say,


we want to build this pipeline, 


but avoid this particle worker, 


because last time it didn't work for us.Of course, is being on the idea that 


<another_yawn>


Who subscribes the mediator as service is able to provide the service, 


but I can take a note and check it with the team.Uhhm, 


I have to say that it's not easy,


because of course, 


[ORGANIZATION3]  platform is based on uhm having distributed services allowed you would join.And leave the service,


it's not that easy to imaging such kind of behaviour,


but we can reason about it, of course, 


(PERSON4) Another option would be to  somehow like have tests of workers, 


and the workers should themselves or the the the party, who is providing the workers should should be able to test individual workers.So like I imagine that at [ORGANIZATION1],  


there could be a script every two minutes or whatever, uh, 


looking at all the ideal workers 


and asking for a particle worker, uh, 


to test it.And if the test fails, 


then [ORGANIZATION1] would know which worker is it.And they would kill it on their side, 


and then it would not be available anymore in the platform.So another, [PERSON4] says another  option would be to force the platform to use particular worker for pipeline or for session,


use quick test session as they side of AG [ORGANIZATION1] for each of their workers 


and if they do not pass their test, [ORGANIZATION1] could kill them.(PERSON9) Yes, ehm, of course, 


we have to define what suitable <unintelligible> for each kind of service 


It's not that easy to manage it also in this way.(PERSON9) I has just a question regarding your note in presentation platform the [PERSON4] experiments,


fix experiments,


probably we discussed about it on Monday.(PERSON4) Yes, exactly this is-


this is this is to be-


this is to be discussed on Monday.(PERSON4) Yeah,


we will apply <unintelligible>


[PERSON10] is responsive,


I know though we we just email him, 


and then get him on on slack.We have sessions starting, stoping with regular election tranclation so it's four to six times a day, 


and the worker is still all work after three weeks.(PERSON2) Interesting is also is the the usual problem that the the person <unintelligible>  the worker is not free dubt <unintelligible> as mark is busy in which case you couldn't even start new session, 


because-


(PERSON4) That's not the case ,


that's different 


(PERSON2) And we're having even a different problem.(PERSON2) Doodle let us know maybe we can have a - 


I think there's a <unintelligible> mechanism, WiFi something.<unintelligible> worker is hearing <unintelligible>


(PERSON4) Yeah, 


okay, 


yeah, 


yeah, 


Thank you.So [PERSON5] please please remember that next time we we would like to make <unintelligible> of such failure to debug thats.And let's let's talk in five minutes again, 


maybe not all of you, 


but  the general [PROJECT5] call.